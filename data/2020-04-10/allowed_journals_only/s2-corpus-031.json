{"fieldsOfStudy":["Medicine","Mathematics"],"year":2012,"outCitations":[],"journalName":"Pharmaceutical statistics","paperAbstract":"Most clinical studies collect several safety-related laboratory variables. Generally, it is the extreme values of these variables that indicate potential safety issues. We illustrate the novel application of extreme value modelling to such data, with the aim of predicting the incidence of severe adverse drug reactions. By applying the methods to a clinical trial data set, we identify a dose-response relationship and use Bayesian techniques to identify a potential safety concern by making predictions from the fitted model, despite the small sample size.","inCitations":["2230646fdf1a0c2e04be6f27a92ebaad7ef38b3f","8a8142032ad9d2f4e2086eafc87f88fe2f320c64","1feb4bb0f0facc12602503b703bc8d24725d672f","9d8cde236ed45c0529d544285d442535018ce245","6baf88c5c5d3515adf0fac359e2e1709503f4534","293aa425383d2e6486477acafea43483c3622fcf","952bbfcfff02c31fd1385634f1eaaf95ec39fbd0","3f28af4356938b95a334441865af023ba6029212"],"title":"Extreme value modelling of laboratory safety data from clinical studies.","doi":"10.1002/pst.1510"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2013,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"In clinical trials, interim analyses are often performed before the completion of the trial. The intention is to possibly terminate the trial early or adjust the sample size. The time of conducting an interim analysis affects the probability of the early termination and the number of subjects enrolled until the interim analysis. This influences the expected total number of subjects. In this study, we examine the optimal time for conducting interim analyses with a view to minimizing the expected total sample size. It is found that regardless of the effect size, the optimal time of one interim analysis for the early termination is approximately two-thirds of the planned observations for the O'Brien-Fleming type of spending function and approximately half of the planned observations for the Pocock type when the subject enrollment is halted for the interim analysis. When the subject enrollment is continuous throughout the trial, the optimal time for the interim analysis varies according to the follow-up duration. We also consider the time for one interim analysis including the sample size adjustment in terms of minimizing the expected total sample size.","inCitations":["38e598295396b2c88790708af001447bebab1538","021576f0f94a2c73165c66ba5f3bf6413effe553","875dac72efc60ef7ecee303ef60cff8ed7926faa","d890981fd150709133eddd19dda629555072ed9d","5e16ff2f3205fc04d68b55820cbf6e22232bdd4e","ab477bc71debefa94c95831e871c1fa78a9d0d38"],"title":"Optimal timing for interim analyses in clinical trials.","doi":"10.1080/10543406.2013.813522"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2010,"outCitations":["763f44692cd6c55412e041fc0b981d6d5f478a78","c10406c10e429be143f17bc6e4ff727f01a62b52","4e9ad8f10151523d22ccbf366ef119c14705c824","05d778cd0f7b9f19c81d777540e25780a2b98a3f","052ba499b1a4b17c2747de03c58d972deb04fda4","493295f4053d334e2f234bf9f8775bebc1105486","b477dd12dd49e44a62c1a303501df5fb6706c7e9","9a927f5ea9c9a66442407cebb3173f449ca5276b","aec392a02f5555c42e42783764204955a13c638e","0aa0db60f0a91ad9d3e80f2f6acda9ea797a7232","ea54f0c0568cab38619ee51e6ac021e76d6a6559","e69bce0185720fcb652ae458a4529a2807f53de8","657bd455382a141e623665cf7e30acbfd8175533","271eccff3aaa8bdb0d098156b64900a7f3fd87df","7de372cae64dea5263076b5139c6b79df9e3157b","0bbdfe869a4370c7d7f9d32793f459a7d48e85f3","e582469e3eed0bcb5c458ff5fd200f5acdbe0d33","159da1053d89d79b93131b64e855469568adf681","7aca1b2a1fc611e9dfce4711befb7afecbc18bf6","7cd6fd47bcd93d4e08d405d81d88189be9f03140","7cf8e0d21da0ad0ac69991c82363c3af191fc47f","5d11e82acdc5f698de985356bc860a070c34eae7","1aa4d47f768d0c7939a7abe63731c01735855be4","44ad920f1d046adb042ea6a33d4b216f2d76ba81"],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"We propose to use generalized additive models to fit the relationship between QT interval and RR (RR = 60/heart rate), and develop two new methods for correcting the QT for heart rate: the linear additive model and log-transformed linear additive model. The proposed methods are compared with six commonly used parametric models that were used in four clinical trial data sets and a simulated data set. The results show that the linear additive models provide the best fit for the vast majority of individual QT-RR profiles. Moreover, the QT correction formula derived from the linear additive model outperforms other correction methods.","inCitations":["48202679798193c01ef24f5ae76f642875417d4e","3a33af5e9fa49e0981a4ce3a5f4f411260ab06e4","61ca999962fd9b8191f9c45b4071001dbfaa4f1e","cb5a26a7af3845e91759fae635f77778920fb7c7"],"title":"A nonparametric approach to QT interval correction for heart rate.","doi":"10.1080/10543400903581952"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2010,"outCitations":["ceca532cb3daea54bf84d7beabaa7879234abbd2","f77d72183c38a77f01c3bfd81e29ba4aa7c6ab01","8ff0dc45045c06102f88d4d285417567fea60d52","6edc6faa9fa8c29c327193ba6a36bac7514ab40b","33adabaf38a11e59076bdef57e0fe23d30737b99","42e816702485d953c4e92ce79b9bd4b499d0f10b","ae805b87cff9e92472f537fe1b26506c2426fbcc","73f6b11604e6622a19c6aaa47897be3968620f59","ca4dd865742aff6e326473154e9516bba2e5c8bc","99a176803dc79facf41c9f62aa702eab5e100ab8","af96cb1d5c7da5418ca7b4310132b5fe7c7364b0","78bd618cc9c66f077688c9b6334477718367857e","2f6f2d50fff6394424ce92c169adca6d7e8f6494","ade7c46b33bfde9afa188a003185f327a50b0efa","86913fcc3b5370d432b5b1691804441045df2250","86d7dabdea041d446eac70ab230f2430a870cadf","2098391def9f8db6d400497b9ba397d526d227c3","6df36ea7e808b299456c37652eb98409abf83c9e","a9fa94791dab5b2bf3345b836663518a5822ed3b","fa0f05b6c48120083dd4cc07b85fe22a2e8f6030","78c02bebf1f84835f30657397f1d445050d88172","87a3aa92e49442d607acb6e78739263f5ced0494","bc1cbf6bea1d5199f9690d8bc70ee85985345a86","dfb38d4fe3d348d971f4495ae1a6254576cb5c0f","67f6912a9677ea4ffb344fe5a12e0fb3e8dd5c2b","8e6f75368f866264ccb2d835820998f6b3ea86cd","15211292412f365ed2d4946333a924029dee1c39","e014de57ee6cdd7c837c3f99ae815e82315e1cdb","3dc46f776b8427257b7507ce793f5de94c8185c6","9b11b173a6f319fb4217645764a2e61c4a9cb2b3"],"journalName":"The annals of applied statistics","paperAbstract":"To investigate whether treating cancer patients with erythropoiesis-stimulating agents (ESAs) would increase the mortality risk, Bennett et al. [Journal of the American Medical Association299 (2008) 914-924] conducted a meta-analysis with the data from 52 phase III trials comparing ESAs with placebo or standard of care. With a standard parametric random effects modeling approach, the study concluded that ESA administration was significantly associated with increased average mortality risk. In this article we present a simple nonparametric inference procedure for the distribution of the random effects. We re-analyzed the ESA mortality data with the new method. Our results about the center of the random effects distribution were markedly different from those reported by Bennett et al. Moreover, our procedure, which estimates the distribution of the random effects, as opposed to just a simple population average, suggests that the ESA may be beneficial to mortality for approximately a quarter of the study populations. This new meta-analysis technique can be implemented with study-level summary statistics. In contrast to existing methods for parametric random effects models, the validity of our proposal does not require the number of studies involved to be large. From the results of an extensive numerical study, we find that the new procedure performs well even with moderate individual study sample sizes.","inCitations":["c602a24af08658ae9329b67db92076fe342c70d6","a00990c60ab6befbfbe09453bb2d7b44e5a5d8a3","4b62381505b088ae116b5bea6442bb1fc93fc401","b7de79e8264e4d30dc078dc92d35ef32214dbe75","d61f8bed945475cb861b8c197b60f6df1aaf83ec","dfb38d4fe3d348d971f4495ae1a6254576cb5c0f"],"title":"Nonparametric Inference Procedure for Percentiles of the Random Effects Distribution in Meta-analysis.","doi":"10.1214/09-AOAS280"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2003,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"In a regular analysis of covariance (ANCOVA) approach to stability analysis, the decision for pooling data from different batches plays a key role in the determination of the shelf life of the drug product. Conventionally, the decision to pool data for the estimate of slope and intercept of common or individual regression lines is made by \"no evidence to reject the null hypothesis of no difference.\" With typically limited observations, a significance level of much higher than 0.05 was recommended for the pooling tests in order to avoid inflation of type-I error rate of the shelf life testing. This logic of the pooling test decision making discouraged the use of replicates to improve power of testing and precision of estimation. The concept of pooling by equivalence test was originally proposed by Ruberg and Hsu in their 1990 article \"Multiple comparison procedures for pooling batches in stability studies\" Such a concept has evolved to pooling batches based on the shelf life equivalence test by Yoshioka et al. in their 1996 article \"Power of analysis of variance for assessing batch-variation of stability data of pharmaceuticals.\" In this article, an approximation test of shelf life equivalence and a test of chemical value equivalence for the data pooling decision are proposed as an alternative to the conventional ANCOVA approach.","inCitations":["139b929f0ab5aeb9ca4a8cbefa90f5fb5df231ac","ce1c54c0d7e82cade0662f48509815ce3146c03f","f4dc102d7eabcf2cb8e62473bd33b279bf2f941f"],"title":"Shelf life determination based on equivalence assessment.","doi":"10.1081/BIP-120022765"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2006,"outCitations":[],"journalName":"The British journal of mathematical and statistical psychology","paperAbstract":"This paper proposes two unidimensional item response theory (IRT) models for analysing normative forced-choice personality items. Both models are derived from a common theoretical framework and arise as a result of different assumptions regarding the mechanism of choice. The simplest mechanism gives rise to the one-parameter normal-ogive model. The second mechanism gives rise to a new IRT model, which is closely related to the Coombs-Zinnes probabilistic unfolding model. The second model is compared theoretically to the normal-ogive model in terms of item characteristic curves and amount of item information. Next, procedures for estimating the respondent and the item parameters in the second model are described. Finally, both models are empirically compared by using two well-known personality measures.","inCitations":["73e58870d2cb3387a2d5922e0c6ce62bcefc1bae","acdafa862c67e1a2fef20cb82fc92f5c0ef07301","b33946049d1cdb75d67092dc6cd22153542e346a"],"title":"Two item response theory models for analysing normative forced-choice personality items.","doi":"10.1348/000711005X64691"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2018,"outCitations":["13976c572d028ec764a4c8a044729d1485480547"],"journalName":"Pharmaceutical statistics","paperAbstract":"To gain regulatory approval, a new medicine must demonstrate that its benefits outweigh any potential risks, ie, that the benefit-risk balance is favourable towards the new medicine. For transparency and clarity of the decision, a structured and consistent approach to benefit-risk assessment that quantifies uncertainties and accounts for underlying dependencies is desirable. This paper proposes two approaches to benefit-risk evaluation, both based on the idea of joint modelling of mixed outcomes that are potentially dependent at the subject level. Using Bayesian inference, the two approaches offer interpretability and efficiency to enhance qualitative frameworks. Simulation studies show that accounting for correlation leads to a more accurate assessment of the strength of evidence to support benefit-risk profiles of interest. Several graphical approaches are proposed that can be used to communicate the benefit-risk balance to project teams. Finally, the two approaches are illustrated in a case study using real clinical trial data.","inCitations":["900c553d2f5f233b720b791aac4b944f71b06e23","13976c572d028ec764a4c8a044729d1485480547","d44ab457cc848a61b69fbecf89f01fd43861bf4e","10390826b7b95e5ac473c8fbb625ac835953af1b"],"title":"Bayesian joint modelling of benefit and risk in drug development.","doi":"10.1002/pst.1852"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2015,"outCitations":[],"journalName":"Communications in statistics: theory and methods","paperAbstract":"The traditional confidence interval associated with the ordinary least squares estimator of linear regression coefficient is sensitive to non-normality of the underlying distribution. In this article, we develop a novel kernel density estimator for the ordinary least squares estimator via utilizing well-defined inversion based kernel smoothing techniques in order to estimate the conditional probability density distribution of the dependent random variable. Simulation results show that given a small sample size, our method significantly increases the power as compared with Wald-type CIs. The proposed approach is illustrated via an application to a classic small data set originally from Graybill (1961).","inCitations":["8c132bf035ea225a67c6c6d499a2bf305de6df8d"],"title":"Inversion Theorem Based Kernel Density Estimation for the Ordinary Least Squares Estimator of a Regression Coefficient.","doi":"10.1080/03610926.2013.781633"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2009,"outCitations":["b68111d2e692bbc1e5708b9d0de346e9e12577d4","6ed0e4a022dbc09ed1e0748a4ba8c192f5dd1d90","a633e5f48dde0e142984aa346df21dceb87cd6b9","6bf4a7070be3d9bb85175dfafa030eff18e0dff1","c608538b5880a9593944e81b7209a82cd70c5e4f","021f48e9e041420cca8f6613124804bbc570933a","e068be31ded63600aea068eacd12931efd2a1029","b365b8e45b7d81f081de44ac8f9eadf9144f3ca5","4148066e5f8658549bcbb59dda2b6808b2ae16cf","d1bdd112b953ef19f5c6c5efb0931e4260d811ff","c81d0e21e9dfaecc2791506f62432b8fd12d3050","8db47bf351a35145618514c3c81a76dafa0539c1","7df7cd771a8ef41a252198785e4f2e08937dce46","ed3a2b1d571a8188f41341f9b5c675a7682792b0","de6556abad53c37d90ea28b673591a7e64ffc660","007f2d17e302ba17f64bf7a76931782da186f984","af2049b9e74970d65f6070eabce18cfed47190c3"],"journalName":"Biostatistics","paperAbstract":"We consider estimation and variable selection in the partial linear model for censored data. The partial linear model for censored data is a direct extension of the accelerated failure time model, the latter of which is a very important alternative model to the proportional hazards model. We extend rank-based lasso-type estimators to a model that may contain nonlinear effects. Variable selection in such partial linear model has direct application to high-dimensional survival analyses that attempt to adjust for clinical predictors. In the microarray setting, previous methods can adjust for other clinical predictors by assuming that clinical and gene expression data enter the model linearly in the same fashion. Here, we select important variables after adjusting for prognostic clinical variables but the clinical effects are assumed nonlinear. Our estimator is based on stratification and can be extended naturally to account for multiple nonlinear effects. We illustrate the utility of our method through simulation studies and application to the Wisconsin prognostic breast cancer data set.","inCitations":["7a56a81afb0490462a3eebe87c7a7713ea571899","4d2b8ceb9c3f94f190f98f557b09b8eddd990568","b91dfbdda0bec4e0b2d528e35ed5267af334e6b2","4c8807146cfc5a01451a19b165f791d2bd56ac0c","f1c90f4e25eeaf7ab7f84915a74e4c9cb23650ea","f0bf77e42d346a52f2e2d9d8718264d3811413ba","43432e95c5c4d052e7a2f50b95773959faa49a04","9deceef095ffe36166a1a985060bb68dd42d6606","aacfbb7df53bd676a107a2c00e94dd871617cc28","a4519df22cf1e18def5953cd68c4ce8e23caa8ee","b0fa3b02bdd7271586ccdafd873edcd6e67e343b","aeb63f4b64d96c7fc71c15dd4932096d4c16aa06","b4627cb676c2714110658956b15cb72b9c34531c","8963209b68bc27ebe9f0be41e5ecf7659b46aa42","71d7233f4e490dcd1e221cf0d4b7584a6806b6b2"],"title":"Rank-based estimation in the {ell}1-regularized partly linear model for censored outcomes with application to integrated analyses of clinical predictors and gene expression data.","doi":"10.1093/biostatistics/kxp020"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2012,"outCitations":["0b3bf78d63374eec590204de72d36aa75722278d","fa0f05b6c48120083dd4cc07b85fe22a2e8f6030","fc0760263f6cc7c2a373694ac1b46bd52a28c03a","a3263063e076c8f2dda89270c7782b6999735b48","a35e2b9794f420b5e93d52a0ff4e7b6340752888","b84b2e796891d791c089540546095d66097d3a25","dcc23fa9b383194e0de2462b7d2e3a50ed85b9c4","a430499ae452a09016fd26932bebfff177635467","1b727670a6b79f1f538bee33e1f369231341f816","8e3154cc9e70d09019e87dfa7e50dffbc8dc82ff","66e9838587369ea71e0872a3822fd742a3fe4bed","f0a39f6155a1f54f7217ff6eb8a8bf9e17dd75e1","3c5dcf98d57ce1ad0ec0a08c87ffe19efcccfc6b","bc4afcf41e7f14cb6be436a3ad02f682a3e5d7f6","d56896f2b22e1c3a133f8aecb130312d65fec712"],"journalName":"Journal of probability and statistics","paperAbstract":"Huntington's disease (HD) is a progressive neurodegenerative disorder caused by an expansion of CAG repeats in the IT15 gene. The age-at-onset (AAO) of HD is inversely related to the CAG repeat length and the minimum length thought to cause HD is 36. Accurate estimation of the AAO distribution based on CAG repeat length is important for genetic counseling and the design of clinical trials. In the Cooperative Huntington's Observational Research Trial (COHORT) study, the CAG repeat length is known for the proband participants. However, whether a family member shares the huntingtin gene status (CAG expanded or not) with the proband is unknown. In this work, we use the expectation-maximization (EM) algorithm to handle the missing huntingtin gene information in first-degree family members in COHORT, assuming that a family member has the same CAG length as the proband if the family member carries a huntingtin gene mutation. We perform simulation studies to examine performance of the proposed method and apply the methods to analyze COHORT proband and family combined data. Our analyses reveal that the estimated cumulative risk of HD symptom onset obtained from the combined data is slightly lower than the risk estimated from the proband data alone.","inCitations":["f54d5c34b61ad7774045dc3d4721b74e3aa3de4d","4cc168b73f0e7fbf29e24e25d78a2b6510946dc3","76a418ab9519abd1c49f151eba9c75c51a9882eb","0e34f6fd4a23d2476ff99e76aaab6b676a3dae0a"],"title":"Predicting Disease Onset from Mutation Status Using Proband and Relative Data with Applications to Huntington's Disease.","doi":"10.1155/2012/375935"}
{"fieldsOfStudy":["Medicine","Mathematics","Biology"],"year":2012,"outCitations":["b1d6e3d6538d4b943d609dd2499478b5658cf279","6bc6d859785aa237858d3a1ed7ae62a3a7b73536","b2807c9a6db0555f9b9dceca19c965935d3dc679","fd8963a669400ade691623a87d2f0f07f95fab8e","b587ac53f169b1554cf69878fe2fd476977509a1","a43e226e75cd000ccee36bd4f4277c5e64550bf6","e3c63fec1800ace9531f014e2958efc639c45a7f","2c6384baa2d268a7b4f14e077b45002511d5c954","e361a69aa1324d26ef4677f3da7cdd052927c7ae","bc6a2800962bc8626262791d3f7672c381cc222e","fa5096ccfb65f95e85737168b6f38de0cbbe54f6","1c8d2fe9759f979a220999ff489bf2358e7928a6","c9437320c409510b573fb96ab6b7aa507eb891d7","7c3b564bbdc8e7e3242257189ab7702d3e095115","fb28b4c68c2b7062ba2789ad52ea899135adde80","2eb1ce1c3eca9be6ad741d67d1745f2f77fee6f6","813bb2085aa88024c63defafaa957d0e293f297f","9923be5815abbd5c43911a57dbe53a8d2a1c64a7","cde6fa76e1842e1a9058e676d05c6a031982a3bd","7826b897e3ca7ab53d8a4c6f5355515572caf5b8","e655b67db8fafbd8e65a65fa70075290bd82a890","52cfd33fba03c6cb5d2c3ae45fb5ac6d1cc297f9","a50dab835002134d30359a1d7cdd3a00c0352439","2e58be74233cc4f1354f9b4ddcbb062c60452aea","e062e50e9d7d03e48bb2a58de31b708fa8839c66","0049c0542c102ae11aa5914fc8df0f384dcc3e73","8979bdafefff9da97342fbc5cf3f511000306f60","4713a6bea2d6e55c0a88e90fa0b25f60a4e6faf3","e2db226839a79ca0d6e7f74740963f8b02b54734"],"journalName":"The annals of applied statistics","paperAbstract":"New advances in nano sciences open the door for scientists to study biological processes on a microscopic molecule-by-molecule basis. Recent single-molecule biophysical experiments on enzyme systems, in particular, reveal that enzyme molecules behave fundamentally differently from what classical model predicts. A stochastic network model was previously proposed to explain the experimental discovery. This paper conducts detailed theoretical and data analyses of the stochastic network model, focusing on the correlation structure of the successive reaction times of a single enzyme molecule. We investigate the correlation of experimental fluorescence intensity and the correlation of enzymatic reaction times, and examine the role of substrate concentration in enzymatic reactions. Our study shows that the stochastic network model is capable of explaining the experimental data in depth.","inCitations":["572f6ed221d042b2e652bae5e8c06df269bf88a5","00f4aa92d88e6ca292148dcae5b893ba3532c76a","13dd506e224761c33456e21154b596f69177662c","797dc1c866f291751cfd69803d2783135e35bbeb","140d2ced01b4729601f8cf1dec3c98f5f2959d0d","3db9d57f92a2059965e20b78759f26d3d07d2968","c06d157acb6a42b8755ec1c8f63e55e89fe035ca"],"title":"Correlation Analysis of Enzymatic Reaction of a Single Protein Molecule.","doi":"10.1214/12-AOAS541"}
{"fieldsOfStudy":["Computer Science","Mathematics","Medicine"],"year":2011,"outCitations":["956d43b30629e6be5e8f2c4edb4cea2404598eff","80db408970c1b8d4ebb664ac313bf5c452f95671","5f2199e859148f6084ab23d19381b4cc45dbcd12","66610a8a0a94c994175cd70c9dde9240c9f3d841","891f42dbae454267f83bcf702669a3d66aaf3568","c49e2bb02df708c7574382774b0665ee2e7fe703","230e257f388b0f3e9b29bc6171cc219c1628786d","f3a8c13b65ab33c78611c678d222ab368d138079","eb1068f5ead075e4e264007f945384885799567c","27ae01b74d54035c28abff93b7e0dd0382139acf","0393a8fb77e5e6a40d2958bab55e3ba0b947e391","dc7c1e485aafe150a8b3048e6c0c027b0ba05c6f","4ba3a815e5f6dd5e0a359422101bc301f7228afb","4573c4a1cba1e37bb88aae38017567bdb60962d7","975dad53de606768df5772d143d949a7dc0cdcb4","34b55fa9b0b0c2040be71fd55e78a36f51ab6005","7bfb4c94877a63d65ff77dfe2455662367df4b12","5a8f3e18746965a1cff97c74fb8c496eeecf927d","b3e1705716a12a2cea281dbd4bab6aa13b6d8b87","714a4e93563f7470a75a95ff0738492d5b46a451","b0b0c7bd956609f5b95722a8597d1107e74945e4","f6751c74e31b4ff675405a8136c05132ecce1f73","684291a5f866be7f4a646d5d5fef46bb1703f468","0a7c6b5bf035199b2054d8822b6e36534022b664","8109e9601e905e49d22e6f3379fa6a035d718001","dde637fb1bd82b3c98f5e45a278986825e9bd750","6c7c89ca96063f3c5247e78f8a2f21f4c52966a8","7a2091603131a161725704c722041b464d796644","a84938515479411a5e68621dc8bdeab0cec7c09c","4ba2b8d4300c29d9540304d753dcd344000ad8aa","62662f043dc3e86f61a3d77fa00ebd4d660e9624","6c0ec79c977542c9a61192037a1fda7066e2b6cd","3c02c434d09701bbdaf6b173a2ac9c8e4a93f8d3"],"journalName":"Journal of multivariate analysis","paperAbstract":"High dimensional data routinely arises in image analysis, genetic experiments, network analysis, and various other research areas. Many such datasets do not correspond to well-studied probability distributions, and in several applications the data-cloud prominently displays non-symmetric and non-convex shape features. We propose using spatial quantiles and their generalizations, in particular, the projection quantile, for describing, analyzing and conducting inference with multivariate data. Minimal assumptions are made about the nature and shape characteristics of the underlying probability distribution, and we do not require the sample size to be as high as the data-dimension. We present theoretical properties of the generalized spatial quantiles, and an algorithm to compute them quickly. Our quantiles may be used to obtain multidimensional confidence or credible regions that are not required to conform to a pre-determined shape. We also propose a new notion of multidimensional order statistics, which may be used to obtain multidimensional outliers. Many of the features revealed using a generalized spatial quantile-based analysis would be missed if the data was shoehorned into a well-known probabilistic configuration.","inCitations":["75b5dc443bb07f4af70c7b4849a122ce2ef167b3","d07ea9ce97101f9469c2214231011a4ca4332e28","1872516d6fe35383348428b962240418c2e65d18","616d6a497fe855a1fb65a22f8377396ab813ab2e","4031c44f7503efd89b90c816fbabd43cf4f1fd65","f0d19d9fb27d3568d0a7d83b4d6f4e23a075341e"],"title":"High dimensional data analysis using multivariate generalized spatial quantiles","doi":"10.1016/j.jmva.2010.12.002"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2005,"outCitations":[],"journalName":"The British journal of mathematical and statistical psychology","paperAbstract":"A method for examining invariance in maximal reliability for weighted combinations of congeneric measures is described. The approach is developed within the framework of covariance structure modelling and allows one to ascertain whether a multi-component instrument consisting of homogeneous measures is associated with the same minimal relative error variance in distinct populations or over time. The procedure yields as a by-product an interval measure of discrepancy in maximal reliability across independent groups or assessment occasions, and is illustrated with two examples.","inCitations":["fda6a241c8be670ad65726477082959ee85d0b26","8e8f4030c05c9ec71b875cc42551ac36209a0db4"],"title":"Studying group and time invariance in maximal reliability for multiple-component measuring instruments via covariance structure modelling.","doi":"10.1348/000711005X38591"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2006,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"This article addresses the problem of heterogeneity among various studies to be combined in a meta-analysis. We adopt quasi-empirical Bayes methodology to predict the odds ratios for each study. As a result, the predicted odds ratios are pulled toward the estimated common odds ratio of the various studies under consideration. With strong heterogeneity among the studies, we jointly consider the display of the 95% CIs of the ORs and a Dixon's test (1950) for \"outliers\" to exclude the \"extreme\" estimated ORs. We demonstrate the effectiveness of our methodology based on the data analyzed by Thompson and Pocock (1987) demonstrating the power of the new approach to meta-analysis to find statistical agreement in what looks like great disagreement via a chi-squared test. We believe our technique (i.e., minimum mean-square sense) will go a long way toward increasing the trustworthiness of meta-analysis.","inCitations":["518edf0b5b2fcee119ad516e84cf9675f49c0dc3"],"title":"Quasi-empirical Bayes methodology for improving meta-analysis.","doi":"10.1080/10543400500406553"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2019,"outCitations":["c68b48655a546fe57b92f802b6ad0e73846756b3","62849bf24a758f0ff7f6ca4325f8e11c396ec9af","d7a6e728e7f31cfac096acc0855bd545fe0cfa09","42c908a37c1e40c4ad0bbe5fb0d010d236a303ef","a0358353000681f94b6f7bc65272579ef3c9142b","0e00b8e08ccccb1a33ff48f8fa767472a3bfad50","2018575a1a33bbb85f3dd7466e6a7bb0561b4e20","e4152143ef0ea4eca3b2d09815cd1f11f09b66aa","1924ce442417e296b09233e2a27334ba67485588","c3ade5ca2ba2181d950860e617c16028869d0595","aa81450b8811debc658dd589081f73ba21306433","dcf6bee2827bb1daa02cc96237aa40b54fb2f306","62aa0a2a0e0251e80aeb52e7c563d5139b554c68","f77b9f9de983ca24076df9d6953677337a57c424","591315bfc5260248616f149edc0f4e4be0e876a6","63a4f8ec37d4763ed3b12b304e44b0a281fe51ad","9a607a3bfd9432a917f703d573fdaa1052647711","c093f9334438e0192c8aee9cc2a490eb4e081798","0ca489c9f3f9842779a585ea88657171a934bc9a","36dcd28a2e5c959b5f32a535168f6ea51102b026","aa29f08d5160469b626e4db503d9265f4e1c287e","d8f0c1bcb6c5afa8cbfe83199b55c014dca08802","e791c15b26a99e65e118b3bc2f4332d997e0a838","5c49d41731f94579dae138f23eacbaffdf178471","daf5e276f63d0c1a999dea2474226670c08cc95b"],"journalName":"Biostatistics","paperAbstract":"When the primary outcome is difficult to collect, a surrogate endpoint is typically used as a substitute. It is possible that for every individual, the treatment has a positive effect on the surrogate, and the surrogate has a positive effect on the primary outcome, but for some individuals, the treatment has a negative effect on the primary outcome. For example, a treatment may be substantially effective in preventing the stroke for everyone, and lowering the risk of stroke is universally beneficial for life expectancy; however, the treatment may still cause death for some individuals. We define such paradoxical phenomenon as the individual surrogate paradox. The individual surrogate paradox is proposed to capture the treatment effect heterogeneity, which is unable to be described by either the surrogate paradox based on average causal effect or that based on distributional causal effect. We investigate the existing surrogate criteria in terms of whether the individual surrogate paradox could manifest. We find that only the strong binary surrogate can avoid such paradox without additional assumptions. Utilizing the sharp bounds, we propose novel criteria to exclude the individual surrogate paradox. Our methods are illustrated in an application to determine the effect of the intensive glycemia on the risk of development or progression of diabetic retinopathy.","inCitations":["5d733eab3705af743e9a64368591c06bd93cbe35"],"title":"On the individual surrogate paradox.","doi":"10.1093/biostatistics/kxz019"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2005,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"Many important clinical trial endpoints are measured on an ordered categorical scale. These include objective tumor response in oncology trials, the Thombolysis in Myocardial Infarction (TIMI) flow in cardiovascular trials, and the American College of Radiology (A CR) criterion in rheumatology trials. A common tendency among researchers is to simplify the ordered outcomes and collapse the data into a 2 x 2 contingency table in order to perform simpler statistical tests, such as the chi-square test or Fisher's exact test. Recently, more appropriate approaches, such as adaptive tests, have been developed for the analysis of ordered categorical endpoints. Each test in the adaptive class of tests is exact and balances good global power with nearly optimal power to detect a specific alternative of most interest. Prior knowledge of the direction of the treatment effect and the level of confidence in this prior information can be used to select a specific test from this class. However, little guidance has been offered regarding the selection of adaptive parameters when prior information is available. The purpose of this paper is to fill this gap by offering an objective approach for parameter selection, and to provide real data examples to illustrate the use of this objective approach.","inCitations":["47c97676c063153def7a6d561454638be9c467fd","f96d74f3c42ff5057035a26575278f8585d72556"],"title":"Analysis of trichotomous pharmaceutical endpoints.","doi":"10.1081/BIP-200062295"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2016,"outCitations":["8bb843b4f274d77c60944e5ac7365a2f36d76c7d","58db9852fedd50a4732e3c174383710422c32ecc","10b6bf1f08cdf768030f27ab0c22bb768eda82cd","5695999bf45467725111ec8174304ef434f4ce65","ca1f3157fd5269224cca948f3b9f098e7c0bb473","79c7d6903e12e1b45bb3f8bc6ca862fed92b06ea","5f0d051ffcbde45f92daee6395883cd476777ad9","b8db0ca28c530dd0d0671af5d1a1c238a5a03fee","aed3e2b26aa6691b81be531e0e9e3c64854e137d","13f4cf274509ae66ce71935828eb98ebdfdae66a","b365b8e45b7d81f081de44ac8f9eadf9144f3ca5","a593eb24ec9dd90a6107b8e696d2cf95752d573a","2a4a3c9b6aac9733e11c8860a5be1f2d32a617bd","865b1607a955f9fca1b46425a4c10e8fa79e3397","7b4b6a3b9d19a1f57033d8642ca7b9ac97e94263","c3620866f75cf4d2cd498abc91b598ae1ddd1300","e57ecbbeecb9bce4610661542168f24bc45bab0b","2c83124c091a7b1b40eab6a980178b0fa8913caf","9529c25408dc86194d417aed73d49ae0e418f1be","3c335edf9b7d59eddb3c1cc0c0e5b7ad84d3c948","2888f87e01c7adfd95f02c52339a7db8ad329677","fe96483ba3f34ca4565e81a5cb130f66c02cf681","7cd1619370c1ab9b68acbb05d91b6562c78ed8a8","33a3b064e3e0464f8e8d534abf70aefa54623e75","4661a7d38647b36dc90957462a31a1c3d6af6dae","8dc764799971b9e1d63c5d37905f810ae01512bf","bf67c1229b3d8dde001fee1388e3bbb2220af72f","dc5b06753fac11268bc2300b7c25d50cbbcdeb5c","21b6c1b4a61d4d2ecbcdccea88b1e290648c08cf","ef1bf316ce572888268aba556d8534768e8c816a","6410ec306cfec30aa85d2172ac9eba1ef5bea4cc","e952633c79cf88bfcebdee83ab2fd81b7430a482","afa65a3c7d08ba31ee00c576c3b36456ffaf735e","62269cfcfd08541926d78a5c5a0d703b26e189c1","46be236b6c3896aea3866672bb4606496694fc77","fcef2258a963f3d3984a486185ddc4349c43aa35","757e8720086c31fc88ba514b19269111f608e398","821c6660965ab4925d49aebffb40fd831b23a3f6"],"journalName":"Journal of econometrics","paperAbstract":"In linear regression models with high dimensional data, the classical z-test (or t-test) for testing the significance of each single regression coefficient is no longer applicable. This is mainly because the number of covariates exceeds the sample size. In this paper, we propose a simple and novel alternative by introducing the Correlated Predictors Screening (CPS) method to control for predictors that are highly correlated with the target covariate. Accordingly, the classical ordinary least squares approach can be employed to estimate the regression coefficient associated with the target covariate. In addition, we demonstrate that the resulting estimator is consistent and asymptotically normal even if the random errors are heteroscedastic. This enables us to apply the z-test to assess the significance of each covariate. Based on the p-value obtained from testing the significance of each covariate, we further conduct multiple hypothesis testing by controlling the false discovery rate at the nominal level. Then, we show that the multiple hypothesis testing achieves consistent model selection. Simulation studies and empirical examples are presented to illustrate the finite sample performance and the usefulness of the proposed method, respectively.","inCitations":["8cd516949697c62d8b3a75e34432b2172477ef8e","866fdd033f75a825bd2d65a4075052a24653966e","f20e52da83cec973c551f68ad1a772c2424bb962","75e2a3d28907620d97d8619d0af13f76e512b3ce","0d54f5f642a346aa678491e4739055124c0dc44a","59d635498682ba01281f3cfde4ed676a6148252d","c0ad0edb3cc042e3061003ad8a62d59abb9274e8","fa7c6124e70dbd6017a43c045adee1763aa36aac","3b8bd3205317f3444255d0e189c149183d79e8c8"],"title":"Testing a single regression coefficient in high dimensional linear models.","doi":"10.1016/j.jeconom.2016.05.016"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2016,"outCitations":["3e14e8f7b70fd1b4f3c56455cc514ef7c7f572b5","05ab43b91321e8cf57a42614dd630baecd110bd0","77be977da1d2eb51ff8f21b5af12ed33b989c917","e4f8536b067127e5269316832a4733def51c399a","779c5bede5f8c3748fd64f2952d2b8e0c2b5e83e","442290e802b01880991fef67e892d7ca87520692","20ee888ca9c3bae784f266405b4d6395c6f32955","eba49f4e6256f44fb6a2fab5ee95519e9a9fb49f","91a95bf76f977328f95bf7e88ab7669ca29f96f1","9a3edc623b5ffa7522ed8f37c01ce4b5125002ad","5f56320c5979faeab78dbd9ddb7db755ba4550f3","7b4b6a3b9d19a1f57033d8642ca7b9ac97e94263","6cf6580f0459bc6e341567e37ebc6ed273f7f60d","ce146144960cd77921bafe062c1ea4a9318600df","80d5869f211be1fc2252647549942ba418521e59","a35d565e8f70cb6ddc09a65904a72622e16b9485","4a545f9750f73b155dfb72b71ef8efcc9033e112","d06798476ae907160dc4ec6b88be466fdcdb8b6d","37b573e791a5e41ef3b59e6f68f58a8cbe9f8cdf","522240ecb53868e9af763ada4b15dcb76f5f366f","b365b8e45b7d81f081de44ac8f9eadf9144f3ca5","6e436b11eab90258229643cd47861f430f00080c","c7cb4ab6226ffb5220ae1d9d6ab7552d7bea2e0a","5bb4c0f83877dc2485ab99120bd4a94780a8a17b","9ea95d38e5b5a0bd8ef95184a95c29265a6d87e9","ea392e0cd29474bf10ab2f6d5afe75da1ea28f39","19f90a8c59b2b5924debf81fc38c53f2f445b236","95d6ff6279fa0f92df6fae0e6bd4c259acfc8f09","6d7e6c10aa858a45ee1e01a6340aa2e111a8c71b","ed796d7626d70749afb0bf713429198f74c8f3df","dc5b06753fac11268bc2300b7c25d50cbbcdeb5c","398ff09f1ef9fdc1d70f59eeb744f06c06998528","83cd164f2df27f57e1e059c2a227e8912e8616ab"],"journalName":"Electronic journal of statistics","paperAbstract":"We introduce a general framework for estimation of inverse covariance, or precision, matrices from heterogeneous populations. The proposed framework uses a Laplacian shrinkage penalty to encourage similarity among estimates from disparate, but related, subpopulations, while allowing for differences among matrices. We propose an efficient alternating direction method of multipliers (ADMM) algorithm for parameter estimation, as well as its extension for faster computation in high dimensions by thresholding the empirical covariance matrix to identify the joint block diagonal structure in the estimated precision matrices. We establish both variable selection and norm consistency of the proposed estimator for distributions with exponential or polynomial tails. Further, to extend the applicability of the method to the settings with unknown populations structure, we propose a Laplacian penalty based on hierarchical clustering, and discuss conditions under which this data-driven choice results in consistent estimation of precision matrices in heterogenous populations. Extensive numerical studies and applications to gene expression data from subtypes of cancer with distinct clinical outcomes indicate the potential advantages of the proposed method over existing approaches.","inCitations":["f59561c65c03d2751a949c94329a1e4207c2d7a2","eebf3bf95a1bc2411a15720fb0c4cc0584a1fc77","06186400a108dcb6ede55f1184619ff5a8999e74","1ff73da2c28dc2b028a4f0d53db66d2d35ba8a3b","3f9b4902af87ca379dac49ff07f4d16d53822103","a4457a77954b23e09f7b67bb06e205dc7b56e909","bd28e6148efe8af711cd0d10746d10a998da92ff","9852b06a19a86a48f13ac228e829aed2f1538f07","0b9975b284e8f9a6e0226b779b6ed28a931bc697","9183efd38147c851d9c143c8d559f4b2a2177ab7","f59a08be36c8ed859fc419824cb51065d549189a","20df179ac839b14f112c2337240bed675bb1b6f3","600859d3b4b993f38ad4c0eed5646310f3743aa0","cf6c92bcc9c41055efaf936e4d32f7e9cc0e68c0","0c06505aa991c5db9bea3c315bdd42999a41124a","041dcde980da15a2dfa37811c5be2f833dcb7ea5","aab04f8e303505557812994f56424b5ccc30cd74"],"title":"Joint Estimation of Precision Matrices in Heterogeneous Populations.","doi":"10.1214/16-EJS1137"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2003,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"In studies on the effectiveness of barrier method contraceptives, researchers need to estimate the risk of pregnancy during consistent use of these methods. However, participants may not use assigned methods consistently, and only consistent-use cycles are included in the estimates. Inconsistent-use cycles are considered missing intervals, and a subject's early discontinuation from the study or pregnancy during inconsistent use is censored from the analysis. In this article, we consider a semiparametric maximum likelihood approach to estimate survival probability for grouped survival data with missing and censored data. The method is flexible in that it is nonparametric with respect to the underlying survival function, yet it can be easily extended to accommodate the covariates in a parametric way. Results from our simulation study show that the proposed method works well in practical sample sizes. Our findings support the U.S. Food and Drug Administration's (FDA) sample size requirements for contraceptive studies. We use data from an effectiveness trial on vaginal contraceptive film (VCF) to illustrate the proposed methods.","inCitations":["b2d5f714d9f0be1612475ad902cc9e9113f72a19"],"title":"Estimating cycle pregnancy probability with incomplete data in contraceptive studies.","doi":"10.1081/BIP-120022770"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2014,"outCitations":["c505e9384d252503ba78953d8382d81414de67ca","edf811c41d0499b696ec5746fbe2106822739251","9847e37ebc9da1542bc398e2e664cd333e58a4e6","bdfb57141b2141095ed942b28be24808aeba8d54","d95f874b9b57453861a3e205c2db6b62ef4bb3d9","624e52c68c9b54ecd87896a66a69445213bf64db","def61683190a7dca6f68f66b47186f092760ed7f","f6360fed53d10faf1b88ff686535527a2becd7c0","1b7b8b8a417253dd238698b489e07f46f0be0d11","869e99037469fa9caa7b62e913b689812e6767e5","a8e4cac0883f378483e9e231e54d8f733a21a2f9","2515f2200ac48791e5a75c7bd6954c083b202098","0c85dc4d20a3d8bf6c545f390baaafdad35facb9","92acf969a2fa3f68a0cc27d9eec89ef16bf6f9a8","8f8a40d577ab28a8e98b6f370fd8098ca9dfdaa1","c42e50e97e1b9b98cccb3747f85c0072167b39f2","f40c9ee43c46151a4be6c9bed20c51e5cdad4fa6","f20efdd234991e6b84388f024866251afed02a36","20c5700e25710544c50ab1112c499c2071c6bb05","7d511431fdb6cf8f2e7579f76b5f9017df556ba6"],"journalName":"The annals of applied statistics","paperAbstract":"We develop a novel peak detection algorithm for the analysis of comprehensive two-dimensional gas chromatography time-of-flight mass spectrometry (GC×GC-TOF MS) data using normal-exponential-Bernoulli (NEB) and mixture probability models. The algorithm first performs baseline correction and denoising simultaneously using the NEB model, which also defines peak regions. Peaks are then picked using a mixture of probability distribution to deal with the co-eluting peaks. Peak merging is further carried out based on the mass spectral similarities among the peaks within the same peak group. The algorithm is evaluated using experimental data to study the effect of different cut-offs of the conditional Bayes factors and the effect of different mixture models including Poisson, truncated Gaussian, Gaussian, Gamma, and exponentially modified Gaussian (EMG) distributions, and the optimal version is introduced using a trial-and-error approach. We then compare the new algorithm with two existing algorithms in terms of compound identification. Data analysis shows that the developed algorithm can detect the peaks with lower false discovery rates than the existing algorithms, and a less complicated peak picking model is a promising alternative to the more complicated and widely used EMG mixture models.","inCitations":["6b6038c58f68ed2b4c2249db9c5afbfd11ce0e88","6e9fb686ab73e017492492487531d6c032d0f467"],"title":"A New Method of Peak Detection for Analysis of Comprehensive Two-dimensional Gas Chromatography Mass Spectrometry Data.","doi":"10.1214/14-AOAS731"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":1994,"outCitations":[],"journalName":"The British journal of mathematical and statistical psychology","paperAbstract":"The asymptotically distribution-free (ADF) test statistic for covariance structure analysis (CSA) has been reported to perform very poorly in simulation studies, i.e. it leads to inaccurate decisions regarding the adequacy of models of psychological processes. It is shown in the present study that the poor performance of the ADF test statistic is due to inadequate estimation of the weight matrix (W = gamma -1), which is a critical quantity in the ADF theory. Bootstrap procedures based on Hall's bias reduction perspective are proposed to correct the ADF test statistic. It is shown that the bootstrap correction of additive bias on the ADF test statistic yields the desired tail behaviour as the sample size reaches 500 for a 15-variable-3-factor confirmatory factor-analytic model, even if the distribution of the observed variables is not multivariate normal and the latent factors are dependent. These results help to revive the ADF theory in CSA.","inCitations":["689cca5b1c131a4ce796bded64d19ff03b53e136","912d8d802f5c1db2ee01eb5306b13f4cda8c45d8","b3e2caad719c9f129419355c55376e9fe41105f0","f88b447b1bc69c44e16751e62d5200addb43e64d","65121e1372f9fdef7dc13f2fc5c719e941842944","8cf862bba854f5fa9f628276fdd50c2c1c37b26d","db5942456d12909877d62cc971395bab251d31e0","28e95b4eb27f662ec8d4078ed39115a617deef48","fe68a6257bd1a95e8203eefb9471c0e5ff095050","313cf49878fba8a62003638a7f3b7db77b9d1de7","51a75449ae2543e661f058bd16e1b954989c2273","3fe222956447ed16ffc124e3192caefc5ca34b49","aad7fac4c8c78da4e115bbd01d7ea3448c38afbf","3ba776fb18be1c58d4d0d954d0d29516bd7c825b","dbe9a0d69de46b1e8435f2d7993333ffcd5d8d77","9d6a2510e61e0b8c1b680cb5eea189cbb8f062d7","0ad26b78b388a77495f4177857ecba791d833305","24f6606b3ffc005308dc7a96bd6bf7314f27c98c","260cf9d45e9105c953a017bba76ca56edf87987c","3a10a05afabe82648c47fbb81e84f9818b7fc685","ce7509167fa9b9de541d4fd581cb818a04573168","4712cb9bcd332214e3252c87dc0226084192c22e","69430b4a91204824bf27d009df89fea4533fd3e3","aaadcbf6ceab4d4cc0cac73dfdee4b8bbac16f1c","d041be86eefa4ef1b6c42a0858bc1286f61b44bc","c419f1663c0d1020f805a4eb7ed84bab37dfc350","08c25ebfed1044ce836da3b22c031395f80e0c95","097bff9d384301035dbb47be1692b325bb56da7a","ef639631f66e1e685973271f0eafd0984a34783d","b697fdf87dc0d5c2804f5de07e0bae4d8ddef1a2","d4eb3134ac16c9e4c0b6e9739441bb24c3e808d3","17745641b3d407a5a8d45d69802c704607a8aafd","2f0f7c174da739fbd80801aa23b621060cf4b370","fa69d5970e3220f76bec8208ebaeb8d77679e369","03cf862e79206c6b63bc41740ea88049a28215cd","9f0b86c2b37655132e582269009bef57b52ca1c8","1769177d3ca5cfff0011613519c74e49ff3ec6b3","fe46b16dbf8ad32dd3275c84796f5ec2b3c3be3f","bedd56d3840a1a3e8c2f1ac04d58d17a6f7bc023","b523822297166ea8a2a15feef361059af1a59f0b","ee6c0d96339a8dab48be3375bba29cc2655de611","c776a38c9f6f602935d376ecce4f775ad9cb792a","5ad7847d86822d2f8fdfd83bd62ff02174fcf076","c7273f1d97d3199c563a00b0ede9428015a97934","969aac5c712b9908f4cf2d5ba0d09280b3800b81"],"title":"Bootstrap-corrected ADF test statistics in covariance structure analysis.","doi":"10.1111/j.2044-8317.1994.tb01025.x"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2014,"outCitations":["2e518008e3f0ce35384cf2444dfd62f4f1026bfe"],"journalName":"Pharmaceutical statistics","paperAbstract":"The book is a summary of multiple testing in pharmaceutical clinical trials, covering a broad range of topics from multiple testing in dose-finding studies, adaptive designed studies and microarray experiments to discussing the regulatory issues and modern multiplicity procedures such as gatekeeping. It is aimed predominantly at biostatisticians working in preclinical and clinical trials. The book consists of seven chapters. Each chapter starts with an introduction to the multiple testing issues, followed by a theoretical description of the available statistical techniques and examples. However, the book does not cover all areas of multiplicity faced by a clinical trial biostatisticians, such as pharmacokinetic/pharmacodynamic modelling, and Bayesian theory is not considered. Chapter 1 begins the book with a summary of multiplicity problems from a regulatory perspective. The chapter is written by two influential regulatory statisticians from the European and FDA regulatory environments and provides a broad overview of the different areas where multiplicity issues may arise. The chapter covers the regulatory issues with regard to multiple endpoints, multiple dose comparisons, subgroups and multiplicity concerns in special situations. It also provides some methods for reducing the multiplicity within clinical trials, such as using hierarchical ordering and composite endpoints, and mentions situations where adjustment is not considered necessary. Chapter 2 provides the theoretical foundation for the rest of the book. The authors begin with introducing the different error rates, including the definition and importance of the family-wise error rate. The authors go on to explain popular multiple testing principles (union-intersection and intersection-union testing, and the closure and partitioning principles), followed by clear explanations (with examples) of commonly used approaches to multiple testing, such as procedures based on univariate p-values (e.g. Bonferroni, Fallback and Hochberg), parametric testing procedures (e.g. Dunnett procedures) and resampling-based procedures. Chapter 3 gives an overview of multiple testing problems in dose-finding studies and how trend tests are used for the detection of dose–response signals. The authors also provide definitions for the minimum effective and maximum safe doses and how they are estimated. Power and sample size calculations are also included in the chapter for the maximum safe dose estimation. Finally, the authors explain model-based methods that can be used to estimate an adequate dose to achieve a desired response. Chapter 4 continues the principles and procedures introduced in Chapter 2, covering different methods for adjusting for multiple endpoints. There is a lot of repetition within the ‘at-least-one’ procedures section and the contents of Chapter 2, which is noticeable when reading the book in order, but does allow for the two chapters to be stand-alone. As well as at-least-one procedures, the chapter includes global procedures for assessing the overall efficacy of a treatment, ‘all-or-none’ procedures and the superiority-noninferiority approach. Chapter 5 focuses on gatekeeping procedures, which offer a more flexible hierarchical structure than the fixed-sequence procedure (introduced in Chapter 2). The authors walk the reader through serial, parallel and tree gatekeeping procedures, using worked (easy to understand) examples along the way. The chapter could be improved by discussing the graphical approach published by Bretz et al. [1] when explaining implementing gatekeeping procedures. Chapter 6 starts with a review of the design and analysis of adaptive trials and the multiplicity issues that can arise above those already present in fixed design trials. Repeated hypothesis testing at interim analyses and sample size adjustment (both in a blinded and unblinded setting) are reviewed, including discussion on stopping boundaries and formulae for updating the sample size. The authors discuss applications of the closure procedure to adaptive designs based on combination tests and conditional error rates, which allow trial design modifications based on unblinded interim data. The chapter finishes with a description of two case studies based on adaptive treatment selection and subgroup selection at an interim analysis. The final chapter covers the design and analysis of microarray experiments for pharmacogenomics. The chapter starts with a clear overview of microarrays and introduces the two stages of pharmacogenetic development. The introduction is easy to understand, even for readers lacking experience in the field. The multiplicity concerns around individual biomarkers and subgroups are then discussed, along with the control of multiple error rates (not just the family-wise error rate). The design of pharmacogenomic studies is demonstrated with the use of a case study. In conclusion, the book is well written and covers a wide range of clinical trial settings in which multiple testing issues arise. Descriptions of the procedures are supported with clinical trial-related examples, with many of the chapters providing guidance into the implementation in commonly used software applications (SAS and R), making the book a useful tool for biostatisticians dealing with multiple testing problems in clinical trials. Each chapter begins with an overview of the multiple testing issues faced within different clinical trial settings, which may be of interest to clinical trial practitioners. However, with the","inCitations":["8be03728b323626226d6efb0d2f9fc33ca0d482c","7f6396b291d713aabb413ca0a7a09f3aac86214a"],"title":"Multiple testing problems in pharmaceutical statistics.","doi":"10.1002/pst.1610"}
{"fieldsOfStudy":["Computer Science","Medicine"],"year":2014,"outCitations":["50202e06d78e6090c9b8d0ccc4d4f189abd766cf","e130f86e996c784b0fc2134041ea1afbf36b6002","0e13aa51d0249495adea2f84a9b7f260f61b9b89","6cb52a446be852ad148e5518e380eefb71a61fe2","e953aa0fdbdd44a8cbd4271b5c708d39729ed14b","269688bee08e2a61b7350806304a6654ba90d730","9c574b4f5abf5b2224852ee2a285b09c9151985c","487a65b5e4e1c0e2dc5e5de898891053d208017a","00206d61c06a95c97430b76fd2902da571c4e174","ebf600cb896bacca7b56d4a796c68598bc8ec3b8","b3a5da9af130d66873355514932d6cf508e9080d","6ae9e0603007cd002f6afead7029bed9b2b3a002","6d2e0be460e0e3b2b74ec8260d886b2397f8f320","ef61e549904229f3c8350bb31560c67cef21c3ef","77ccc742456a14bc70208f84aa3bae35fb67950e","00cce17fec8074e35d797c937b32452348237d8f","e60f3c1cb857daa3233f2c5b17b6f111ff86698c","11042025bcbe94cc630f3c814989c32241141a4c","686261e8a8c91c760a10747b49090ee55597aca6","cb2c2696a89d7a67cad87b74ec91310278fc384a","9415482c3bef23d0c7611f62b5581928d7a5b792","66ce37a0007557e31ef4c8acdd87f4f4a045829e","f913bda6d242bb968a68b19daaf4206913df5c8b","70556fb317475a35de14080e087317a82a326fff","03e3781ffbee1eacd88c2e4623d83e82632b1896","b26be44b7e9c49615a33fe6f7d32faca2cd8e49c","cc6abe57629afd0284d4e0882aa2cdbc7d6b90a1","45ee7447b9dd406496c4a5d9d8fb6556366a01c6","307d4f561831d98246c91424b84ff90f81b964eb","20a36abf3dcead76ce7234d92079486203f5cd40","9bf9b87f11dafc4f1faf58ef823fc8f31f86e585","b143e6dec33677ff29e5eb5e62bde80a458aaa6b","9ce15a5153bf69e23b711ab3baaa25b24a63ea2b","cec881ba85bdef2d218f3f9dbd5dba65f7bea244","f540679fb2d2f962ed18a418ec02d5b5ec2b4a7f","0f97bab3b4a07f2a598ba1397a553e047374acc7","cbc908aa39ae87a571f694d181c1dedf57b1ce88","a38e5c51ad3ad475b7cef46afb77cc75e1d4cb62","2edf95e2c4323783731c388b33ba79bb72faa5d8","47d20dc4f6eb2d2e01f03e3f7585c387faa45830","82c494785550ba5635074c3d3474510381bd7ac3","7037c59c33668a7a858aaa20acbdb882d4ebf602","59183f99d570e2888447a2496fa27ace3e7e6ce4","a20f0ce0616def7cc9a87446c228906cd5da093b","ff45297a6643f88389e8993229b1c27dfed93768","5bbbcb2988e0ef5171fadda83160db23bfe5829e","84956b93631269a9f382833ce6e68c78c61dd023","ab7cb404b71f3119ee47fef478c9f709a613f89f","13408589ae501df86a0207a496e1ea925d7a90f0","f19257ac730be56a293af5dfa742a40be4c97482","c88763faeebfc910a4720f339d8e07782fd396dd","4d508675ee414f4a8041a7270f63f3307ce50476","cc22d04377d75c35fd806620687143e7a120db5d","4d81a982911f1e0b31dbded3ee4e7631834b412b","ce9c927489496b72ee045acfdd0937d4b8bcff1c","3181f8d1dc8833a64caf144a657e661822b27a61","f921075fed8d1deb9e9a97dae13f2eab9f368af3","7f9562e6c2a9fc5bc0f4488cda85a704e83d3cd8","ccecdf227475db9be6f0fa8f431c1db51e9dcd83","d314f74b8dae9f066c1e9aa24a6874579baf0a47","3e51806c99640cbca726edd777a1d2cdf1e9667d","49ddbccf06ce8b1383df46d9fad5439f7bf47389","e078b805964bd72ee439f8e5fc50c9cda009a31c","47d062f0554881d5a9855474e2cbe502edeb12fe","3ae1cc3304d7dca4bb2f4ddb4089935c9a986949","dfdc72b8b600c46e01b459158c21c74dbe8958bf","eaf121b1d613a236e0ec41c13874a567823e8419","b0a4ffe7b6989eb57a5fe1d54ee5871b3d70b6ea","68097683e80c1efaf8bc9b82c8ac029656bbd196","dff24b4b3c88178607eac910fd21526d80423dad"],"journalName":"Electronic journal of statistics","paperAbstract":"Dynamic treatment regimes are of growing interest across the clinical sciences because these regimes provide one way to operationalize and thus inform sequential personalized clinical decision making. Formally, a dynamic treatment regime is a sequence of decision rules, one per stage of clinical intervention. Each decision rule maps up-to-date patient information to a recommended treatment. We briefly review a variety of approaches for using data to construct the decision rules. We then review a critical inferential challenge that results from nonregularity, which often arises in this area. In particular, nonregularity arises in inference for parameters in the optimal dynamic treatment regime; the asymptotic, limiting, distribution of estimators are sensitive to local perturbations. We propose and evaluate a locally consistent Adaptive Confidence Interval (ACI) for the parameters of the optimal dynamic treatment regime. We use data from the Adaptive Pharmacological and Behavioral Treatments for Children with ADHD Trial as an illustrative example. We conclude by highlighting and discussing emerging theoretical problems in this area.","inCitations":["fa14b07295b80a88833ff5281b2bb067ed44ecdc","a33d4bcfd3d4cdd48f766b3f57699ce07ce0514d","21eeb49b30a3a31ac764e31a3edcca2806c496fe","1336f54dc988f76282c853935396be435ad8204c","d290797a05041405bfd179c397e571cc3dba5374","8711d6b82a745ef50e948c3acf60959b24e699bf","f21ca73c36354f2fcf1b3d0fb283951c58f3c831","b1d33d8be5ec3d8a4c39938ed5c45f9dd976c841","59206c65ba8d8889fe4326654b162f8f18228a62","9ba6e7f676c270249aea38d105621e38bdee7e3b","6c359f5b04d348a4237a57ca5fa25d63cd0dcd44","41a04853a09d1d958e223eb5f8cbe9c648ef2532","975133e227d88432ca3cae400170c93ffdba603e","2b35cf0951c2d17d8ed8b805afbee9f89ee7caf5","3c1b605bb4daf3027bdcd1a2f47407cf1be7ca96","43ef6f75c7b0aaf61cbebf7796041bacc27a4b34","cc5df26f67e90632e4bd1388e96760a3d168ba22","0e739d92688a413b0eeb693817543372bd4acc7e","eedaf1f12c7e18cf3d5d9ea46305cddb9f485c82","2db12c9f2056aba0e660f547340f7551ab84402d","58b4f1104fe4ead1badafa6bf751af678b94961c","1001ca294f6a9124aa548b532bc3bc550964635a","e0cad0c76d169facddf1074f8182af3030952a57","db0c1b316aa03b1bcc0be9698dae97243b685a5e","0482e4c276e31c003b9e8ea1c35ab6c8ee66e3c9","f35f6d46ce5e862665a96fef2f96671194c9f6d7","67623c8e72fcd48f0c8fa50c83f8672453b8dc49","3b3a6ca781d98d58d021f3762321904b8b7b974b","c2acf5489a27a870633b07bd559895546262ddeb","7aae7a2a68f59857cb9da8b7162e5c0a311b3cde","d78aba5c3593aa740983e5d09a88a373b7400f93","7cd0ff116044e00bfd6fb275aa701619a7916799","9c953423ca1bd7cf198afa0d78bad9092912c607","e071d484c5ea86187372d639689cd46248aa5d2d","a7eae0c584c761a150bd574f7a48237358fec785","917305b84383b3827cc6a0012a16238eb01fa474","729e30adced7986a80e19a6e0e9090631c7ec57d","222baa4e9e7ce691fdfddbc826a70e027daed70d","79c7788ceac3f43412ba163db995d80202c9ac4a","c162d2fd950ddd21754729cbd4b8bbab34897e10","fd0a23aef8bb1706d0835a836960d7cf0d21eadd","574e8ceee80a6907f1918c7e647325f74f5530e3","c6706c9084e870737fc415555c529c29bc5e188f","5d7bf26925300bc8a0c5857e835643545a7d339d","5248380a6ece676c23fb8eba3d747e72f8108033","d2be3c60850ff160ade6e240de85c5ba5e051edd","b5df55c24ef2773309a7306064da95b8e0083858","88c1c9c9f71c8cc8755aeeed15ddde43f274f8f7"],"title":"Dynamic treatment regimes: technical challenges and applications.","doi":"10.1214/14-EJS920"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":1995,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"Physiologically based pharmacokinetic (PBPK) models are now commonly used to predict the dose of toxic metabolites of chemical substances reaching target tissues. A typical PBPK model can involve 20 or more physiological, physiochemical, and biochemical parameters, each of which is estimated with some degree of error. In this article, methods for assessing the impact of uncertainty in the parameter values on prediction of tissue dose are proposed, along with methods for identifying those parameters to which predictions of tissue doses are most sensitive. Many of the model parameters are related to body weight, which is assumed to vary in accordance with a doubly truncated normal distribution. The application of the proposed methods is illustrated using a PBPK model for benzene.","inCitations":["9f70fec9196a2a0d949421be8a4f6736c716dcf3","3298f05ef162f83f1767102e859c8e857b96e481","15ff390084d65d961cb53f238546170c70e96803","e8299c8fc3e6c7dbcac031bd9ffb6aedf16ea24b","703a3f9dd43501bff4a460feeec94ed9fa41ffcb","6d0f2556e9c698691d717fdcf03bbf748ac910ff","a2e327301342a144a11b9549ca2b9dd23c077182","40b05f5afb7831d8956217893bac8bb1bd63c79e","fc99db727d42655e961694365ed78f1890a2b4a3","ffc4f4986ab590dd2fb5c89e9525f1a1efebc212","a341a03184ea8091b5b249dedb8f9cdc585eece4","f48f1ec4ed54e4ce02df4eee39bf98a6acbe8535","ff285396414ee1283ae4758cc1ca48bacdaaa663","31d8f0ddb0b2d1cab0ba142c088e5d2299b47ced","05e9b3eb5cf04eb47885c70f2412918b0526f63a","2e1f1b19fdc02e2a0ec89b9bb2322caf11f3727c","c504e9b6290fd04a376fc24e750d44c2c7f7a573","169f27f15f11be9f04ee7d793e756077a7d4d308","e252f3df6c2c3b81f63f523dde14a0bfc958d965","931085cdb4e0a9d25cf9eeecf1404bf4821f8ee2","b0e651d0ff9b9ab0ad19548a39f5c2a04d99a6cc","29983ac9034a9f81f51e61e4335acd715fbdeebc","c67b19f7ec41cd97106414527ab353374b312ee5"],"title":"Uncertainty, variability, and sensitivity analysis in physiological pharmacokinetic models.","doi":"10.1080/10543409508835112"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2012,"outCitations":["1d2674d7b57549eb51504e18a6977300070ab0f0","e631bf797c2e272ed33b693f6e33862fb614cc67","97abb89e17de203dea6ea5c2503c789114253276","6bb37b57586c9b7424c7952308d508c8d14be190","377339cd55087d503b855ae89d2126495cf104ee","0dd873118532dbfa6f67b4ad0a57b1f7800bd91d","096c93d22a619b356f9f1684498ecf8ff9bc366a","b165bb3b66411672f3d22fc17020057507d99a35","f45f963b7b967d526651937c0e5486c8448209cd","e45b74bf3ede47ff25dee775800d16cfdf01cfdc","1b6bba900c5b327d63d30e7f8247393f901d89db","53ee06aa31677c574934a24ce848fc5bc4d27fbb","63e144426a104601e964d96eee8124b3ec3a89c8","2175e9e6841185ce004eb7362266b1ab8462011a","a927ec50a86d9681aab8be5796fc2a958be146df","10a760acef54312ab7cde16f9de498f33aa94ec3","e1053197256c6c3c0631377ec23a3f7dc1cb4781","463d8514450b61b42be73b632bc206e200f24290","9b3e9850ca6c89ae53e130c23fcc0bdbba0eb447","29ff9ccc52119bc9c74f9b60a047fbf573e7c352","d182dc7da5991d98e7e633e30724f20bc7a5a21c","b7fd5d2258df1b2a11777d93c7d05e660007ccd5","d1ee10466731510b7ea29dd2f6d1bb6166d2c856","2123af11db503a40925585134d73274cdc92f914","ee78864a1429b08e471c1d74eaf49a6e3d9eee4b"],"journalName":"The annals of applied statistics","paperAbstract":"Studies of smoking behavior commonly use the time-line follow-back (TLFB) method, or periodic retrospective recall, to gather data on daily cigarette consumption. TLFB is considered adequate for identifying periods of abstinence and lapse but not for measurement of daily cigarette consumption, thanks to substantial recall and digit preference biases. With the development of the hand-held electronic diary (ED), it has become possible to collect cigarette consumption data using ecological momentary assessment (EMA), or the instantaneous recording of each cigarette as it is smoked. EMA data, because they do not rely on retrospective recall, are thought to more accurately measure cigarette consumption. In this article we present an analysis of consumption data collected simultaneously by both methods from 236 active smokers in the pre-quit phase of a smoking cessation study. We define a statistical model that describes the genesis of the TLFB records as a two-stage process of mis-remembering and rounding, including fixed and random effects at each stage. We use Bayesian methods to estimate the model, and we evaluate its adequacy by studying histograms of imputed values of the latent remembered cigarette count. Our analysis suggests that both mis-remembering and heaping contribute substantially to the distortion of self-reported cigarette counts. Higher nicotine dependence, white ethnicity and male sex are associated with greater remembered smoking given the EMA count. The model is potentially useful in other applications where it is desirable to understand the process by which subjects remember and report true observations.","inCitations":["de1b107508d948fed83a51e6978ce3b2f2017d56","589c2aef366cb6986f818e2dca24b361879a7d50","73996678a27a79306f189cf8d1b5af3961691816","670f4b0cc6700d8ed68be68e810908d57f3802f6","a53ca547c0d3e62792d9fefc93892fa15218e35b","625b2a2a8dae87b5a1d7355a6413b7297dc7f68e","b83348c842bc1bb6840ae39f7066b030095cb93e","f484abc2ebb02ea5f775303a70b649e93549cecc","90b338a73ea74555bb6d73b5597c58b7a88e0bc2","7b0703c1e3cafa307067e5b6df6dfb480b3652b0"],"title":"Truth and Memory: Linking Instantaneous and Retrospective Self-Reported Cigarette Consumption.","doi":"10.1214/12-AOAS557"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":1992,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"While a large portion of pharmaceutical stability data is known to follow an exponential model decay, linear modeling of this data for expiry estimation is the norm. Expiry predictions based on linear and exponential fits to stability data were made to estimate the bias due to the linear fitting. It was found that within the usual expiry limits on drug potency, the difference between the model fits is relatively trivial. In cases of loss of potency greater than 15%, small assay variability, or great disparity between the length of the study and the time of expiry prediction, however, there is a nontrivial difference in the predictions and the exponential model is preferable.","inCitations":["cee7e0dcad6318711e7763c29d2b98e222924f92"],"title":"A comparison of linear and exponential models for drug expiry estimation.","doi":"10.1080/10543409208835032"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2005,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"In testing multiple hypotheses, control of the familywise error rate is often considered. We develop a procedure called the \"fallback procedure\" to control the familywise error rate when multiple primary hypotheses are tested. With the fallback procedure, the Type I error rate (alpha) is partitioned among the various hypotheses of interest. Unlike the standard Bonferroni adjustment, however, testing hypotheses proceeds in an order determined a priori. As long as hypotheses are rejected, the Type I error rate can be accumulated, making tests of later hypotheses more powerful than under the Bonferroni procedure. Unlike the fixed sequence test, the fallback test allows consideration of all hypotheses even if one or more hypotheses are not rejected early in the process, thereby avoiding a common concern about the fixed sequence procedure. We develop properties of the fallback procedure, including control of the familywise error rate for an arbitrary number of hypotheses via illustrating the procedure as a closed testing procedure, as well as making the test more powerful via alpha exhaustion. We compare it to other procedures for controlling familywise error rates, finding that the fallback procedure is a viable alternative to the fixed sequence procedure when there is some doubt about the power for the first hypothesis. These results expand on the previously developed properties of the fallback procedure (Wiens, 2003). Several examples are discussed to illustrate the relative advantages of the fallback procedure.","inCitations":["749245bc20224e04a3b76b924ce4d5ea2c1795cd","626abb06891431a93c90c8d14c27e581cbd819ab","c93d397707e6386e297a3a130168085b9d0fa2aa","3a1d960bcd2ea887bf6caa889d30883cfaf95f1a","0f4ff4f1b6d60b754cda6eb9b082d83c1bf8831a","b30e5d2965013de8996bcf7d747048e774b114da","f193ed23cd44c1b7aeb2ee5d550693d7efe293d0","afdd5635cec5e186a458372bb8edee8122c6265a","decfecf3361939c06c44bfc240ef4d8617398892","066b36429d6d2a63303cc92185d93a20e463adc9","5e9ea3cd164e88cc2291d863de09c645d608a6cf","512614cd03f38e47ff84880b1d8122ba52c3cbc2","c18d34ddf5d5c87d4dce3b67a24aa757fbcb8db6","ff886b41816697fba82a98402566109b9e5587e4","9ddc221865f1dd90ab38ab633228eb6d2703679b","b2af5cb367cd5923ee94c37b0700d549e3e30237","df36a95d5b75889971eaf3f82bd6ea8f3a950f27","38b06f8ab0536a7e5966dc85d53ea24e4e56367d","8be03728b323626226d6efb0d2f9fc33ca0d482c","179d7b170048360a00877b55f9b8073ae1143009","612ec94d75ed5cab36196b56ccbc6140b942545b","681ea803d2cb7fd3be834725500c128a83d9f1d3","58893f770d212eb1080230a11bbab6674af0c8dc","c658930e46c5be74e29be60310cf8849829014a4","7f6396b291d713aabb413ca0a7a09f3aac86214a","fd02bb9d736477fe48569e0d09b3223432703071","7878d01516c5792e3fa9697c4d1eaf918602bec6","3a1c62946a1ca57fc0e96cb701e061614d347fa5","ffb20682723dcd13b49af89a5ada6b116a8d98a0","296bb6dee9f2b59fda82e5e4c52e8c2aee9233e2","944d174f82ef2cf003b8e0ca76e709c327d77327","a2a0146488ef0306ae91b63dbdb85b2decbecb4a","9ffa0ae498e6ad395b4f8a6b7ffcbd0020cfcb90","dc9d259c3856552407b7c32a6ea6b20ebd5776b3","f08eed95e1e745eeef68575b790678c6e56d1050","7b18bcbca7ad7cdb20712afc5b74badc5c3f71e8","0137fb09f57fd3685a6c3a43159c3647b6f1d667","09a77b51af5de428e1a8addda7e046a1ae6fb0a7","0a52bb3cd35a8af809318f31ab85c43e1dea3259","12d5729242fd6b136e08a30742b006365e9548e9","1086643c453895287174269eb2121491ef270c75","35512ed66f6126a5fa0bdfa166f00b7633c42ee4","ac1fbb3e6e21f28033c732c72ff07c3416d84366","bf06b80f4df8c2afdad13ee9fbc258c4845bcdf7","e67bcbbd1eec1eeea9827d802ee1b64753d31c95","61948481f4dd034d189c913c3a81ef13960d9593","5ea404d8911b0fabb2ec86841b3db7e5a6ed2215","2e518008e3f0ce35384cf2444dfd62f4f1026bfe","ca2c7d1d3793ec7fa83db8f85a1816824a195fe7","3f4d3f28b91349df050753e7c941f01dde7c03e8","b93f9ef4cf683853eb2b03fc7ca1fe3d82b4e80e","0c80fd49ed5712b1504218ba63b4be5759e9252b","b73918710de8700e847e69374f90660db877668d","86329018e2d19074629a9546365bc81a1dd474fe","8986a0cbc386a14cb155f1ee046f7cdf859e308c"],"title":"The fallback procedure for evaluating a single family of hypotheses.","doi":"10.1080/10543400500265660"}
