{"fieldsOfStudy":["Medicine","Mathematics"],"year":2019,"outCitations":["1a67f9a4624b4ea989e4ea9b14ea178a010017c0","51f6d7eb5b1f55ceeedd639faf077ce8a1404819","112de95db5282c8641b882f2abf3f4785b8e6b09","8372ba0c67a322bc31ccfcf6510c09bc66d6dd59","ed44accab4571065b3df1304f7c51183fe1ea506","a885244bfa36c0999dcb81a008b207e46e575bcb","903e861fa6d9a41fe5f3604d97a4c7a2a9e5dcaf","a23a99d081798412bff95c3c330217a09c0d2fa5","9ea3cd1a9344513d10c45f2bb4762db76e194d0f","ba7684a2a2b46a1ed9fc5bc0d18bda2de4eb455e","f6d530f554ffe2d4df9f0c0d2ba5186cd005d619","e28f032885e290495facb5aea8308f3ff8234406","4d8a5338042da99819746ff835b6f299135e2023","9c445e726cb8ca9c05312f9642c2129d8396d71b","58e9392768967835ebe8e13c7d70e0945937bbf8","c124b9d58c817e795fe33bcda6aff8065f6f0d02","3ace8fea1e22ac42546178c3246a80b080679775","202164619db253c7e748722528528a44c8de7bf5","3e2b34eedafbd77da575724a57992121698913a4","8ad6d501eac936c9d9b780eca017d5d1d1e59fae","20e06e571827d881f6b2544340e1b97910df84e3","2dd51051c3998f4edda0467c19883a54ba8d788a","e962494715cdb359a610176ad7f0a1e036b97dc0","dea60927efbd1f284b4132eae3461ea7ce0fb62a","3685e6f7e8817e91249332fc005951af1274044c","f967f84f17e1df9a3bdebbe8a02d916cb3ce4e1d","9c25536527d156b3b237e458acda1e11d0f19bd1","8c5e0e6f85b9dc15ecf23d43a49404925c4c41bf","81a65f23474ffceb2481836328608102950da979","12e08d630adbc6ddcff65bd1ffd8b84ead3b1f4f","58cd525db8e3eba143dc0b1a71df86d3cea66fc2","49bda01e28f3f9fffa4fa14bd909c0a2340aa066","a8aa981d6b19bb40add4ca25f00311cc3fb03f64"],"journalName":"The British journal of mathematical and statistical psychology","paperAbstract":"Motivated by the recent replication and reproducibility crisis, Gelman and Carlin (2014, Perspect. Psychol. Sci., 9, 641) advocated focusing on controlling for Type S/M errors, instead of the classic Type I/II errors, when conducting hypothesis testing. In this paper, we aim to fill several theoretical gaps in the methodology proposed by Gelman and Carlin (2014, Perspect. Psychol. Sci., 9, 641). In particular, we derive the closed-form expression for the expected Type M error, and study the mathematical properties of the probability of Type S error as well as the expected Type M error, such as monotonicity. We demonstrate the advantages of our results through numerical and empirical examples.","inCitations":["61c6215bcc5c663f63b69358d43e8f57ef8f6540","a39e373c338868ce01ad931eca2e44b9a0c81145","6343256d921b1adf6deca98964d93c33161fed0e"],"title":"A note on Type S/M errors in hypothesis testing.","doi":"10.1111/bmsp.12132"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2009,"outCitations":[],"journalName":"The British journal of mathematical and statistical psychology","paperAbstract":"Many robust analogs of the classic analysis of covariance (ANCOVA) method have been proposed, some of which are based on some type of regression smoother. A method that first appeared in this journal, which is relatively simple and performs well in simulations, is based on a running interval smoother combined with comparing medians or 20% trimmed means. It makes no parametric assumption about the regression lines and does not assume that the regression lines are parallel. A possible way of improving the efficiency of the running interval smoother is to use bootstrap bagging and a minor goal here is to report some results supporting this approach. The major goal is to consider how ANCOVA might be performed when bootstrap bagging is used. Simple extensions of extant approaches that use some type of bootstrap method were found to be unsatisfactory. However, a basic percentile bootstrap method was found to perform well in simulations. And a reanalysis of data dealing with teachers' expectations about the cognitive ability of students illustrates that bootstrap bagging can make a practical difference.","inCitations":["6c9a040d625083977884720472c6c4396ed58d2f","ea59f177f7b3c0518137376dce2120cab980cd72","308ff42b39912278d9384482304e160526959c35"],"title":"Robust ANCOVA using a smoother with bootstrap bagging.","doi":"10.1348/000711008X325300"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2017,"outCitations":["590104bfdd8fad1e146353bc928282983a49ef9e","77c986937d205592a007df3661778a5ed4fc4e38","ea98fdd35ca740e73e148e48df1248f210d7d879","4fcbad3521f84de6521c1f5138b18250dcf75212","7f6292a62c76f3d5c28430b60a996369f0d1fe88","ad6fca96c95d99ce317ed3b7d61ae369433cfcc5","7a00d54d500ee0f53da04a6702c902082a576757","7ed4a5f153a0b71ba3438f397b066b6a4dc02e71","6dcd3f1fb5be7a5bf69a85a28c8f3dfe8b090eec","964253e56e6f20145f3482e8d30c6ca69af78a06","c2eb0d1d80ff84af322b4c8ee5f8c165bfbac1a6","01a1d065a5292be740e75029622a3ab5e71e3150","b0c81beb50167fa273a7a5ade267e100089afbdb","4316c104d91c67137fc15c4fefe44a2e526d5d2e","431d54d99372d0d477c6a8996570ec8add0bc2f6","3ea559fbb4aee6eaf9ae4331f265e01d149b4b31","851b5f214c15ca2527abd6ac3b12f2bc8785e401","5808b306a17547589374752d82568ac693a3cc28","77ab1f3667164d256cadacbe8d85c4077ea89fb1","ca14a857503ef4cdfe8f266c3061161d4f49f69b","5324bb95c3d37eb196019fce93bf02826a85ab3b","03a5c66bde972627a70e802de782c865f2a6c2b0","4a6f1b5c8ee93e5fb0ee55d967b1fe6f2efcd87f","16202e122a7f761af138b28c0b43e63687b06315","a4fdc64c1ef9cb444f528ead4c7702134bd4a3ba","16ae7126d1da227285df7ef7adb8ba605089b201","08ec4d4da9d34fb30b2637a28810bfcbf8f104fd","d50bec8bfb162ca0e08f1f6a04572247eafbe5ed","a45f5d9b482da3711786a1c3a8af358ffef0bc4e","3644e38e97131ae0c72ae110046954e3039f93cd","805db512f28586522b26c07868f7155a786f609e","4df1b16a046875815ff784fab5c0687f88e7dc8e","755298f33f9352815af4990eab002d6c83dffd75","12cc5cb88daecc342f2cdb9c56c3eaf0becda13f","b211079aac55cd6ddb136e4f37b4f90f2ccefda4"],"journalName":"Journal of statistical planning and inference","paperAbstract":"We introduce a rank-based bent linear regression with an unknown change point. Using a linear reparameterization technique, we propose a rank-based estimate that can make simultaneous inference on all model parameters, including the location of the change point, in a computationally efficient manner. We also develop a score-like test for the existence of a change point, based on a weighted CUSUM process. This test only requires fitting the model under the null hypothesis in absence of a change point, thus it is computationally more efficient than likelihood-ratio type tests. The asymptotic properties of the test are derived under both the null and the local alternative models. Simulation studies and two real data examples show that the proposed methods are robust against outliers and heavy-tailed errors in both parameter estimation and hypothesis testing.","inCitations":["be85c4ff766952b397ab3fb28a76712059411733","80fb2bddaff2e7e2bc66610361d9eead59c8561a","983e22e9cac7b30f173a9fbefa7bb74ce0a808b9"],"title":"Robust bent line regression.","doi":"10.1016/j.jspi.2017.01.001"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2013,"outCitations":["a86ef4c45fca6583a1446a96e4de4f3d8d668b44","5f4b4e2101e7ff2cfdae0781d408d298776e6854","cc0efccebc8d55ebc6318dcd836b40adb1e9c0ec","f4c7163ea523c8fbb97fcb3700af18ca05bb1ff2","86b596ac7c0feffb606b2d8feb54517516b41f81","659a92e70189dcd34bd39c01d3ade5518ac664fd","705bc7b74b0fe0f3bf008c76820d9b6531de3715","685bf8d9c9784f7ad0bafb7dfe7f2854596c5983","e296d5ca9dc2fa8912d67ef32ccf61811e6e3ba4","3762b521d871d0adf90a35e0411ce861a4d14859","4e433c6daed851557202f129988d17502884ccbf","8cb01b154ae81d71a82bfcbacd6de6761891b208","679f7a2b04813e70ba123b005ee46183ae9fb612","5c5260d0b7304ff90eb6dff3a39500006d2b4907","1592a51a6e68fad35580177dc93d5a2f88b6a66e","42b59e5385c2a12560862b2cd466b602cd7baea1","dcb2368fda80d49ca675a98c6c241666b70bc3aa","d9dcb23a9fa300ee24e8793a339c3aa17d3e22f5","7e9867e651fed7d80e91999af434bbf4d507bc0c","50ca4ddf538fe76b90b9a2298a7a30590d195541","1ab6d04bcf450bedf25ddf18965cabd0aac23d2c","0b278688daa0053805cd1d58fab6fba3467fc234","90a5a175fbe4379e503ada742b7e3648236f62b8","0a15503913d0c6d493a812033f98ef04da39b317","b40be81b7271a3239f00994e13a84e752faafcb8","81df3dac1f7679b5cd5ff45606cd94d3c8886959","7fe59a873246a62128549c29cb3543cb9390f1d5","10b3edb9ee7fdbc6c1a4e52df46dc9041e56f049","975f7e9163a14ba8696f5d2711936427dcc12400","48cfa0a10fd3d4760036b0a8369fece70f5813e8","163088df67df32b51aedded945195666db2ce8d0","5d152733314e2c906b920502d91dca2af191fe62","66287e72a366ae6f154b3d76001b5641e65f3750","b22bda0357782d72b40ff9b86867fc8cac9ec828","7e4946ec77ec7cc7226f1d99f5f927a6d650c43a","5647a88934fd6a1c23c919c636a30e17ff143ca6","d758e28f37428ec582a15cfc9e139e5ac2ecc1b5","802374c55ab73617603a0b08036296f7156cf7a0","6e01361606a745b17f939b6ac29c124131e75c7c"],"journalName":"The annals of applied statistics","paperAbstract":"Diffusion tensor imaging provides important information on tissue structure and orientation of fiber tracts in brain white matter in vivo. It results in diffusion tensors, which are 3Ã—3 symmetric positive definite (SPD) matrices, along fiber bundles. This paper develops a functional data analysis framework to model diffusion tensors along fiber tracts as functional data in a Riemannian manifold with a set of covariates of interest, such as age and gender. We propose a statistical model with varying coefficient functions to characterize the dynamic association between functional SPD matrix-valued responses and covariates. We calculate weighted least squares estimators of the varying coefficient functions for the Log-Euclidean metric in the space of SPD matrices. We also develop a global test statistic to test specific hypotheses about these coefficient functions and construct their simultaneous confidence bands. Simulated data are further used to examine the finite sample performance of the estimated varying co-efficient functions. We apply our model to study potential gender differences and find a statistically significant aspect of the development of diffusion tensors along the right internal capsule tract in a clinical study of neurodevelopment.","inCitations":["0f63b4532de1cf8a240a6d7218293f575f6e2ac8","043054c515f306f37834bca3fe6f53484ca5d06e","81a23049b38e057ee1d03d4d999882af0de5e828","1509c640790290775668c9ba88a99ac8d2ca0f98","2baa53b05ed75a2b20f0f474b9e821877b6101ce","d56613c2b7e78d09c803e4cf75aae9ff4996d025","24587949b89577a6feeff916559e7cdd66a47f43","d5174d36d3f2f29eaf100e87a039fcbacfea444d","2ba5f8627884a5420b6d9a732eb2138819bd0b0f"],"title":"Varying Coefficient Model for Modeling Diffusion Tensors along White Matter Tracts.","doi":"10.1214/12-AOAS574"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2013,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"Although asymptotically the sandwich covariance estimator is consistent and robust with respect to the selection of the working correlation matrix, when the sample size is small, its bias may not be negligible. This article compares the small sample corrections for the sandwich covariance estimator as well as the inferential procedures proposed by Mancl and DeRouen ( 2001 ), Kauermann and Carroll ( 2001 ), Fay and Graubard ( 2001 ), and Fan et al. ( 2012 ). Simulation studies show that when using a maximum likelihood method to estimate the covariance parameters and using the between-within method for the denominator degrees of freedom when making inference, the Kauermann and Carroll method is preferred in the investigated balanced logistic regression and the Mancl and DeRouen and Fan et al. methods are preferred in the investigated proportional odds model. A collagen-induced arthritis study is employed to demonstrate the application of the methods.","inCitations":["2fe427b561855c9edc19be263fea0614446bc085","0486aea56ca262b1e58c7ce6bd6da5372686e114","38f380ab49bc249c1cc3a01f87a1db969cb69779"],"title":"A comparison of bias-corrected covariance estimators for generalized estimating equations.","doi":"10.1080/10543406.2013.813521"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2012,"outCitations":["84f272d8bf1eaa77c4a3e45c480b2b2ab9b49670","a258041060127ddab21df90a78300917ed267723","75eb4fb3e4ec3e958a53a3e6412a421def870701","94cbf53015b9d952fa48503adb8dbdb93c242fdd","d48d1ca25b087657d43b2ee49b139bd3f4894042","485061768ee47789cd6763140b918da80386f590","b9187d85815e36e50a721d383044bb4afa1b0f72","48b8ae6a9f426fb516c41de6d80cf2d01329e2b5","52ab1f2b09a46ad0fdf53b667709e21033415ec4","d40fee01a7708099f9e9392f10ac0b370b7ed8a8","b872af483adb03dfa91262ca4f20af3751dc63ea","b6d0906ba50119fca2843b84ded50ed63eefa6ae","b2142e512677925dfbc809f22bc46020f6871002","d6b8ac12d218dbfbf1eb13e58bcdb18da981e25c","51511e0f2ea6c48b4f9ffd4ca76405c5390f7842","7035357aff638f4afe8b73882148edece9eb09b7","c96cba9e10944df38d81e68499518b551cea549f","bff1cdc1a299e9f0525b44bf93155ce9d6a19207","68a08f57ce967aa8a13f63b41bff953da54ded8c","b26eb5cca8f7a72276be76dbc0e5d2f09ad0e94f"],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"The rising cost of clinical trials is impeding the development of new drugs. There is an acute need for critical evaluation and innovate thinking while designing the trial. Adaptive design has been repeatedly called upon in the last decade as one of the prescriptions for this intricate problem. From a pure statistical perspective, the adaptive design framework depends heavily on the appropriate selection of the type of test statistics and stopping boundaries. There are several methods proposed in the literature, based on different test statistics and stopping boundaries. All of these methods are rigorous in controlling type I error. In this paper, we group combination p-value methods into major categories along with their stopping boundaries. We review and compare these methods based on their operating characteristics, including average sample size and maximum sample size under null and alternative hypothesis, power, and early stopping probabilities. The optimal interim analysis timing and alpha spending function were used as the independent factors for this assessment. We propose an evaluation matrix and establish a framework to assess the most efficient design in order to assist in \"one stop shopping.\"","inCitations":["96e4f5aa6a7008d2a0b06269a7fc34fd644b78fb"],"title":"Optimization of adaptive designs: efficiency evaluation.","doi":"10.1080/10543406.2012.676532"}
{"fieldsOfStudy":["Computer Science","Medicine","Mathematics"],"year":2010,"outCitations":["1a1751bb962b83b73fbd2d0f03dda9abf637e887","cfa7a6d7c128f055cf4647051300416c390b4e29","e1a99546ab5743f9ff33fbc7a9eaa38cb34cdf75","8481789ff8e58b818927831b7c66eb583b27fd50","37e44d1de8003d8394d158ec6afd1ff0e87e595b","bd51a0e545ebc0cf521702af7d97c850051a740d","3b8e7ac8b4ef22cb0a50381be13ac9edc91c7341","740ea546c6968102e8f28bcd333af94e8057d156","68a2fe5688423372ba22705173c78bb88f722466","cf49eed2ce325ae6a880ec8a3f4eb7fb3f09d480","cb8202c3189cce0908a721e59f049438db8654c2","15896899772ad3413fbcff021178ba5d9b08eb73","f94d26a8b58309d25daefd4adc126ae47647370e","e69bce0185720fcb652ae458a4529a2807f53de8","746554301fc69990cead47831552c67eefd259cb","caea8632ab8e1a9affc3af00f8d4b48de0777eb7","a0afa4ec10b2b060aff0ec676a661c8013c7df1d","52526a489e6f41fe30afcf033cc7c1a8b26d25e3","be712a349d468f3fe6f7cd1f608a7d998162c541","f90a86d3c0b174c1175bd1e6aa8620a9701a2c18","d8239db298ffd2ade96a2fe0750286d4f5f04cc1","8d76672d52622d9c45014d630717ce911d1292ba","e8f60cfc38b0888c2e37e7228c26da9bd13603a6","2938e46a8e6d40a82219839e75c3b07ee4a89c17","6e4ef9da13090e66d28019b64a886041cb0428e5","731df2bb791c3fa221ca9498bfe43bb04b698357","9aa6443860ca7c8ab8dd642b4f948d99cf6e9f30","5a3859b23b28139d3189ac51c6278d8d7273fedb","42ef73e2756016d8794cbc1fa283a4ea72330ba5","cb009fac7b4e3af6d78a708178585f2243886627","654352f561d7de3b556834f8ae5dae86759abdba","fbad7286a02730a794177c030ec070b9f54c635c","fd302d757fc8d8120103491f987945f7e96842cc","b7294ac444ae927f71ac442372903ff5e2a763e1","400b45a803d642b752a84147ef547af7811e8f3f","54d1e1d6b46f1c382382ac2144ae33d2eec0ed54"],"journalName":"Computational statistics & data analysis","paperAbstract":"Many diagnostic tools and goodness-of-fit measures, such as the Akaike information criterion (AIC) and the Bayesian deviance information criterion (DIC), are available to evaluate the overall adequacy of linear regression models. In addition, visually assessing adequacy in models has become an essential part of any regression analysis. In this paper, we focus on a spatial consideration of the local DIC measure for model selection and goodness-of-fit evaluation. We use a partitioning of the DIC into the local DIC, leverage, and deviance residuals to assess local model fit and influence for both individual observations and groups of observations in a Bayesian framework. We use visualization of the local DIC and differences in local DIC between models to assist in model selection and to visualize the global and local impacts of adding covariates or model parameters. We demonstrate the utility of the local DIC in assessing model adequacy using HIV prevalence data from pregnant women in the Butare province of Rwanda during 1989-1993 using a range of linear model specifications, from global effects only to spatially varying coefficient models, and a set of covariates related to sexual behavior. Results of applying the diagnostic visualization approach include more refined model selection and greater understanding of the models as applied to the data.","inCitations":["07ff769edc723cd8b2bf8c8e5cd30d7f922c74ab","6f68803251cae2c40f31a55aa0c97219a853f407","c6e4a0da5acad9f176afa94736267e30b811d3b6","cd77e8b1b13b79732f1e2a3eb5fbba68786ea3f3","3cb3bbae3db082f652cadaa4f00e9a024105abb4","cbd207c4e8f5d2c874c0f98373cc7eb5ed3cbd7a","98dbe0efca9e498b4e9402e8baea5f4657d03145","29bdf5c568c7768ebbc95e85d8f6ec8f7fbe629e","34e726e2a6eaddcaf6193c6021c164f42b7032c4"],"title":"Assessing local model adequacy in Bayesian hierarchical models using the partitioned deviance information criterion","doi":"10.1016/j.csda.2010.01.025"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2002,"outCitations":[],"journalName":"The British journal of mathematical and statistical psychology","paperAbstract":"In the likely event that some clients refuse to participate in a psychosocial field experiment, the estimates of the effects of the experimental treatment on client outcomes may suffer from sample selection bias, regardless of whether the statistical analyses include control variables. This paper explores ways of correcting for this bias with advanced correction strategies, focusing on experiments in which clients refuse assignment into treatment conditions. The sample selection modelling strategy, which is highly recommended but seldom applied to random sample psychosocial experiments, and some alternatives are discussed. Data from an experiment on homelessness and substance abuse are used to compare sample selection, conventional control variable, instrumental variable, and propensity score matching correction strategies. The empirical findings suggest that the sample selection modelling strategy provides reliable estimates of the effects of treatment, that it and some other correction strategies are awkward to apply when there is post-assignment rejection, and that the varying correction strategies provide widely divergent estimates. In light of these findings, researchers might wish regularly to compare estimates across multiple correction strategies.","inCitations":["2680f983484e830700cfebbc2de7bb940c2dfaa1","bc09635d1ac0aeace9d275396633684607f7fa63","10e7a460f3c5b31835da749d4fc5fd09ac42df4d","d1ece3b35fd1fe0593902583557e5cfeb702490a","26ae0cd9dfd747fd8829ce22bdf954681ec1bcd3","bad73771a1da4e8a13b4246798ad6da61d4da569"],"title":"Outcomes and sample selection: the case of a homelessness and substance abuse intervention.","doi":"10.1348/000711002159707"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2010,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"As more biologic products are going off patent protection, the development of follow-on biologics products has received much attention from both biotechnology industry and the regulatory agencies. Unlike small-molecule drug products, the development of biologic products is very different and variable via the manufacture process and environment. Thus, Chow et al. (2010) suggested that the assessment of biosimilarity between biologic products focus on variability rather than average biosimilarity. In addition, it is also suggested that a probability-based criterion, which is more sensitive to variability, should be employed. In this article, we propose a probability-based asymptotic statistical testing procedure to evaluate biosimilarity in variability of two biologic products. A numerical study is conducted to investigate the relationship between the probability-based criterion in variability and various study parameters. Simulation studies were also conducted to empirically investigate the performance of the proposed probability-based asymptotic statistical testing procedure in term of empirical sizes and powers. A numerical example is provided to illustrate the proposed methods.","inCitations":["5d3ef4bec0940b5bd960981758e860cc5d2d1571","63aff7336cde449ca6648e7e87dc4fe2719642b1","c5fc43e388eefafcad61c9393ed5ba3b46cc6d18","4f71472d7eb02af4133f7a1ddd7aa3b838f121dc","f5e68d8666e9dd758bdebbedd548403e8eb2b245","72a0da7b962a9968c127665a192b3c75e370ce2d","572bdc1f8754278a9dd16cbe559054d106392f70","3485c87ea4c014b50e93759f1e9f021421a083d6","70ac9d005449cd82cc75c4631d6e7f4efdfa8bd8","8396ee74f1b063e3a6b12016128536e9dfc1bfee","3d972b954ce38204aa1b6d496f1cf626fcc23502"],"title":"Statistical test for evaluation of biosimilarity in variability of follow-on biologics.","doi":"10.1080/10543400903367097"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":1996,"outCitations":[],"journalName":"The British journal of mathematical and statistical psychology","paperAbstract":"Principal component analysis and factor analysis are the most widely used tools for dimension reduction in data analysis. Both methods require some good criterion to judge the number of dimensions to be kept. The classical method focuses on testing the equality of eigenvalues. As real data hardly have this property, practitioners turn to some ad hoc criterion in judging the dimensionality of their data. One such popular method, the 'scree test' or 'scree plot' as described in many texts and statistical programs, is based on the trend in eigenvalues of sample covariance (correlation) matrix. The principal components or common factors corresponding to eigenvalues which exhibit a slow linear decrease are discarded in further data analysis. This paper develops a formal statistical test for the 'scree plot'. A special case of this test is the classical test for equality of eigenvalues which has been suggested in several texts as the criterion to decide the number of principal components to retain. Comparisons between equality of eigenvalues and the slow linear decrease in eigenvalues on some classical examples support the hypothesis of slow linear decrease. A physical background to such a phenomenon is also suggested.","inCitations":["43968b5816f02f109526c1751950202418878426","67bfa6eea793cbcc93b4bf1e99dd1d6896f3267f","58d4c92d719d198c4d6e519806c831580b5b5b5a","5c7bc8ab76bb297061b02f10cb2293c474d37fff","d791f32c331522da1bd924a243146679c6112485","10723c39f9dcfcbd45d4ed7460006dba78c6b67f","2d4268e64a801058b5652481610f171b93b0c844","902e2919c5f22aa98f2d20ea95e48643d9f3fdc8","5b65dea4abaad0eba8ce8b20529873675bd52ebf","c9da31bc26f562eff51bd2680f54f81476a65148","b3807231918acaeb31c5c2bdf6e05dd858412992","bc325d408aed3e3776e921251bb1156f8ff625f9","548bd55928057f97dd4e0225cc35d1dbb6361eca","17c70004bf584d0021d14519a665754b7b9bb963","ca0e525ea6435458630cbaf0cbdf3d1660fd695e"],"title":"Test of linear trend in eigenvalues of a covariance matrix with application to data analysis.","doi":"10.1111/j.2044-8317.1996.tb01090.x"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2007,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"The United States Pharmacopeia (USP) content uniformity sampling acceptance plan consisting of a two-stage sampling plan with criteria on sample mean and number of out-of-range tablets is the standard for compendium. It is, however, often used mistakenly for lot quality assurance. In comparison to the Japan Phamacopeia (JP) procedure, USP procedure is less discriminative between lots with on-target mean and small variance and lots with off-target mean and large variance. The new European Pharmacopeia (EP) and USP harmonized test adopted a tolerance interval approach. But the \"no-difference zone\" criteria modification for off-target products make the approaches biased in favor of off-target products. We propose a parametric tolerance interval procedure to test a two-sided specification that is equivalent to the test of two one-sided hypotheses. Testing against a lower specification is to assure that the drug product is not under-dosed for the sake of efficacy. On the other hand, testing against an upper specification is to assure that the drug product is not over-dosed for the sake of safety. The operating curves of the proposed procedure are compared with those of the USP test to illustrate the difference in acceptance probability against the mean and variance of the lot.","inCitations":["db526c066feec8e4f1c0fb3a5fa8c6db214f4e1f","942990f6e55058a47769445881c1bfa208828857","c3eae877c709a4d74b91dd423aa155a57572d913","7648847815b5d2cb0e6a42d6f5e013417fa77e8e","3c284f0dc47836d5881c5b62ebe69c2fa4eadbe9","8107e044fc62bacd2fc123feb9155bdb8af20237"],"title":"Parametric two-stage sequential quality assurance test of dose content uniformity.","doi":"10.1080/10543400601001527"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2017,"outCitations":["73fcfd9256017cc77c8c72fecc370f5e2bc4c8ec","48f6192b4dfdc8f389e7183575d0e6b00853e1b4","562137a824243cdd810a2b7a5ed0bb2689fe601d","e24526746a7753669be3bc021c3212e29033e366","cbd6745299a28c8b41acadcfb612dd34fa91a68b","21080064a8e42026d3be35a12c50f63402ec881f","d1d4c9284cabf410db306509c71cea9c0148fe20","c9e3f9e9828c7a078e1d3f8652f12027e988e306","06260e6a65b2d3b942fa63cf41da55f1839563d2","45925f5d863919bc491528ada90e141bfbdada42","8705dc8973afb7c9cad5aeb860b66cde464fb33f","b289a4d7b4b3766a9037a60134851af3af9490ea","69184e62fba447166180304b4766c36e6ba9d2b8","14703343e9979b1b9bede5f2502557bfdb6c6572","69cecee898e055680c56909a98d5bde2f4c9144c","526a6d5d69b96f08e8325ebd22e21bf2fdbd8826","a10a000ea03094d48c3466b06e9e64ce1f6d7645","23d7a81d6b8a58f6742f995caf60de34359fda09","721b25ffad2623a8d1e8044882f66e0dbe678f1d","3ccba5b39bf74158369afe4ef0613df7577f3a53","2db4003d940d0c55a5210af113d6ea8d282660aa","3b7f4962786c088b23920e33e9cb464cdb20ab70","96c78fb203bce7b83c9454822b2c531e4fd2ad40","44b92824f26751237986da8b043415a5b8d67a7e","97a0b529bdbc0fb5682cc5a5ae6c578438cae899","fa0f05b6c48120083dd4cc07b85fe22a2e8f6030","7289f6ccbe433da35bd8b14fb782b665af909b46","77f3f320b85e4ac5ef096dd57ec401ae8bf70f73","7ce10624b09c54d2604f60b4c2d48409201fcc5b","7e6a1b2b2f832bc2d0b77bc279508e1074df79e1","02f810de8ac9f90ded5e0a67e81b919850682093","f5ff6404a75f98e91a84daa80b27fccbe1477c89","7c092892ad87532f7e9f8d9ff79d73a892c6ae7a"],"journalName":"The annals of applied statistics","paperAbstract":"In mass spectrometry (MS) based quantitative proteomics research, the emerging iTRAQ (isobaric tag for relative and absolute quantitation) and TMT (tandem mass tags) techniques have been widely adopted for high throughput protein profiling. In a typical iTRAQ/TMT proteomics study, samples are grouped into batches, and each batch is processed by one multiplex experiment, in which the abundances of thousands of proteins/peptides in a batch of samples can be measured simultaneously. The multiplex labeling technique greatly enhances the throughput of protein quantification. However, the technical variation across different iTRAQ/TMT multiplex experiments is often large due to the dynamic nature of MS instruments. This leads to strong batch effects in the iTRAQ/TMT data. Moreover, the iTRAQ/TMT data often contain substantial batch-level nonignorable missing entries. Specifically, the abundance measures of a given protein/peptide are often either observed or missing altogether in all the samples from the same batch, with the missing probability depending on the combined batch-level abundances. We term this unique missing-data mechanism as the Batch-level Abundance-Dependent Missing-data Mechanism (BADMM). We introduce a new method- mixEMM-for analyzing iTRAQ/TMT data with batch effects and batch-level nonignorable missingness. The mixEMM method employs a linear mixed-effects model and explicitly models the batch effects and the BADMM. With simulation studies, we showed that, compared with existing approaches that utilize relative abundances and ignore the missing batches under the missing-completely-at-random assumption, the mixEMM method achieves more accurate parameter estimation and inference. We applied the method to an iTRAQ proteomics data from a breast cancer study and identified phosphopeptides differentially expressed between different breast cancer subtypes. The method can be applied to general clustered data with cluster-level nonignorable missing-data mechanisms.","inCitations":["6e19e6bb94f785916752be61aa169dc11f6aa05c","a63e97cf07d881bd8a2d34356d835e035240e025"],"title":"A Mixed-effects Model for Incomplete Data from Labeling-based Quantitative Proteomics Experiments.","doi":"10.1214/16-AOAS994"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2019,"outCitations":[],"journalName":"Journal of applied statistics","paperAbstract":"Population-level proportions of individuals that fall at different points in the spectrum [of disease severity], from asymptomatic infection to severe disease, are often difficult to observe, but estimating these quantities can provide information about the nature and severity of the disease in a particular population. Logistic and multinomial regression techniques are often applied to infectious disease modeling of large populations and are suited to identifying variables associated with a particular disease or disease state. However, they are less appropriate for estimating infection state prevalence over time because they do not naturally accommodate known disease dynamics like duration of time an individual is infectious, heterogeneity in the risk of acquiring infection, and patterns of seasonality. We propose a Bayesian compartmental model to estimate latent infection state prevalence over time that easily incorporates known disease dynamics. We demonstrate how and why a stochastic compartmental model is a better approach for determining infection state proportions than multinomial regression is by using a novel method for estimating Bayes factors for models with high-dimensional parameter spaces. We provide an example using visceral leishmaniasis in Brazil and present an empirically-adjusted reproductive number for the infection.","inCitations":["45c872e44b9e74bd1a9d4d55c2ba38a2f5a684fd"],"title":"Bayesian compartmental model for an infectious disease with dynamic states of infection.","doi":"10.1080/02664763.2018.1531979"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2018,"outCitations":[],"journalName":"Journal of statistical computation and simulation","paperAbstract":"There are no practical and effective mechanisms to share high-dimensional data including sensitive information in various fields like health financial intelligence or socioeconomics without compromising either the utility of the data or exposing private personal or secure organizational information. Excessive scrambling or encoding of the information makes it less useful for modelling or analytical processing. Insufficient preprocessing may compromise sensitive information and introduce a substantial risk for re-identification of individuals by various stratification techniques. To address this problem, we developed a novel statistical obfuscation method (DataSifter) for on-the-fly de-identification of structured and unstructured sensitive high-dimensional data such as clinical data from electronic health records (EHR). DataSifter provides complete administrative control over the balance between risk of data re-identification and preservation of the data information. Simulation results suggest that DataSifter can provide privacy protection while maintaining data utility for different types of outcomes of interest. The application of DataSifter on a large autism dataset provides a realistic demonstration of its promise practical applications.","inCitations":["02d4791cf09b19a7601468550ce3067243aa51d1"],"title":"HDDA: DataSifter: statistical obfuscation of electronic health records and other sensitive datasets.","doi":"10.1080/00949655.2018.1545228"}
{"fieldsOfStudy":["Computer Science","Mathematics","Biology","Medicine"],"year":2014,"outCitations":["b4887419f0d2966d6da7a701a763db9ee973ff7b","a24b7bf40c967f357e66b00dc7d2141a6966986c","67db62c833ca56f802c19b97e0a1fd72eb127c45","b9f508406ae8f2c7f00d0f45d86cfa8ea0cc18eb","5249e0821d8c3f9e0091d4d9f0208529a55bd611","a2893118e14c29a23472b02249b4641b9971786b","bc27a1d84122b73c32239f27311ac2b3d00191db","87f08a2be6148ea103f10b3625b8d3ee4f549dcb","b7aa26dd8b1621bfe747a3eeed8a6fcece912028","858522e6ec58c99c182fcb12a5836fb780c65d2b","595800b3f00f22899d7e2fe998712a4023407d24","fca3a44a9e94ac18e860a07e237e6c368fed2db0","56eba5620886995510ddcb1d09746e5ca5b62806","0a682af815949f6f7aaade2fdcdcae3b5383c8e0","d561712462d746a929adbbdf057c93df1e44d7a0","086ca78f513f44d013f761e5cb74d3878a8f2ffe","065216b473e94affbe20cd1003e1c3d6a080cef5","fcef2258a963f3d3984a486185ddc4349c43aa35","0eaa28aa3612057f8af7c93c59e03f26e3f67ca8","3c2824ab6d4fc4da7ccb3253ce122d75a78627a0","c4a7380df8ba9bbe7a7f2240329d44c6ec78fe97","a239ca50422303fdb8d2b9d9d764700fb1ed7a78","3a1e3a3a7c125590db2dcc49d324b5b3ca0b7c6a","89c8179cce5887300a8b588c86cfd3e6db0b2801","81409ae56f342416144b4a0a0c010f8e6b110874","156e7730b8ba8a08ec97eb6c2eaaf2124ed0ce6e"],"journalName":"The annals of applied statistics","paperAbstract":"Meta-analysis techniques have been widely developed and applied in genomic applications, especially for combining multiple transcriptomic studies. In this paper, we propose an order statistic of p-values (rth ordered p-value, rOP) across combined studies as the test statistic. We illustrate different hypothesis settings that detect gene markers differentially expressed (DE) \"in all studies\", \"in the majority of studies\", or \"in one or more studies\", and specify rOP as a suitable method for detecting DE genes \"in the majority of studies\". We develop methods to estimate the parameter r in rOP for real applications. Statistical properties such as its asymptotic behavior and a one-sided testing correction for detecting markers of concordant expression changes are explored. Power calculation and simulation show better performance of rOP compared to classical Fisher's method, Stouffer's method, minimum p-value method and maximum p-value method under the focused hypothesis setting. Theoretically, rOP is found connected to the naÃ¯ve vote counting method and can be viewed as a generalized form of vote counting with better statistical properties. The method is applied to three microarray meta-analysis examples including major depressive disorder, brain cancer and diabetes. The results demonstrate rOP as a more generalizable, robust and sensitive statistical framework to detect disease-related markers.","inCitations":["80ae0e8a3d2d6df1d771b42cd1d29cdb21337424","b9f508406ae8f2c7f00d0f45d86cfa8ea0cc18eb","1eb911e04d90764c83c0534a708966630ee02f6c","cd8478f1b3df43b5f67670f61fe9eaf7a7e59a65","586cb91eb3ff32f710e13ac3e94e6ef4a1cc4ab7","6e71451b5380528ac7b36da7285616e90e32a724","d6c60fe2e04bfb3607394a3dc0897e6c7d34945a","fc4ec7830089aae8603e3203a512372f17b5dc86","fb127dbe0245b09b8996e4f5302a0ca7092c369c","5eafd339f381b20c62c9ad302327763e12040828","065216b473e94affbe20cd1003e1c3d6a080cef5","aa9d32f9fad9122e90f5a67093315083ce39a694","e5718a5fa3b665b38528f3410aab2cdc7318961b","5bd5f437a2e9963f8ff49c30b7e6b38bb80edbd7","1dd0a8dcb4a6ee509fef12c08a56e07938397798","2197f9276cc4d4bc401a365e14a9710820ace630","66c0c02189457bb8f9174984d839a86f0af74b05","ba39393e541875d50baa7e75eac38bf069d929ba","b281b8c6667e55fa5aab72806d160853bfcbab3a","2fca79b8d0eb47ab33fc8391fa0806467409e203","b7a7a040f06e34d2a3b9bf42431fc070965221cd","7117a15585b1dd7893104d1ad624d9cbc1d0d314","8c121e04a67c242bf0a5bbc344936892c592902f","cff1629a3c4bad79928bdf9f35736054a45b6f05","a2b98651efd52141ce3a79ce759bb812d2f16174","16285148a096cd802bd276a0cba0e7c4c0a0f4cc","3d2c1e85198ce031ce707afdec8b1337ed9fca02","c1fdbeea9bed0a3a38e4a46fe5b9ca23f16a456c","7e7fb553a8b37384839b302f906b92713f3ae30b","201dadf91f2f89144aeec5a0656c6a4f0e4443ef","690d3d189125381f0e95fd0d1761be852545fa5e","8e2fc59c61c6f9af34996da38208c05a7ceb357b","2fbf012ce319ddf28ab1e1f07b679c65ce739c24","ff7731b759f073aeef030521f162a0243ac33456"],"title":"Hypothesis Setting and Order Statistic for Robust Genomic Meta-analysis.","doi":"10.1214/13-AOAS683"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2016,"outCitations":["f7a2cad709323197675188280ba834ca3d3c5196","ebc37fcc389e15e948b8dbb440bf54dc38ddaf9e","f3cc383d9a48c1646634dbe8290b1461f65bed6c","3c2112e04ca65b69cee371e8e766ecae188496f8","993b42cbd447e9860a441d26479c4aeba595e096","b953a08a10eddd2a579f5618a1746ebd6b28700e","f63e3665a0c6a373056e523607aa1f6cd42028dd"],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"Confusions between drug names that look and sound alike are common, costly, harmful, and difficult to prevent. One prevention strategy is to screen proposed new drug names for confusability before approving them. Widespread acceptance of preapproval tests of confusability is compromised by the lack of experimental designs and statistical methods to support valid inferences about whether a proposed new name is unacceptably confusing. One way of identifying confusing names is to conduct memory and perception experiments on a set of drug names which would include both the new name and a set of control names (e.g., names already on the market). The experiment would yield an observed error rate for every name. Inferences about the acceptability of the new name can be made by comparing the error rate of the new name to the distribution of error rates of the control names. We describe four memory and perception experiments on drug names, carried out using clinicians as participants. Each experiment included drug names designated as test and control names. We demonstrate how to use a combination of logistic regression, Poisson prediction limits, and highly assured credible intervals to identify and apply a threshold for identifying unacceptably confusing names. Our models show an excellent fit to the data. These experimental designs and analytic methods should be useful in the preapproval testing of proposed new drug names and in similar regulatory scenarios where it is necessary to draw inferences about the comparative safety or effectiveness of new vs. old products.","inCitations":["06cfeadf2be21887ab9b43ed71cf952b59554412","9b21985cd75e9dc54f0ed6a7472535def0d38d3f","8982f3cc4393e786589d2662e22991418b197afc"],"title":"Detection and prediction limits for identifying highly confusable drug names from experimental data.","doi":"10.1080/10543406.2015.1052481"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2017,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"Ratio of means (ROM) and difference of means (DOM) are often used in a superiority, noninferiority (NI), or average bioequivalence (ABE) test to evaluate whether the test mean is superior, NI, or equivalent to the reference (placebo or active control) mean. The literature provides recommendations regarding how to choose between ROM and DOM, mainly for superiority testing. In this article, we evaluated these two measures from other perspectives and cautioned the potential impact of different scoring systems/transformation for the same outcome (which is not rarely seen in practice) on the power of a ROM or DOM test for superiority, NI, or ABE. 1) For superiority, with the same margin, power remains the same for a location, scale, or combined shift (no other transformations) to scoring systems for both measures; however, for NI and ABE, different shifts can change the power of the test significantly. 2) Direction of scores (larger or smaller value indicating desirable effects) does not change the power for a DOM superiority, NI, or ABE test, but it does change the power tremendously for a ROM, NI, or ABE test. Caution should be taken when defining scoring systems. Data transformation is not encouraged in general, and if needed, should be statistically justified.","inCitations":["5ab80f7e5f1feeb5c260272c281a82416d03dad4"],"title":"Ratio of means vs. difference of means as measures of superiority, noninferiority, and average bioequivalence.","doi":"10.1080/10543406.2016.1265536"}
{"fieldsOfStudy":["Mathematics","Medicine","Computer Science"],"year":2015,"outCitations":[],"journalName":"Technometrics : a journal of statistics for the physical, chemical, and engineering sciences","paperAbstract":"When conducting high-throughput biological experiments, it is often necessary to develop a protocol that is both inexpensive and robust. Standard approaches are either not cost-effective or arrive at an optimized protocol that is sensitive to experimental variations. We show here a novel approach that directly minimizes the cost of the protocol while ensuring the protocol is robust to experimental variation. Our approach uses a risk-averse conditional value-at-risk criterion in a robust parameter design framework. We demonstrate this approach on a polymerase chain reaction protocol and show that our improved protocol is less expensive than the standard protocol and more robust than a protocol optimized without consideration of experimental variation.","inCitations":["5d3c7d6d42e0dd2e7a8c5ca5b4dd81d3acea32d1","876b0efdc0095089073b4145fda5f1014d603ebb"],"title":"Robust Optimization of Biological Protocols","doi":"10.1080/00401706.2014.915890"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2012,"outCitations":[],"journalName":"Journal of statistical planning and inference","paperAbstract":"Density function is a fundamental concept in data analysis. Nonparametric methods including kernel smoothing estimate are available if the data is completely observed. However, in studies such as diagnostic studies following a two-stage design the membership of some of the subjects may be missing. Simply ignoring those subjects with unknown membership is valid only in the MCAR situation. In this paper, we consider kernel smoothing estimate of the density functions, using the inverse probability approaches to address the missing values. We illustrate the approaches with simulation studies and real study data in mental health.","inCitations":["8bf439569f12e047ba404e3c2556c98c2236e6c2"],"title":"Kernel Smoothing Density Estimation when Group Membership is Subject to Missing.","doi":"10.1016/j.jspi.2011.09.009"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2014,"outCitations":["770f69d1c2bdb90849178b5aa93a16f3341ce8f6","a3b58eede935bb7ea9d5f9c8a7ea0999ce12b46e","1c208ab968ee49460b8b3509340b83e9d1143ccb","df59f91600231053ea82dd3bc1db316567024d62","7efbe5481755c050bd06e8f7389ebc3e9dbe6e3e","f7cfe594dbc602d6b871ec3909744e28c8b3dac6","35ce461c6fc7133223ea101e23e96c993685fb72","3a7dd6b9445fa80419f70eb10a40d0a67d8b2698","04ed031886914c3729e103e0f0e6c61afdee7964","5b32f7aeafbba4d97ef5f54cd6aa9848e08153e4","bac85ffbd7760aaf678e0f91634fcdd0c8f09883","6e68089d1800116fcffee59fbbd45afab0aefb2d","f395c410f725e2936be6bdd795cc75c711db533a","1f1b750baf5b0fa427c5b38379cdcc8d70634d36","fc9641f2233b837909f1181af19bc6aa1a711dd1","9088adb0428a2ec17c4b4f29991184ac2469d108","c0029e5c11419fdb9542e5ba60fd14b4e9b2ab4e","59133aaaaaaf722cfe57e3bce0b0d9dbba244f8e","0f75513fa5ad9f86e96ad9139de6fee5b0e0f694","69d3e6289e12290dfb1e79e08e3f405975deb382","1a8c44b8f4f6a1d7f63cfa6b5039e90892463661","6dda1f8137c6c6a8a4e5ec5794e216fa25fdc214","fe1d1959a533c235d4d2bb2acd176f2f9f2790f1"],"journalName":"Biostatistics","paperAbstract":"The residual risk (RR) of transfusion-transmitted infections, including the human immunodeficiency virus and hepatitis B and C viruses, is typically estimated by the incidence[Formula: see text]window period model, which relies on the following restrictive assumptions: Each screening test, with probability 1, (1) detects an infected unit outside of the test's window period; (2) fails to detect an infected unit within the window period; and (3) correctly identifies an infection-free unit. These assumptions need not hold in practice due to random or systemic errors and individual variations in the window period. We develop a probability model that accurately estimates the RR by relaxing these assumptions, and quantify their impact using a published cost-effectiveness study and also within an optimization model. These assumptions lead to inaccurate estimates in cost-effectiveness studies and to sub-optimal solutions in the optimization model. The testing solution generated by the optimization model translates into fewer expected infections without an increase in the testing cost.","inCitations":["febd139ee46565b0c28b1100bb8683043f378c5c","eb4d3f0352f6e621aedfd5d8fc1035d2a1b75afe","29454a84f5360572fe3fda2d9867f7057a90c4d4","8a953a6ee981aad8e77585309a84febf0d0b7941"],"title":"A probabilistic method for the estimation of residual risk in donated blood.","doi":"10.1093/biostatistics/kxu017"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2009,"outCitations":["82266f6103bade9005ec555ed06ba20b5210ff22","64b98832b40acf8adbc8124d9a3c8a904b486adf","b5206a16a4a45ecf9acf4e4e7ebee29f30cd9d57","dbc1cc0b55f10cc3d970b9cf30282538185e275b","872dfe0a3acef7616dc71bd67f634887fb4da75e","de0be2874b22b211869ddfb5c835359ed6426f34","dff2652f0564fa8b0dce552bec1bbcd4b4097d33","b08b48008b9f4408074f9b113fe3d9d755644713","15221e32e87168ac83af34006c85d929437bae4b","523ff8e17e4ac642015ce9c3f56ae7fb10e19ebe","ae60f8db8e9f9b97f7af72214acf53bca1e6e73d","f5276ee10f01035b8358d2fd650e53df6c7c85a2","e075a2e4f3db88da5d06fe9d68d79a19f2a2765f","e13d1d8a0fcd707dab79586f9f5fd608720fd4c8","55eefd21a96bbbf6af02737c77173e155d4d7578","b2319107c71768a08a5ae407e8661e2dd834444a","cb339bc18dbe8a259a460f24efe73bf20bc425b4","a3213aa2599ca23e0b32a9237594a01b0070316f","b7294ac444ae927f71ac442372903ff5e2a763e1","477ddb7be7a1f505bc1e146b7de07d28ba1e218b","d2d758b667092bb483c18cd86e661460b84386cb","0f2563b73080306f41322eb9500bc24aca9d2e41","65e25ca5d3603f8e82b8d82f63944d46287b077f","01e6b93894192f256746cb22359da7179d22abdc","1dd44b7f1652e56486b54a4f66328db54f425603","6588036f29e2d91f34ebf2e07ceee847b918cd97","f7ed62ee36f24699a2a49890caf60a055a1976e9","e7f9254f8e9678dedd8c2ccee99624c271ceeb14","8e0d2f4343b03802b8608eedbf9b76c007537821","1f83494815856bf535f925b667540eb418630173","d2892f6ed4deb4d1e730acd1bffd4035623290bd","17109f66d837ec59675fcef04cc072decc315f11","746554301fc69990cead47831552c67eefd259cb","37e7b513fbc432544cb8f8b1fbd2b436fb26bb47","83a0ab9ba503043d88c2bcf03513edb358a6c9b5","148268febf39ff09ff021f084c041d1551ac90ae","7e7240aff31e77cd0d7cc5ad7dbe933aaf473028","a1984a512161e7c3113f60274302ef16b1c82e5e","b19e50ceb7009eb51b6b3f27bcd652b22eaaeffd","c39630eb553b7c9b9da424ae0dd465802fee85cd","90065ba675b9a9a2b07a0cf424390720fa627f0f","00650f799617a5e7febb269e428b2b7c385edddc","c5696ee3fbaaf907b1b589eec759234b76330d2b","65bb01b985035307f7b1102e17b8a5c0f2dafff8","42463b9682587d76c32a22d5e95637f335ec78fb","e45daed4e9e47699cae7ae29faefb99e2e164eb7"],"journalName":"The annals of applied statistics","paperAbstract":"Spatially explicit data layers of tree species assemblages, referred to as forest types or forest type groups, are a key component in large-scale assessments of forest sustainability, biodiversity, timber biomass, carbon sinks and forest health monitoring. This paper explores the utility of coupling georeferenced national forest inventory (NFI) data with readily available and spatially complete environmental predictor variables through spatially-varying multinomial logistic regression models to predict forest type groups across large forested landscapes. These models exploit underlying spatial associations within the NFI plot array and the spatially-varying impact of predictor variables to improve the accuracy of forest type group predictions. The richness of these models incurs onerous computational burdens and we discuss dimension reducing spatial processes that retain the richness in modeling. We illustrate using NFI data from Michigan, USA, where we provide a comprehensive analysis of this large study area and demonstrate improved prediction with associated measures of uncertainty.","inCitations":["6417e1a1a5801a7c195fb620c49227ae8e82e926","489c465821ea63cef33908a3b763f5bb47e2ddaa","dd8cf19beb2a674777db61fd3338a83a9f89ae28","840bed4dff94f4d519ec1bcca095d446d7d9736c","fe8054b26378f062c78571fc3ba4b2c6dc7ef8d7","e05d6d42505599ed4c670458d781a6479cd316e1","4f41a78f859a79f27941a684cbe3ac7fde930c4b","1cc05b6799bde251579b764a060a13fb632a9f91","077506258db66be3d188b7fce539aa8731c152a8","2e55196466515e751e38c5f8adf36356b6eb16a3","2c1cbd81508c257902e596a286e93d06d666c1bf","3a3a2270c830f2e28a33109cd25c1dcefc283813","0014e2439f808a321dd38e78f5b0ac1cfc9d09dd","ae8469584ea3553fb6c1042fdbf4c67d8ad279c9","8a71afa34793b8785827e69ed4607721ceab55f5","2fbd43ab75c1373095b0a61e2011c91e66e889fb","78aef7cd1536a86d2e03fae22ae8c23f84c93d74","f65d09863fd937d3959d894190b9224359c8ded4","ba50fa375f164c5cba1cb83e8cd9a19a4c0c2977","027714d1cb3a776de868b518964a813b05ce62e9","67fce855ff3a08e79103ce5242614df6c2a0a9c1","cb031bfd2ed68a0d9de4d2dca7cf25a3d8cecced","301f7cec55817a66f493c262b562321ed68a6c03"],"title":"Hierarchical Spatial Models for Predicting Tree Species Assemblages across Large Domains.","doi":"10.1214/09-AOAS250"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2010,"outCitations":["8e3cfaa13b97d152833b429b179eed389394eecf","4c693a4f9d8c64730cdce6b5b6794a7a62a0b7ba","9151d84629277bab26148bdb6379626b44e1cd0a","017b60fe0906948661610f1bfa60d16a7ca47c3f","d00760ca054a90bf6f8bec742635ecca8d76a67d","62064218665ad89f0cb2a44f5b19f7703d9c7e71","09bc263568c5437ba03e8acf6193714aaa22fb64","39914a560a956f6ee5bfc65e1bfd25f2edcd692b","6d281f055797105434493f8c77ce24f7423bb646","d6f4eb08a3717bf23129e529a75a9ff33b010050"],"journalName":"The International Journal of Biostatistics","paperAbstract":"Current methods used to analyze time to event data either rely on highly parametric assumptions which result in biased estimates of parameters which are purely chosen out of convenience, or are highly unstable because they ignore the global constraints of the true model. By using Targeted Maximum Likelihood Estimation (TMLE) one may consistently estimate parameters which directly answer the statistical question of interest. Targeted Maximum Likelihood Estimators are substitution estimators, which rely on estimating the underlying distribution. However, unlike other substitution estimators, the underlying distribution is estimated specifically to reduce bias in the estimate of the parameter of interest. We will present here an extension of TMLE for observational time to event data, the Collaborative Targeted Maximum Likelihood Estimator (C-TMLE) for the treatment specific survival curve. Through the use of a simulation study we will show that this method improves on commonly used methods in both robustness and efficiency. In fact, we will show that in certain situations the C-TMLE produces estimates whose mean square error is lower than the semi-parametric efficiency bound. We will also demonstrate that a semi-parametric efficient substitution estimator (TMLE) outperforms a semi-parametric efficient non-substitution estimator (the Augmented Inverse Probability Weighted estimator) in sparse data situations. Lastly, we will show that the bootstrap is able to produce valid 95 percent confidence intervals in sparse data situations, while influence curve based inference breaks down.","inCitations":["fd7d092f01bed73e8dd5fe100efee243e0cc18e8","e158ea00669155bf8614a70604f04fbb6753f447","48ec49beabed2886d65434448f614d9e0f22d488","a7b6848a8b07bf21fb7936b6f21b02299056697e","8d8029cde8c9859caf85bdf3880310fa09d409a1","7a592ae91acc5cafcd43bd372f30d63d761b547c","ef295cd94e97c2cb8d2ced1fbce174325a09576b","d1afc1bac9c451642735a9d50f4f1503db7b19f8","41f517c7ac126f86a5946cb80a38c65af752dffb","d9717c53d893c435be06205f0893cf9dae78b04c","b0b2c40e5689c5e0f6cf234d2ad48c6151da2efc","b32f130cfe4e0daf5a6be97cac57cec14427b8f2","b669a6fff30ea7be5909e90f33a3767687150486","8933ca1e36478b5ddc2ef37fa8d33583f0784f2e","d5fb168d22ccc4429bf3529eb19a68d6ca56a5d2","f8cf8f35d47f078fb2cd9ee179bcd68eae08ddc6","4d76a996ae6d8372e3ca6ef947ba72930e11eff3","5190fdd5cd9163316084838cbcd8916facb617b3","2edc363b9b5ac16c7eac6e57950c8ad8bbb95cd6","db5043638485d7203aec46bd367fda6fcfdb0f3f","4ff698c36a414594b32ee35ff150daa4d6a2e47c","8ba1234c0c067d816d546aca66c6af4903c44451","6ce72fcbe684ed330c52995a9614fa1434b3be87","76e6ca67cf6b44c2ab939999750e0f843955283f","fba6430dbf9559f26b1a996b71902f22ff2c93c0","f13530b2f420ce4d715320fb1a4f55d8c1547564","18205fb6d7d49e0f96b78debb396315001c33a2f","a39cd2f881a71b887bf821233290647c58876dd5","e996fdf996b787cd052db8e1978597c73c01b9a0","618e232c5d120cdbfc703ae3a88049e8fc320243","b17273bfc7242acb5469de6c9486e332db2c7b45","a8d96725525660c33256814faad47fe06611b2f1","ec303888fa3c7997dc1d31f3e3f8fae4baf69a55","5f561f92ceffeff37b1782a22a19ee86ba597ce9","b6d77285743714db09463240543560025c6ff301"],"title":"Collaborative Targeted Maximum Likelihood for Time to Event Data","doi":"10.2202/1557-4679.1249"}
