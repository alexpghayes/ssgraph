{"fieldsOfStudy":["Medicine","Mathematics"],"year":2016,"outCitations":["73d6948a5fb62bd8c3fbbd612b1064003bcb2222","fbc0616fb7b118668b61a4c5b75b2308e908705d","d90a98dbd297e3b57f166ea139258660188792ed","862d95f2d89ac9b9405dc25c329a2898c984d53f","6ed0e4a022dbc09ed1e0748a4ba8c192f5dd1d90","d49fcaf2314659817b433b6fb13e386bc365d034","5293e78c979b3a91da2b748b03727638fcfbedf2","113b10df570f00ed2065e5e6fb2259b44ab94f1d","0893c416c067673df1a3ccba355fd9dbdea9b4c5","b800f9dde3ee805463172f38db62b79b2a8ce98a","92e5dcb2ce71ff1c0e344c3fea1085c924e32650","9415482c3bef23d0c7611f62b5581928d7a5b792","95d2e0e1a4abdb6e1993ab90634eadea3b7e1f10","201b2bc5d34a0cd1e562f066ed03a5301ab2c1b3","4b39cb5f7dbefedb5208d389ca6413cc8b9fca1e","c74cb2dc88baec89af714577ddafa454ab785135","8d843a9781a148d9ff52432490917a2f21951af8","73a8a205a37f0169e89d3f0819a8ec36b39d3d2a","b365b8e45b7d81f081de44ac8f9eadf9144f3ca5","80b6df0b985e25755bbbcabe3e8662afa65782c0","29aef93923512c31cf59b08cc5cd0529ba0470a5","a2893118e14c29a23472b02249b4641b9971786b","efe973075ac6c86965fdc937e44d5bbac34d00c9","6cd1350af11da392dd0b188ba57167e677494e3f","e5ffaa4d7752d55cc5cf76eed1fec267b2db171c"],"journalName":"Biostatistics","paperAbstract":"When a moderate number of potential predictors are available and a survival model is fit with regularization to achieve variable selection, providing accurate inference on the predicted survival can be challenging. We investigate inference on the predicted survival estimated after fitting a Cox model under regularization guaranteeing the oracle property. We demonstrate that existing asymptotic formulas for the standard errors of the coefficients tend to underestimate the variability for some coefficients, while typical resampling such as the bootstrap tends to overestimate it; these approaches can both lead to inaccurate variance estimation for predicted survival functions. We propose a two-stage adaptation of a resampling approach that brings the estimated error in line with the truth. In stage 1, we estimate the coefficients in the observed data set and in [Formula: see text] resampled data sets, and allow the resampled coefficient estimates to vote on whether each coefficient should be 0. For those coefficients voted as zero, we set both the point and interval estimates to [Formula: see text] In stage 2, to make inference about coefficients not voted as zero in stage 1, we refit the penalized model in the observed data and in the [Formula: see text] resampled data sets with only variables corresponding to those coefficients. We demonstrate that ensemble voting-based point and interval estimators of the coefficients perform well in finite samples, and prove that the point estimator maintains the oracle property. We extend this approach to derive inference procedures for survival functions and demonstrate that our proposed interval estimation procedures substantially outperform estimators based on asymptotic inference or standard bootstrap. We further illustrate our proposed procedures to predict breast cancer survival in a gene expression study.","inCitations":["274fb949e1c3fc2d9a8aeead3fb5d3a8e9640b80","51f64a7a0e8794e9a3428543c3f12641c87a6849","91fd2db002c8cd7ac5ad277ba5704b6ed4e63323","46bffb6b067772430eb513de96fa973b25eaaa77","30bd343c225315b3f05cf43e9f7482cbb75d7c00","0bb82cf2bb8d3293c30f8077711743815041e093","cd01e989b31b2628724b15d90acb4980c2ab71f5"],"title":"Inference for survival prediction under the regularized Cox model.","doi":"10.1093/biostatistics/kxw016"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":1999,"outCitations":["b9cbb80a03dcb40029fae265c7a92943a4910ace","0e8680fee73d2212606767b02ec824c0ce55df2d","6e4ef9da13090e66d28019b64a886041cb0428e5","ac81de9c9db10930438387a7b069f3073444b616","2c288210396f26755fe42ee36c14309b445a94e7","14ae79f1e13b94b156a54ad746e22e849f6e9409","9f8adcc49a8c6200ce917dd31cdc45fba6985af4","014d2c69452da4b1aed0e51db76ac93e11c4c387","71ff930d1a0daba04bd8ed0a79e0f123a6088844","ae057979777f9ac627f84849bcc8b269b6594fdb","d3eca54eea61a87fcf76738088ccf57d3301ca95","46848e4c1c0d71681ad72d39e983b28984cfef04","556dc057ade0fac6f0ce7f149040dcd4d6940635","1c2a2ce3fd63a24c0e2c057d49a17fc72192084c","9871c9dce9887bf4798b5cd0a6aab34c3363b898","9f282400aa7f9eb4dd221c43b6a9e0aeca9bbc67","f5e14f1aaf2d8cdeaa5be227401e1ee7bc2345d7","deb5235b36d85412229ad43c9c9dd124247393b0","1afe6540560350edfc68a24fdffbeba7ec610530","1d480fc6abfdd048ca00f681a3000c3fb494da92","833e416916e119bad9ae24b1b646183a589d35ae","9621b7d4ac709da91a5f259f76b2284aca8dcca8"],"journalName":"Journal of the Royal Statistical Society. Series C, Applied statistics","paperAbstract":"\"Multilevel modelling is used on problems arising from the analysis of spatially distributed health data. We use three applications to demonstrate the use of multilevel modelling in this area. The first concerns small area all-cause mortality rates from Glasgow where spatial autocorrelation between residuals is examined. The second analysis is of prostate cancer cases in Scottish counties where we use a range of models to examine whether the incidence is higher in more rural areas. The third develops a multiple-cause model in which deaths from cancer and cardiovascular disease in Glasgow are examined simultaneously in a spatial model. We discuss some of the issues surrounding the use of complex spatial models and the potential for future developments.\"","inCitations":["a89aacc47f41e674aa73c590bc135ae8d554130f","941a61eb0a352be32547d05d708a8269aaa20092","2fbcf3e92a89993005b23c46798693a79ec90729","bacd30c3ef45a5427b9ee1c940dee1fc07dacd0d","5cbfefb9c2f6449d0f0ccb9ba2cd582157220ceb","7e8c19214378e0a641fafbef09e5113c66a764eb","3baf3f9eec695f6005179195317c4a8081ef4031","41e4fb55d72bc398ec3dd857dce533fc6f2f7d79","68a2fe5688423372ba22705173c78bb88f722466","a7dd2de837b33e70dc9c89b0fe5cd2dadbf95d63","03e3db82fbc84a3f8d3e820d6cc91f528b3d2c09","ee1f6f84da65eb1b3c411d6b0e9ae1eb3e9d79d9","15c351aff21afc800a80cc179da3c51477b072bf","b4f7aeb5a44b9399b92160a0bdec047e46d7be97","0930c965b73a4daca6bde783f25c30c4b8c0f0d4","d341cc50a4ae8aa1d394d3166e65624e3809591c","6292bc730c09b1d4ee3071da66f262850203bf3a","f49e1aede974b9c977af0c0ab4eba2256fd3fe3b","9e965e8094e0a938f131a1b471c811cbf0e685cb","deed23b74de4937c1cba7b8899aff07abf849e94","469286f619d9b0eaac492ad6bbf229ff51e863db","3712bd02af79772f7278ef8d7e381d3d93c1f0cb","258614d90cb19c664b73cd46a892d54609848ae8","7f2c9854cd9fca2e82e62b9171c1247a3cc9bb4b","2d241569d65483705c6a819f0a8e4d34a84e8bc9","c026bbe9805e6296f1e50463b3a6a00c59fc46b1","cd3d91bb7ddaadf496f77a2a95cefa17aee83ee4","7b68321ff85052f30c07235a933342b74988339d","4e007cce952aa9d64016bab52885d43a5f5aed2d","eca8c3c3d9e4964e49163c929b01f98e53cb65de","f5442a6b97c5467dc51a9a76dddea2e4e6a6247d","dbf2f892f3d9949b12f626be82345b87c96a59d7","9720e74ab8d0c72a7560fbdfa6a8c3832afe5026","8fcb77a42d50b2177d51bea27a00f372fde034d5","11e0f7f8f6b353652f16852cb5fe05b383195f8c","bd6e132b7dd74ea1ad9f6e61a73cda2a1c4e00e3","50358ad09ae661fb04857f061ceffa739585b30a","d6033622a9d81fa22cc4def32c974aa5633d1288","8d8cb208e583a2b375e20610de1fd653a8c8478f","ecc904d01182c92664f53543d967a29d70cd5616","d0b0a146b1712083813e77eb8c1839ad047eb179","0828ae4e89e0342ca21af87d66407b121cbc5d53","3f7228798cefaa38e7c3a233837dbbc23cf5849e","1469178e3c8d9a948b721752b395b34a0d837c4f","3a810cb8ee112b3522ce2b9f1a05afe9992f7996","5f2662564c101a0a1bf8995314d719f822137472","e1719adf95a611f88d8821ef94dea496553b5310","1854b5b680560eb9952f13043fa6b1b4f9400f12","78e68f60e1cb72672c311f5f3cb6048c9eb5974e","366db996eceec6891836b4f2cd55adc5ba84b159","86318b00d651ed4cb4f4894d6584046f43d542c0","2b0fede6a879f0f082cd15809f423fc5b58105d7","067e0264a6625476420eb3dffaf5ae804e287a2f","246e90f9ad9969f5cd220e8b213998f44d4c637f","0a9b3e2371ef6ee10d3725b2e1a6639da7901f21","64349f2e1b62f12e17a8b628c96283dfbc989f4e","59a94a98a3505c0596f715d4adf4377730e78a21","e4e9cb94c9efe569b08d4747d22b60e6814cb6e6","05bc3f9bd887bdf953b607d1c448f10af23e8ecf","83e29192a893fa508529aabb338d7625762f1635","7b3c053b8d3ca8fe6ac9b5c2ac6f7344a123cf8b","726ff759fc23259b8eec2598d2919f521ad756c7","aeba5733bdad630ad8ca37455f179dc2130b7117","fa8ee93b1cbba0b5020c182bebeb34a6bdaa2ec7","3fe1c8eab2dc3811148ef7a44c8e35e314ed0903","aa5faa3c50427bd95f4616b643ca48a92e375591","e29da9502bf404fc0bfe0acef34e10236c46baec","88236bf45dc591175d65fa28e466c3d5d12298c2","17745641b3d407a5a8d45d69802c704607a8aafd","7461346bc4a5054edbf8dd364999426147480f4f","970583fee038090646d0b386204ba29a643e0c3b","08bf1cb682c7aff03101e05b7ccb0d06b00049ca","4e4ca7df8be4fcc963f171188c744f5e045b13ae","3cf0bf04c6fc54288c1b8b85b5f0d30104167be6","63c00fbf502d0d7e3ee5663f009f3ea7a2f205ad","ed2fe3af576e99541aaf8f024efdf38bdecbdf19","9b0082db5ded5a1a30f391dd200b2bae6a3cb6a6","6d27b43bf0b0fa2bf030d05e4bef2def59b3c39b","c1994a5647bb56fcce4cc1a47a540080f185c7b6","62bdca234d14fe6a60b65a868f29971a5151a7d0","c8f36bc9345c23ca7637a55db1f1b58516ca32fb","940180331a9f133c8b27ae1e567395850447eb27","f65d09863fd937d3959d894190b9224359c8ded4","96c28c9d6449e82598270a372d77498cb3828558","a0e2bfd4e2a775528dce5b7a529a3078fa1a8596","3e4c02b303fabe43909d7ffebecbc01bc292c7bb","3b591cb340679c3b20becc7c1bcb179220655d16","7f7aaa46ee2c0ec1de20aecc9c367980a39fee84","0ff55b44ef1d2e19d626a6309ac112b93fad9d34","da6787fd2f1a96557769e0c3805f1de85aeec25e","c339d1334067935da31db76cf752d9c33a48237e","7e908f144df3766f77b5df797126f9f4d9be0d1c","8bfbc114f9f0c517ac10e013b5ea1c4329d6ff71","32973eb8ec47f9a6582594561bd52cb666b75a5c","269cc78772966da23f9c994bd9916f56d616c01e","22a4f4b33f01880f46981fc7868a789f30d87c67"],"title":"Multilevel modelling of the geographical distributions of diseases.","doi":"10.1111/1467-9876.00153"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2011,"outCitations":["b54aeac7ef6a01d8345e0eb50037503affb17a67","3274e12432c2edb5c637fef5dc285f56e4c9d9ac","a6ff22ad3f57b21139e820c0436210ad887a825e","cabd8d37076c9a6ddb047fc7423d754dea765c61","3f7372b15e149c3ab97ed6fb4c8124d485926ad3","0b305dc618a44dce40eed056346d3a69bb61599f","3bb96f6ac76e71053f85f4308aab5988e322842f","e1c6f381601c241d624207aace9865d224886e69","257408770682b0353de4c1ab6c2f63e5fede3e0e","834cdd7792e5cab06fb47e96e4dcb875375b1bac","d07c1ebde55bee4c7d67009abec5f5c5a4163aed","a5f07f7e112bfd89d72961c7124cc450f9445175","3cd0186189f25ccb969b81de352e39c1d6d4c3b4","4a32f0f05779ad869681914a99cd4f95d788562f","a190b4803dd9343acbcf5bf64c1c23c6784745fa","e149d9dbe60db16499ad86e43295ecd200698adc","a569332e6eeb0783ed09a32090c611861d635675","c11b139e059a8a002e5bc6527a1172118699bedb","d0ce6cd74b275afb5a36e0ad8e1c2713de7ce2ba","c552fb8ba78035bfacca376f54ec4670637bc1fa","45d1b3ef9d9be19b8ba567891966ca34791622f7","3010dd74934709134ea8ea30e3248dc51ea4a0ae","88b51eb03f1b0a3449136bbb16b8aa40ed0c1307","691cfad5080d56eec8a5767db1d23e295a88ca8c","a73e838e1e4a9df02ed6655eecba99d5e7a2333f","8445da88c4990baff1d37564ab65a498f1db3c32","d6862e0bbecee2e916c1c09afb1620efed80ec93","a57277d85b43542630b524a628fc8f26691b530b","1cd51784d24e174822864a2a8b0a3845173d831f","8dc2594dc0d22991644df1bf8cc503541b1d9dd7","d1c385827547375efd491dc18ef31462e4008ad1","cb8f2abb4ae58dc980999a180c738ae7fab586be","0583940b9eeec1edf84802209ea63dcb4fcf3010","ae71a67b31ddf5cc30f64ec49413bd8198f3bb18","c5d9f56239a24a41cc91f4c10b0411a6e934b734","f340b3d52d57068914f147602c463269b3898dfd","273fc306cd2da7f3b7d85542f6ea36d9923ced7d"],"journalName":"The annals of applied statistics","paperAbstract":"In the United States the preferred method of obtaining dietary intake data is the 24-hour dietary recall, yet the measure of most interest is usual or long-term average daily intake, which is impossible to measure. Thus, usual dietary intake is assessed with considerable measurement error. Also, diet represents numerous foods, nutrients and other components, each of which have distinctive attributes. Sometimes, it is useful to examine intake of these components separately, but increasingly nutritionists are interested in exploring them collectively to capture overall dietary patterns. Consumption of these components varies widely: some are consumed daily by almost everyone on every day, while others are episodically consumed so that 24-hour recall data are zero-inflated. In addition, they are often correlated with each other. Finally, it is often preferable to analyze the amount of a dietary component relative to the amount of energy (calories) in a diet because dietary recommendations often vary with energy level. The quest to understand overall dietary patterns of usual intake has to this point reached a standstill. There are no statistical methods or models available to model such complex multivariate data with its measurement error and zero inflation. This paper proposes the first such model, and it proposes the first workable solution to fit such a model. After describing the model, we use survey-weighted MCMC computations to fit the model, with uncertainty estimation coming from balanced repeated replication.The methodology is illustrated through an application to estimating the population distribution of the Healthy Eating Index-2005 (HEI-2005), a multi-component dietary quality index involving ratios of interrelated dietary components to energy, among children aged 2-8 in the United States. We pose a number of interesting questions about the HEI-2005 and provide answers that were not previously within the realm of possibility, and we indicate ways that our approach can be used to answer other questions of importance to nutritional science and public health.","inCitations":["88b8d33a5879a77c96631d1cabe42b696b78973f","2fbca7cc936b322a30a9fcf6498ea78096135a42","ce8456f16f3d99dbe39bd6ea127479e407d66b0e","ef24285ebc10770b6960dbaca2494364f76b74e0","46411e2a4d879099580bdf792c442338ee4daaf1","66be03239ed082f53957c4cf2b694ff40a5b96bb","9ac47e1dc85990fe7230e0b9a1ddd484b41d15ab","7f49cbecf12c6987560149e1ad6b96254b9bb329","31e6bec78cb52eaf3988965bc8da87d713329baa","abae0aa551d98782daaca5c9cc5ee1f8f056d7b4","c35931403d3228c9c01108f234683149585193e5","75f92d5f364f157fababb20ce113f22a28032ce7","0bbfd91b5785d4596ca34b5c0f651c9e7f17791c","ff55dce9a59bc5f8de30a4e550b8692477c4cf21","e1c6f381601c241d624207aace9865d224886e69","1153b86810075851c7caa7f2466f7b21d70cb134","9254f8fc9dbf9a165c92a03d8215e943936e713e","1cc48cc99f31bd268b70f5b8b616beece1f41a39","49922b816f56fa6820a7f98712ebad5ec87c936c","f75b4cf95471dcff6622b66a411b65cf64b22e76","2ff2a5035839e1019fdcef6596fb56ef63e9f328","bb65e0548b6df4035a07e18d3c3847421ea24d2b","83008368643a01c52203138e32181a50379e3fb0","8e79bad0606efdfc4ad19dd338661fc9642b1465","5f7e22ab676e1bfa7cf2a90b92e12071bf0f0e27","02eec59a706cd1c70b38e6af9f9eed722eb2643d","d41d02c4690ff8b9684ad71614f75d0d8f454b71","79f48bf1150d2917fe8bdf0de9593dedc21f03c4","1ae05786763a5321dfce4fc856f7953ececc4b8e","ce08b4044d99e58925741ca9dae1c0589cf819bd","aa01bd4d7e538792ab5c546dc527ba704fe976e7","9d862f07a483f3dd4a581bf40570fe57ffae4806","b335f72d5c0248f27e41297f53a304089e456109","b56e031267d5041abe8512df43ec77860617ee24","5c0659804383d9231ce5a64b9b7d45882d7e1d12","9bc4149befa8a3c2041b515e9ebb87a0afdb8c7a","989c6e093a548a491557e3893791f9e31ba2a33b","52abf49fda77c364d91b93f638c3ec296a091487","d3cccfa6076db5d2a5407ea35cfb28b2dcea0cbe","970d3bb87a562c2602c9ea6e7f23c287747bca67","a05f4aa071b7e036e697d17c4d625cc0edc8932f","757da34bf25f153e6584f7944ee0eac02f52c2df","c8800e83fd2b5a2ae638bfddf616cfb0f48b31fa","4ddb4caedb359080fd1efd581bd762e4aec55c3d"],"title":"A New Multivariate Measurement Error Model with Zero-inflated Dietary Data, and Its Application to Dietary Assessment.","doi":"10.1214/10-AOAS446"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2019,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"Nonlinear mixed effect models (NLMEMs) are widely used for the analysis of longitudinal data. To design these studies, optimal designs based on the expected Fisher information matrix (FIM) can be used. A method evaluating the FIM using Monte-Carlo Hamiltonian Monte-Carlo (MC-HMC) has been proposed and implemented in the R package MIXFIM using Stan. This approach, however, requires a priori knowledge of models and parameters, which leads to locally optimal designs. The objective of this work was to extend this MC-HMC-based method to evaluate the FIM in NLMEMs accounting for uncertainty in parameters and in models. When introducing uncertainty in the population parameters, we evaluated the robust FIM as the expectation of the FIM computed by MC-HMC over the distribution of these parameters. Then, the compound D-optimality criterion (CD optimality), corresponding to a weighted product of the D-optimality criteria of several candidate models, was used to find a common CD-optimal design for the set of candidate models. Finally, a compound DE-criterion (CDE optimality), corresponding to a weighted product of the normalized determinants of the robust FIMs of all the candidate models accounting for uncertainty in parameters, was calculated to find the CDE-optimal design which was robust on both parameters and model. These methods were applied in a longitudinal Poisson count model. We assumed prior distributions on the population parameters, as well as several candidate models describing the relationship between the logarithm of the event rate parameter and the dose. We found that assuming uncertainty in parameters could lead to different optimal designs, and misspecification of models could induce designs with low efficiencies. The CD- or CDE-optimal designs therefore provided a good compromise for different candidate models. Finally, the proposed approach allows for the first time optimization of designs for repeated discrete data accounting for parameter and model uncertainties.","inCitations":["d3367c9f9086a6437eb32d35f383abae42c18ad1"],"title":"Robust designs in longitudinal studies accounting for parameter and model uncertainties - application to count data.","doi":"10.1080/10543406.2019.1607367"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2007,"outCitations":["c9381b0a02b8400af167eebf78f9c5e45c7fa2b9","97e37fca5e7b4fdb97ad373be6e2143458eb571a","8be8ce6a2a27093c8a4bab1a1ac48b0a061c78bb","82dfbce5d51d319bfdd7e6675a863c44b39efa49","d7770551bab20d8c7e5f18dd9288d999325b2326","3107eb5248a18393cd31dba067d962022a7f2312","643a32df31779c79602579595e0f416b23db2754","be90348fcd7e5043904e417575ec12cf07219ece","e75dd2d53718243b174eda80b1e4e8e5111588ec","20a697445957a82fdcaeb97bbc09900665a058b7","ee2d27ba808f0d9aa9fed96bd58a987acd1275f0","8e56bfcfd626cdb65397523ed5aabc957d0dc2bc","80be13a65a63c965e824bba25191908e6c66d2c5","acbc9d68243aafc701f0a6782520c4324beb37f4","b6a5d96dd85c20fcd77bcdc5f80532a08161817d","f558afeec9667b66995b46e306bcf5aabc2898b5","fb1bb4ad7cce4cb3c1cd09f67dad2ef2584985a2","d8e3f5dacc7237370697dc9a44b7e5bfcf37a0b8","43498420375c6def2e58544dcd92fcd6f065e459","9c36b95de793e1ee8880b7af2a24049b3490858f","af2859f928ba64c1973bf080aaf7706f6f016da2","c3ce69a2dbb178fa14b4201c8364960f23fd56c6"],"journalName":"Biostatistics","paperAbstract":"While epidemiological data typically contain a multivariate response and often also multiple exposure parameters, current methods for safe dose calculations, including the widely used benchmark approach, rely on standard regression techniques. In practice, dose-response modeling and calculation of the exposure limit are often based on the seemingly most sensitive outcome. However, this procedure ignores other available data, is inefficient, and fails to account for multiple testing. Instead, risk assessment could be based on structural equation models, which can accommodate both a multivariate exposure and a multivariate response function. Furthermore, such models will allow for measurement error in the observed variables, which is a requirement for unbiased estimation of the benchmark dose. This methodology is illustrated with the data on neurobehavioral effects in children prenatally exposed to methylmercury, where results based on standard regression models cause an underestimation of the true risk.","inCitations":["2cceca0f7cecf678994f1293515bc48d3ffacf20","2579ad058206c6411832a370e2ff3a88ba975c0c","c1d08bb008753396bcd2c45cf755b0fa173feaad","06082a0a18d8693ea4c60e41877527c85e84d602","e8ee84d0b3e6af64049b4cc4212d5b89611e2c1e","14bf25c8454b4ed98419c7f1d35900985642fbe1","6b1c5dc0a24b774da02ae5a2d8d68c1bd3d15853","eceae49fc0a1e139d1b02d908525653d3c48030c","cd73431fb5a40613e68b9de56110879946500685","cb9c39f30cc352b9a67945c10e5dfbd67e4c3ef2"],"title":"Estimation of the benchmark dose by structural equation models.","doi":"10.1093/biostatistics/kxl037"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2010,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"","inCitations":["7b91632278d0b9b6aa89965e4a695dbba94ab1be","9618c9e22b80100b005c223ecc7b772dea74e98c","4e88f73030ba7423ee67eedba74a8c14fe82d81a"],"title":"Comments on the FDA draft guidance on adaptive designs.","doi":"10.1080/10543406.2010.514458"}
{"fieldsOfStudy":["Computer Science","Medicine"],"year":2008,"outCitations":[],"journalName":"Journal of statistical software","paperAbstract":"Internal pilot designs involve conducting interim power analysis (without interim data analysis) to modify the final sample size. Recently developed techniques have been described to avoid the type I error rate inflation inherent to unadjusted hypothesis tests, while still providing the advantages of an internal pilot design. We present GLUMIP 2.0, the latest version of our free SAS/IML software for planning internal pilot studies in the general linear univariate model (GLUM) framework. The new analytic forms incorporated into the updated software solve many problems inherent to current internal pilot techniques for linear models with Gaussian errors. Hence, the GLUMIP 2.0 software makes it easy to perform exact power analysis for internal pilots under the GLUM framework with independent Gaussian errors and fixed predictors.","inCitations":["e8269f2071766ba8e90037c38f258e65379a26ae","477eb5fa6937c894a4d16757ce8a0f24148ae785","43f3529d674cdd693f0013101cfe7329c8d0d86d","a475a57211c5bd2d96867946bb77ee14c62489ab"],"title":"GLUMIP 2.0: SAS/IML Software for Planning Internal Pilots.","doi":"10.18637/jss.v028.i07"}
{"fieldsOfStudy":["Medicine","Mathematics","Computer Science"],"year":2014,"outCitations":[],"journalName":"Journal of statistical software","paperAbstract":"Finite mixture modeling provides a framework for cluster analysis based on parsimonious Gaussian mixture models. Variable or feature selection is of particular importance in situations where only a subset of the available variables provide clustering information. This enables the selection of a more parsimonious model, yielding more efficient estimates, a clearer interpretation and, often, improved clustering partitions. This paper describes the R package clustvarsel which performs subset selection for model-based clustering. An improved version of the Raftery and Dean (2006) methodology is implemented in the new release of the package to find the (locally) optimal subset of variables with group/cluster information in a dataset. Search over the solution space is performed using either a step-wise greedy search or a headlong algorithm. Adjustments for speeding up these algorithms are discussed, as well as a parallel implementation of the stepwise search. Usage of the package is presented through the discussion of several data examples.","inCitations":["b29daca979a859cc29b3723253a963b5a58e0d9d","ab8c400667532b887ddd43d11a9f1c3f93b27671","b00f7aac6d8afc205dc654713915cd2a9625e1fb","eec9e98647abdb42bd6b649e24e6d0469f1fd7d4"],"title":"clustvarsel: A Package Implementing Variable Selection for Gaussian Model-Based Clustering in R.","doi":"10.18637/jss.v084.i01"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2016,"outCitations":["5ade2d9f7d4ff693d0576f19413c636006e6135c","d69c51883155898c28b941d2a3734e6234ed571b","ddd660f2a83ec98ebb7f0b96499822b8ff35d24b","dd1137e2fa1ae5b9170fc9847b94356eafc71bd6","b1958f8a8b817575a2049b00874dda94d766be34","30c246a0d502f05204a4ff8e43cfd315941a1f51","ded13118adb4e97b16c4d8d9630d186c4dfbebff","305c1929f9b5cd60aede21b30b7f6fb65b31dbd3","ac698a726f5efc3abbeb85f99b35ce724253188b","13d4c2f76a7c1a4d0a71204e1d5d263a3f5a7986","a6563be2bbc0a9b1ebf54362916ae0cb22db46b7","26213739650e7afc9ea576c9b4d9115d9a222351","cebab2eb16f50cc2a456fd8f2d36f5db32cbfee4","2219b330ef98f6ea71a172659595b7506fca3633","d158680063539d86a18b1d47c8b59df375bd6b9c","2b8a052efd4b3831178e469de18a67094121ab93","2d611458f70a315dec999cd044def11b28920a0b","4c7329ee6b7080574e3886505b03f8b5b84e64bb","faf481fa68a00820555fd0411f35e066d0e6b90d","9d614c928f31491bd5d6b8c654d09912f03d520b","126a25352db3bd310b7e48df9604e26b2b8d3e2a","4954e15d9aebb0a0b8be48bfe213f410ea5e390b","dd1fc7669c1d98bdf79343ebd997b1dbdcceb387","1b2aa5577f66c1d7a79c6c3a03ed6d95ead3ec81","d0a5215059245596077008d6aaae90fd20fd302e","8e5f1b2673e28a77ed5286cfad59c204384f35d0","97510e2048af0c6c510aed405091514946c4eb13","c0b55888629592a7b5039905ab096a6003506aef","f89be3aa29635b1e7f6c8bb40d9aa81acaf41fa5"],"journalName":"Journal of the Royal Statistical Society. Series C, Applied statistics","paperAbstract":"In this article, we examine the causal effect of parental restrictive feeding practices on children's weight status. An important mediator is children's self-regulation status. Recent approaches interpret mediation effects based on the potential outcomes framework. Inverse probability weighting based on propensity scores are used to adjust for confounding and reduce the dimensionality of confounders simultaneously. We show that combining machine learning algorithms and logistic regression to estimate the propensity scores can be more accurate and efficient in estimating the controlled direct effects than using logistic regression alone. A data application shows that the causal effect of mother's restrictive feeding differs according to whether the daughter eats in the absence of hunger.","inCitations":["8d7804bc9937fce59fa2608e07d27ab2b270b03d","f29f639c78f657e47dc2db609c629eb68da27973","3583f2a253dd7b910c265da34eaddaf00d38dbfe","631a2cc5447aa8820dab9e11f41c2a6fbbab8e8e"],"title":"Estimating controlled direct effects of restrictivefeeding practices in the 'Early dieting in girls' study.","doi":"10.1111/rssc.12109"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2010,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"In clinical trials, examining the adjusted treatment difference has become the preferred way to establish non-inferiority (NI) in cases involving a binary endpoint. However, current methods are inadequate in the area of covariate adjustment. In this paper, we introduce two new methods, nonparametric and parametric, of using the probability and probability (P-P) curve to address the issue of unadjusted categorical covariates in the traditional assessment of NI in clinical trials. We also show that the area under the P-P curve is a valid alternative for assessing NI using the adjusted treatment difference, and we compute this area using Mann-Whitney nonparametric statistics. Our simulation studies demonstrate that our proposed methods can not only control type I error at a predefined significance level but also achieve higher statistical power than those of traditional parametric and nonparametric methods that overlook covariate adjustment, especially when covariates are unbalanced in the two treatment groups. We illustrate the effectiveness of our methodology with data from clinical trials of a therapy for coronary heart disease.","inCitations":["63c1b363153481f645fc5fb526fdf449a05254ff"],"title":"Two new covariate adjustment methods for non-inferiority assessment of binary clinical trials data.","doi":"10.1080/10543406.2010.494267"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2017,"outCitations":["6ae01c34a5845ad3e2bba32d14f28a0aeb9d9534","87954e4f5b7b46107f126dc1809ba167b50ff039","800b9673e4511a6a4ed65445d2371e844af02142","42e0a370814bec52294b63a3e6b79ef4c3a4b775","ab6f93e93f5e40f5c6425501a4dabf865ce897d0","480be04d6b9eb577eb51a0af8813b32363ca0a91","e582469e3eed0bcb5c458ff5fd200f5acdbe0d33","d801e1af249bda4013832f71b0d0185e9a8e29f3","506ff50f25e835ff35f8d7e004c290d40599187d","fdc95bc36ae3cdbab853e12198f3456cf8901877","8a25ae38cab87409fdab754bfc7535c0f8ddb980","400b45a803d642b752a84147ef547af7811e8f3f","99334f3ea4b5d6a4d0cf444d257037cbd644d16b","dab8c701d1f1c9134a5994515c07c919e8eb9db6","b4783800c2fdc455e58a50dd42a1aa2d85c4c830","b7294ac444ae927f71ac442372903ff5e2a763e1","86eb601d98e20cfd30415b1e7d82e80fa95781f1","8e7ed0922e9af120a20ccaaa53158c26354683b7","0f2550ee06c6cfadb8dc52fc6744b8b11aeadc8c","bd1f14e7531220c39fad8f86985cce7b283f035d","51bcfef92aef96df37b25bd1ed7c096142107007","3f600e6c6cf93e78c9e6e690443d6d22c4bf18b9","eaa92825507c32ea70821f608adf8c6ebebfddbd","3e0176ecce5a3520a162495f55ea2c4557018e67","4ead4d868721e8b38c266415a1f6201cd147a78a","949b73ad00033edc9fc35f4170756bf0ff08c36f","182f77976b08d832b5cdc7debdaeacc300c8e723","f1d3d313a723c9eaeef496244edcfefeae237feb","8537f7d886fa75957d269336efb66ce0d4c1a58e","3c7d33f8d1f3450657a1de2e5dd56f2b35db658e","18f355d7ef4aa9f82bf5c00f84e46714efa5fd77","d68cdf570a2de762cecad738a5f8693a8fc5a961","0093f3de836f464169bf11a612b46f25200558c0","8091181fc405c8aa8416adaffd0e0a2d11dafe86","18050a6c578c16c6abbc74da5e73eb210e9c11be","17d2f027221d60cda373ecf15b03706c9e60269b","acff2ad53b2ef7e3c6a7419768c6c87e4394ed2c","83730969c0686b1d185bcca39f9b5743fa53ebc1","b477dd12dd49e44a62c1a303501df5fb6706c7e9","e5e82951b8ae1d831549a5e22c7196fd875de421","25ab3b2d0dacc3aa4788ef47aa5967a26867213b","14821ac1bf09890a857fca2a6c324e8c85f2c0d0","c63d87c57c3e61b961ca6909d0fa05d6e456afdb","995e43cf5a2fb25f4c8dfe8c92413917f95ecad6","8112c4305b88d85199267e9e03d3a0aca4432059","05175204318c3c01e3301fd864553071039605d2","fcc9ea4a0620b76dfeab95aecf1dd0356d1e6e57","4683ee17a102066e272d658c9fcb4a933586af11","8fb6b1b98efb824338f3ddcf85f8ff23661f0e28","7fe59a873246a62128549c29cb3543cb9390f1d5","62791257ac277db2b314bbb18e13bee48533ae0c","78a32538627620fef162596271e0f91abe408b3c","9f9e71a9bb60ee1169d599df635ae874cec14f3e","fa505dbd4816c6cc704a9abafac515cfcceae33a","657bd455382a141e623665cf7e30acbfd8175533","ef1a3854f8336398d71e88a785263d92a704576e","04b23f577c20d1a0e2a67aadda555f58e6d23d6e","9a7332e7af8e9faf832c59c1fb0b985bfccd0b53"],"journalName":"Journal of computational and graphical statistics : a joint publication of American Statistical Association, Institute of Mathematical Statistics, Interface Foundation of North America","paperAbstract":"A number of classical approaches to nonparametric regression have recently been extended to the case of functional predictors. This paper introduces a new method of this type, which extends intermediate-rank penalized smoothing to scalar-on-function regression. In the proposed method, which we call principal coordinate ridge regression, one regresses the response on leading principal coordinates defined by a relevant distance among the functional predictors, while applying a ridge penalty. Our publicly available implementation, based on generalized additive modeling software, allows for fast optimal tuning parameter selection and for extensions to multiple functional predictors, exponential family-valued responses, and mixed-effects models. In an application to signature verification data, principal coordinate ridge regression, with dynamic time warping distance used to define the principal coordinates, is shown to outperform a functional generalized linear model.","inCitations":["e0697717ad2c81593ae3ee04b0f6164855096896"],"title":"Penalized nonparametric scalar-on-function regression via principal coordinates.","doi":"10.1080/10618600.2016.1217227"}
{"fieldsOfStudy":["Computer Science","Medicine"],"year":2016,"outCitations":[],"journalName":"Biostatistics","paperAbstract":"A dynamic treatment regime (DTR) is a treatment design that seeks to accommodate patient heterogeneity in response to treatment. DTRs can be operationalized by a sequence of decision rules that map patient information to treatment options at specific decision points. The sequential, multiple assignment, randomized trial (SMART) is a trial design that was developed specifically for the purpose of obtaining data that informs the construction of good (i.e. efficacious) decision rules. One of the scientific questions motivating a SMART concerns the comparison of multiple DTRs that are embedded in the design. Typical approaches for identifying the best DTRs involve all possible comparisons between DTRs that are embedded in a SMART, at the cost of greatly reduced power to the extent that the number of embedded DTRs (EDTRs) increase. Here, we propose a method that will enable investigators to use SMART study data more efficiently to identify the set that contains the most efficacious EDTRs. Our method ensures that the true best EDTRs are included in this set with at least a given probability. Simulation results are presented to evaluate the proposed method, and the Extending Treatment Effectiveness of Naltrexone SMART study data are analyzed to illustrate its application.","inCitations":["0bc82b04c12106f667f688cce5990718a81c2a9b","3f018e77860b5daa8e97fe66c9db38c472681fb4","ab51c96ee7a287b56140fc3ce43446b980b2f30f","41a04853a09d1d958e223eb5f8cbe9c648ef2532","b6ae481f46ddc7f67f5fc0ab052c7dad78357699","f4d0ccacd7b2f8c7ec7566924bce74734e82c0d7"],"title":"Identifying a set that contains the best dynamic treatment regimes.","doi":"10.1093/biostatistics/kxv025"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":1999,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"Many clinical trials have time-to-event variables as principal response criteria. When adjustment for covariates is of some importance, the relative role of methods for such analysis may be of some concern. For the Wilcoxon and logrank tests, there is an issue of how covariance adjustment can be nonparametric in the sense of not involving any further assumptions beyond those of the logrank and Wilcoxon test. Also of particular interest in a clinical trial is the estimation of the difference between survival probabilities for the treatment groups at several points in time. As with the Wilcoxon and logrank tests, there is no well known nonparametric way to incorporate covariate adjustment into such estimation of treatment effects for survival rates. We propose a method that enables covariate adjustment for hypothesis testing with logrank or Wilcoxon scores. Related extensions for applying covariate adjustment to estimation of treatment effects are provided for differences in survival-rate counterparts to Kaplan-Meier survival rates. The results represent differences in population average survival rates with adjustment for random imbalance of covariates between treatment groups. The methods are illustrated with a clinical trial example.","inCitations":["7950f737021d562dd881b851cf92e511b339e309","6ff050437008bbe6b21aa208fdf1a3e7c6cd85a8","51d5b862e68b31a24cdfdfa3cd43d6a941040ba3","b052fe7531b9e15aa3219eaee21b4c979d8648d6","df368bdb16d3b1d042f3f830fd04b58215278d4d","0fa6a5b47ffbde44637657be817a0088a6f4c57b","f5d4537d1c1e1c2e42a79a0ec794ad49fbaa257b","ef4c7472cc62426462b4bf938d1ade706f6582fb","964358fd6537b20738b3eda328241a036483b49a","aadfecb392b4c60d6fe90e51f81390281ca4a6fe","50d5e0edd7dc2bc8d8973ecf5097196e8efd20d1","17dde866ca8d00a9a409f610385b8eafd0aa11f0","d65abf85fa31cce691db20cc75f2862ba539254e","3994d55da7bb1edc8d220b7801fff1ec8315abaa","3f136e26cae5255c8ca324cf387189b25616e6e8"],"title":"Nonparametric analysis of covariance for hypothesis testing with logrank and Wilcoxon scores and survival-rate estimation in a randomized clinical trial.","doi":"10.1081/BIP-100101179"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2005,"outCitations":[],"journalName":"Biostatistics","paperAbstract":"Simple tests are given for consistency of the data with additive and with multiplicative effects of two risk factors on a binary outcome. A combination of the procedures will show whether data are consistent with neither, one or both of the models of no additive or no multiplicative interaction. Implications for the size of the study needed to detect differences between the models are also addressed. Because of the simple form of the test statistics, combination of evidence from different studies or strata is straightforward. Illustration of how the method could be extended to data from a 2xRxC table is also given.","inCitations":["fa502f4e58357643f270f1fb64a3040818151b9b"],"title":"Additive and multiplicative models for the joint effect of two risk factors.","doi":"10.1093/biostatistics/kxh024"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2001,"outCitations":[],"journalName":"Biostatistics","paperAbstract":"Biomedical trials often give rise to data having the form of time series of a common process on separate individuals. One model which has been proposed to explain variations in such series across individuals is a random effects model based on sample periodograms. The use of spectral coefficients enables models for individual series to be constructed on the basis of standard asymptotic theory, whilst variations between individuals are handled by permitting a random effect perturbation of model coefficients. This paper extends such methodology in two ways: first, by enabling a nonparametric specification of underlying spectral behaviour; second, by addressing some of the tricky computational issues which are encountered when working with this class of random effect models. This leads to a model in which a population spectrum is specified nonparametrically through a dynamic system, and the processes measured on individuals within the population are assumed to have a spectrum which has a random effect perturbation from the population norm. Simulation studies show that standard MCMC algorithms give effective inferences for this model, and applications to biomedical data suggest that the model itself is capable of revealing scientifically important structure in temporal characteristics both within and between individual processes.","inCitations":["ea2d96ba5b45cbd38e134320b85aa331895afab9","252ed5976a835ab15be54935bd421ca2e68c4488","962ea45576c07b33e90fcd0694c07d5d40e487d7","905f0e11f4cd678c72b31d3765e4bd7430fa0d08","1d37c048cf972d80882cec7ab087d912731d29c6"],"title":"Semiparametric models and inference for biomedical time series with extra-variation.","doi":"10.1093/biostatistics/2.3.261"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2013,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"For a clinical trial incorporating a group sequential test that allows early stopping for efficacy or futility (GSTEF), the primary hypothesis concerns efficacy. However, the type II error probability of the tests of efficacy is neither specified nor known. The type II error probability of a GSTEF is partitioned into the sum of its component type II error probabilities of futility and efficacy. This partitioning provides transparency, allowing researchers flexibility to set these component error probabilities directly and to know the impact on the total type II error probability and vice versa. This transparency and flexibility should improve the application of GSTEF to clinical trials.","inCitations":["9290e054b4a6021aac8f753af798d42a1e1493d8"],"title":"The type II error probability of a group sequential test of efficacy and futility, and considerations for power and sample size.","doi":"10.1080/10543406.2011.617229"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2009,"outCitations":[],"journalName":"The British journal of mathematical and statistical psychology","paperAbstract":"In this paper we argue that model selection, as commonly practised in psychometrics, violates certain principles of coherence. On the other hand, we show that Bayesian nonparametrics provides a coherent basis for model selection, through the use of a 'nonparametric' prior distribution that has a large support on the space of sampling distributions. We illustrate model selection under the Bayesian nonparametric approach, through the analysis of real questionnaire data. Also, we present ways to use the Bayesian nonparametric framework to define very flexible psychometric models, through the specification of a nonparametric prior distribution that supports all distribution functions for the inverse link, including the standard logistic distribution functions. The Bayesian nonparametric approach provides a coherent method for model selection that can be applied to any statistical model, including psychometric models. Moreover, under a 'non-informative' choice of nonparametric prior, the Bayesian nonparametric approach is easy to apply, and selects the model that maximizes the log likelihood. Thus, under this choice of prior, the approach can be extended to non-Bayesian settings where the parameters of the competing models are estimated by likelihood maximization, and it can be used with any psychometric software package that routinely reports the model log likelihood.","inCitations":["cbe7a09d04a745fe6a0a245d44fb6aacac4d502f","f6b0de889859cc8a39c295ea9918a0b2f3b07877","f6fc7480f8149f3228e4ac4a42bb864fa68b1340","19484c73ac3e36ef6b6cae508dbf0a84197c5f32","13de93f54b37ce4ba16106c963086c910c8745b3"],"title":"Coherent psychometric modelling with Bayesian nonparametrics.","doi":"10.1348/000711007X246237"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2011,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"There are many ways to bootstrap data for multiple comparisons procedures. Methods described here include (i) bootstrap (parametric and nonparametric) as a generalization of classical normal-based MaxT methods, (ii) bootstrap as an approximation to exact permutation methods, (iii) bootstrap as a generator of realistic null data sets, and (iv) bootstrap as a generator of realistic non-null data sets. Resampling of MinP versus MaxT is discussed, and the use of the bootstrap for closed testing is also presented. Applications to biopharmaceutical statistics are given.","inCitations":["7153cdaf712f35a653ce34a72f0a287e80774a4e","73206c9a24c36cd77d0dbc56fe7e0c572222fd91","9971afff030a1f2e84d1be1d2610a9724bf75c04","7a41e934961e7c9bad6c78c29a2c66bdbaa42b40","2039ab37153c000eabc2c647533005d112b5bb53","247b501cb360c1882d5e53d72b79897c6cc7b77b","fa70c80bd4beb354dfdf5ca683f276aafe5ab25c","a28c02d7128658ffa6b465230fb4c306f62e9ccc","3186f22468e2505a2ff181d5f644c58f6d564828","6a13b3a19ff87a8e03cd2a9e2e6b4fc4f1cdd598","d9c9557f969696401db8a90092d16ba6549d0c77","5ad745051464cb74dca903db257bc150ba95c099","5807994fbb009717a2cab51cc424066e36db213d","312e6666e12def67ed7f4988ba7f184433f102e0","551681b1a2ab85a242c4395bb8355f4ed554e847","ccce4bfb07c85f492d10b234cb20bcd36742e99a","c2b91019be7ed6b831873ef2631734dd066d5368","8b6f8cf9da9007b2b8c6d868bfdff26a1bf441d7","de16e411295e74cbbb1ac68fc47113d7c812926b","319cfaa03e53db5b6237ad524de1ee22cde7dec0","d5ea9be8a7ff0ae5ef101d5bb040b77f94c2b40f","abfb2c23d357ebc82a73962a018a9e4cdf0d3221","b2cd96beec70537546d5c6fcb0f6b7911446d278","dac5275be872bcb7cc26787801a8e9cc293e8590","fd5c7d61d1b1a0b65b41d80b3c10ee85f0328884"],"title":"On using the bootstrap for multiple comparisons.","doi":"10.1080/10543406.2011.607751"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2011,"outCitations":["a372c0a7636f0402475521158cbe714b3e20c677","d476bd7b8175aafc611a6f4ee53914da9672f30d","840c0cdb1f428d300cd7986d170da5f807b3d20d","12aebfab697b58c761d69fdc3be98580ea9f65c0","b61ecd5940c16d6fdfb505d3cac0c64edaee8311","09b2a5a291ad1355fb42626dddcbfffdd801a1b0","47f4b51e66d19fdc8feef5421aeb89f72acf44a3","2c65e74142ac0fe999212ec1d60346520a6a9190","0ee8b2999019216bc860ea5f6a51a56cedca17ea","33a885858d8cbc3b9918b7592130ce2d82332b56","e3841b601bef933ce64aee7cf9988fed823136fc","bf3a8dfa1157ec1608eec9a6d2e73dc5971153f9","fcef2258a963f3d3984a486185ddc4349c43aa35","aed0a148d5c6775f6b906b9b8a5d58dd6dac99d7","830731f28bf7c77cb289d5331638d26d41cfb775","d49b166f8c11dabebedb85339d8b8620af18efc4","781df52cce1b41509a47ba54366078891d43e38c","3ba242a0a36158bfafb989d5685b3c8f00096b03","2c8ec6b1e8eb342786028dbf9babe5f61094ff20","bf78a18dd547155c83eda81de3fb75321ef143e5"],"journalName":"Pharmaceutical statistics","paperAbstract":"Large databases of routinely collected data are a valuable source of information for detecting potential associations between drugs and adverse events (AE). A pharmacovigilance system starts with a scan of these databases for potential signals of drug-AE associations that will subsequently be examined by experts to aid in regulatory decision-making. The signal generation process faces some key challenges: (1) an enormous volume of drug-AE combinations need to be tested (i.e. the problem of multiple testing); (2) the results are not in a format that allows the incorporation of accumulated experience and knowledge for future signal generation; and (3) the signal generation process ignores information captured from other processes in the pharmacovigilance system and does not allow feedback. Bayesian methods have been developed for signal generation in pharmacovigilance, although the full potential of these methods has not been realised. For instance, Bayesian hierarchical models will allow the incorporation of established medical and epidemiological knowledge into the priors for each drug-AE combination. Moreover, the outputs from this analysis can be incorporated into decision-making tools to help in signal validation and posterior actions to be taken by the regulators and companies. We discuss in this paper the apparent advantage of the Bayesian methods used in safety signal generation and the similarities and differences between the two widely used Bayesian methods. We will also propose the use of Bayesian hierarchical models to address the three key challenges and discuss the reasons why Bayesian methodology still have not been fully utilised in pharmacovigilance activities.","inCitations":["f796a81098ec78b67b87ddc6ceeefc3cc47311d1","49f9d03a94318f7a567824207e62b1e9948913eb","47a1c08cbb8b572e67221410ab64484e88c0a565","cd7e52799b266b6e5563af4f3b1bec314a90ffdd"],"title":"Why a Bayesian approach to safety analysis in pharmacovigilance is important.","doi":"10.1002/pst.524"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2011,"outCitations":["8bd0e6e87d19436fe8c3344697bc4d11bed9adca","0fee515a80761c6c28d22f8d3180833653742678","4f782c26ad7465c7fdf11976199290b8cb5bbffe","eb4d812c9bf8a08cf086a6f0a51b25d72bef9da6","0b58a7ff0a754cc56827f9440aac86aa17f15bb8","c03f16c557d001b1a3ee21b3918741380498d6bd","eb15ade1574c3541b94952e973c30552efc8a727","5005bcebb8ed17596badd8c183cd32569f41d007","b18e36811e1693558199ae4d3baf7f8577fb129a","b20acd06f95538c244fff544300a7761926efd5f","20b4b8ef5c3650f0477f0840d0e2fabeaf5ba5d7","2391a4a974daa44ff3e0750b3379a096a65a3ade","c26c47c5d824fecd45b860e85e7767ec38782d8d","9973abb4e77d640ab6f0c40e8077d190b1185f57","a4876f9f66bac302fc07c3edc87a9877578431b5","eca1e888fa145e70b43aa81a7cc8feec950e143d"],"journalName":"Journal of statistical planning and inference","paperAbstract":"A generalization of the Probit model is presented, with the extended skew-normal cumulative distribution as a link function, which can be used for modelling a binary response variable in the presence of selectivity bias. The estimate of the parameters via ML is addressed, and inference on the parameters expressing the degree of selection is discussed. The assumption underlying the model is that the selection mechanism influences the unmeasured factors and does not affect the explanatory variables. When this assumption is violated, but other conditional independencies hold, then the model proposed here is derived. In particular, the instrumental variable formula still applies and the model results at the second stage of the estimating procedure.","inCitations":["8642f8e2f4364b64f8f085704272a13fbeb04511","ee94652ff1bfc9fc50dbab72e0ed6cb4512b171b","83610cfe32899d5efb402b3af46a956219b63d51","5fe140c95486d80dca182645d517ce6b045d9366","de7c09c454a3eabe601fa19c4787d65ffd743685","7d5e10b199802f69c3567d622061c999c1e90ee1","b7d2fa88d29acbf7a722e8f2e68d2f81492d6380","7f8807de90a3d5c7b0718c883cc4ba4bce10786d"],"title":"On the estimation of a binary response model in a selected population.","doi":"10.1016/j.jspi.2011.04.014"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2013,"outCitations":["bfbcd0d4018f5755e25d65df3ac9ad3552542577","84589205ea01f6d51d85b03bf159e732339389ff","90d45f0f452c640ff3daf4354c230e03f91c81e9","0b00fa2d50376bf876354c93bc616cdb7f4c1be2","e4fa7314c6ade3e55f716a35c2c99801cf184f02","f6c90f40fa584533c6ef8887ef7fec2cae032632","e45b74bf3ede47ff25dee775800d16cfdf01cfdc","3baf28e87d22cb1aedcfd8ca81ca09a3770ca777","4e6867f8e851ccaa953c83de62740dc7d917be2a","31f49b63a562fcdd995b70f09a0e9c3b47732fb8","8c268326ff1a9f612811bd44b72abfaa097c7d8c","9654e976b2ef363c77b51bd9dce253e14e4d34d8","c264816a1963f5d3c6beaedbcb4679599dca1353","6f259a3047fcb94194ac1ae7ee6adc62220c86c7","8f7324234a5aafc7c8bc854f396b9d202bb3ea5b"],"journalName":"The British journal of mathematical and statistical psychology","paperAbstract":"I am pleased to have the opportunity to comment on this interesting and provocative paper. I shall begin by citing three points on which the authors happily depart from existing work on statistical foundations. First, there is the authors’ recognition that methodology is ineluctably bound up with philosophy. ‘If nothing else, ... strictures derived from philosophy can inhibit research progress’ (Gelman& Shalizi, 2013, p. 11). They note, for example, the reluctance of some Bayesians to test their models because of their belief that ‘Bayesian models were by definition subjective’, or perhaps because checking involves non-Bayesian methods (p. 4, n. 4). Second, they recognize that Bayesian methods need a new foundation. Although the subjective Bayesian philosophy, ‘strongly influenced by Savage (1954), is widespread and influential in the philosophy of science (especially in the form of Bayesian confirmation theory...)’, and while many practitioners perceive the ‘rising use of Bayesian methods in applied statistical work’ (p. 9), as supporting this Bayesian philosophy, the authors flatly declare that ‘most of the standard philosophy of Bayes iswrong’ (p. 10, n. 2). Despite their qualification that ‘A statisticalmethod can be useful even if its philosophical justification is in error’, their stance will rightly challenge many a Bayesian. This will be especially so when one has reached their third thesis, which seeks a new foundation that uses non-Bayesian ideas. Although the authors at first profess that their ‘perspective is not new’, but rather follows many other statisticians who emphasize ‘the value of Bayesian inference as an approach for obtaining statistical methods with good","inCitations":["6278aeab8c1b509d4da0391157033698ca1f8262","3baf28e87d22cb1aedcfd8ca81ca09a3770ca777","e36b64fd23116f335253fcc06a78d746fcae8881","d6e8978cba1c3bc03106d2d08db29d0085e7dfad"],"title":"The error-statistical philosophy and the practice of Bayesian statistics: comments on Gelman and Shalizi: 'Philosophy and the practice of Bayesian statistics'.","doi":"10.1111/j.2044-8317.2012.02064.x"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":1997,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"Contrasts were evaluated for the maximum blood or plasma concentration (C(max)) of drugs measured after repeated and single oral administrations. Variances of C(max) were calculated and also simulated for a single drug as well as the comparison of two formulations, i.e., for the analysis of investigations of both bioavailability and bioequivalence. The coefficient of variation (CV) of C(max) was higher in the steady state than after a single drug administration when the variability of the disposition rate constant (k) was substantially larger than that of the absorption rate constant (k(a)). In turn, the CV of C(max) was substantially lower following repeated than after single drug administration when the variability of k(a) dominated that of k. The latter condition often prevails in practice since the relative variation of absorption rates generally substantially exceeds that of clearance (the latter being proportional to k). The statistical insensitivity is superimposed on the low kinetic sensitivity exhibited by C(max) following repeated drug administrations. Consequently, bioequivalence trials conducted in the steady state generally permit a declaration of equivalence even between drug products that have very different absorption rates.","inCitations":["225d7f1b245f01eb69643bba3e9f4a3e3a434475","8a0e0f978649508c9824b4f73f8e11506d2dea78","62a4953a3e716755545ea3f26a064a393eca8a15","f798d5f4693d3eeb63d678b02f6bd52386f83fcc","b29c21744172389795eb4b87e66a8638edaf3c09","bd1aceed6641eea0ea891a6df4bc9be48d059249"],"title":"Variation of the peak concentration following single and repeated drug administrations in investigations of bioavailability and bioequivalence.","doi":"10.1080/10543409708835179"}
{"fieldsOfStudy":["Materials Science","Medicine","Mathematics","Physics"],"year":2006,"outCitations":["2943ad62e51ce79321a5a8fc9b311b4fb86f7332"],"journalName":"Journal of statistical mechanics","paperAbstract":"The Cellular Potts Model (CPM) successfully simulates drainage and shear in foams. Here we use the CPM to investigate instabilities due to the flow of a single large bubble in a dry, monodisperse two-dimensional flowing foam. As in experiments in a Hele-Shaw cell, above a threshold velocity the large bubble moves faster than the mean flow. Our simulations reproduce analytical and experimental predictions for the velocity threshold and the relative velocity of the large bubble, demonstrating the utility of the CPM in foam rheology studies.","inCitations":["f588e219c98b81615fe22e97ebe3a573430d430d","6fde2c8cf833c4d639139455d72fb3b85f48c455","03805349b3ef6396d2ea4ce417b25c7b0faebfb1","69606021416a3e8ade13cdc0ec1d2a56783c274b","6f640c4124d4d86a9538956c4b6239ff59030074","3379c36d223ec8b2fd69253dcc0576df28f3a8de","fda777ffa5d88826dc2e9b5161d9e3133d787b7d","461b41f16b17a65763f4cfe6df2cb91df19b0e0f","0d7734de7d4b14787b177ec288797f7326bb4035","7db9381e40748ca21ee4fe9c664917f81b24bace","4a9334268c4493180b66a605984356018b40416a","16c13691ac0437c05a6faf5c999218a2d55b87d6","642b777ad02fac10b416edb0eb291a4495dda5cf"],"title":"Viscous instabilities in flowing foams: a Cellular Potts Model approach.","doi":"10.1088/1742-5468/2006/10/P10008"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2015,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"Hypoglycemia has long been recognized as a major barrier to achieving normoglycemia with intensive diabetic therapies. It is a common safety concern for the diabetes patients. Therefore, it is important to apply appropriate statistical methods when analyzing hypoglycemia data. Here, we carried out bootstrap simulations to investigate the performance of the four commonly used statistical models (Poisson, negative binomial, analysis of covariance [ANCOVA], and rank ANCOVA) based on the data from a diabetes clinical trial. Zero-inflated Poisson (ZIP) model and zero-inflated negative binomial (ZINB) model were also evaluated. Simulation results showed that Poisson model inflated type I error, while negative binomial model was overly conservative. However, after adjusting for dispersion, both Poisson and negative binomial models yielded slightly inflated type I errors, which were close to the nominal level and reasonable power. Reasonable control of type I error was associated with ANCOVA model. Rank ANCOVA model was associated with the greatest power and with reasonable control of type I error. Inflated type I error was observed with ZIP and ZINB models.","inCitations":["292a196694afa01ff072f5983b1da299eb14190a","5c76d6b683494f7afdf0c0128aebf3ca9e406147","ed4f63964f9699aeddfd20084652fca546c38eb2"],"title":"A comparison of different statistical methods analyzing hypoglycemia data using bootstrap simulations.","doi":"10.1080/10543406.2014.919939"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2010,"outCitations":["bdfb57141b2141095ed942b28be24808aeba8d54","1d8e82fa957917ac0d2c4794a1bcb7c6cb7ce42b","261693c0671a0c52bbef78658e4a1b072ae89c1b","51fec0515b11cabc2be4832eab43ca5f6ff387d1","2acc95027922f890d80c7be6bc72b8464a237941","53394de960a2411445297df796a8d19832bab6ff","8d6b06685efe311d29026abad522dcbff0471894","c93dc7eeeee984d548e0a7173b43ad4ad43b3840","8f6eba84f6e99dcef6e3be550e5bfa6540f5ea2a","fd075364c23902d5f523dcec5706ed6d799ee2e2","6aa8c57c3e2cbe5f31890d18fcd3dc29c6660273","5356b4c32184ad0a1c559551b9a616363f52023d","c140a5f2be76023ef2215710e961d343c4dafc93","6fab6eb00d2fc91bd8bfac6730992addb09390a0","e317beaa48322e327277b2b57e6a404fb2b3ba8e","f96eafc432c1d0d4118b44eebbe054222a00e65c","d0f3bbe7b5654427246bee62650f8f89ec3ba26c","79148b9eaa267f72d201e1ac66cc3d9eb62ff112","55b4419eaead93388a58d322e9f5eb9ab8ba17bf","c499d177501f54bf2778dfa93fa58f5700535a62","048e3a0904f7d964a0ade5da031a585dadc5a92f","c4e970357ab88bea583211c7705c7283eebf219b","16b08e37c37454f7983d08112251d2419d50aa12","97418d365f941d4c89ce33f6757b538b73cf992d","314ebe77b1750d03443e17d4f593cc3ac921765a","fbe678e40aed14fd7b93349c1cd1dda833cdfe9b","2317d06f8382a2c93d91019023c14d7951812cf1","7be86c009679a630c2ca69a8d4961c50773c80d7","8871308cc5917077cb7ac8b0e6b39088118547e1","e616a58e6336d0791410771e5df2d2131a098936"],"journalName":"Journal of computational and graphical statistics : a joint publication of American Statistical Association, Institute of Mathematical Statistics, Interface Foundation of North America","paperAbstract":"The MM (minorization-maximization) principle is a versatile tool for constructing optimization algorithms. Every EM algorithm is an MM algorithm but not vice versa. This article derives MM algorithms for maximum likelihood estimation with discrete multivariate distributions such as the Dirichlet-multinomial and Connor-Mosimann distributions, the Neerchal-Morel distribution, the negative-multinomial distribution, certain distributions on partitions, and zero-truncated and zero-inflated distributions. These MM algorithms increase the likelihood at each iteration and reliably converge to the maximum from well-chosen initial values. Because they involve no matrix inversion, the algorithms are especially pertinent to high-dimensional problems. To illustrate the performance of the MM algorithms, we compare them to Newton's method on data used to classify handwritten digits.","inCitations":["12b406050e31637a06269c1a6d9ce6166b4ca875","82bdf97bc71a9da4335b5689ef49beb75a3a74fa","1d9c3a30a1445f450c81433d99e467421f4c2f8e","1a9832a565e1e4d145a792df822d13d0ff99eb7d","ca7e78d8001d83e235907c3b3db19ce3627e644b","1735337118ba8ab26cccb81fab9088b2e28fee09","340663d0037eee32f638b99e1ab56109019165ab","90add57e9d79c3f403d0875409d5e60b3bf1351b","18b9671f449ec82127d0b9c5ff7a5e3eda901a12","e8f7e7bb0cbbc9d590fa8c4828198d63793bcab7","6fd3a2a1c7c1a9cb3a90a240b782a0b2d2385155","f8fbebc4d8e038522b31e9ba7a21450f7f2f0531","d533582cc5c20936d45b918e30f485e6ba85db05","3b1dbb4c0a2d51a488d5b8e1a9e57bec856da178","2ae814fa18e1b978a4feaf74707608b7d6e24777","ef487526a3d3f4fb151c538f91bdc4808c57db5a","7ecf471b2b46cda3da935c770fa3184882637080","fdffff8c1bf5cdd258f287136e0bbcd8ab0b7529","358747f1309c10da25e3a5ebb47eaf9b0714e096","5b4e57369b076d3e3bd190b4c3a67e998c3e0b69","166ca2dde0ee4496624e05477151e246b8a62918","db44513b7a908505e099898ba2607ed55e985886","4de1b2ffb2a30b4ccf12b855bf849a89f056bd5b","8415299556c3e2bb9cbdb1ef70e6fd2023ee548d","963ea1aa73fa720d8bf6c263aa3f6fa7d7904e7c","7674dd2cf1863104c51f46747aa911650432b0f2","b322d90a3b58ec69f41863b0e904c1614c2ccb9b"],"title":"MM Algorithms for Some Discrete Multivariate Distributions.","doi":"10.1198/jcgs.2010.09014"}
{"fieldsOfStudy":["Mathematics","Computer Science","Medicine"],"year":2019,"outCitations":["977e9d97068254b350e6574c50bc86b51f9d7012","801f65b76e9dff94c81fe405d373ab775bd5982f","103f310681f9a599fb652c0397d86922d2565107","a25bf371a82fa81d74aece7aa54fb89ea3a46cb5","3766d6fe45328e3d94ea0b3823001a1e9d317214","b2f40e7eaac560276906fe08895033f33ec9e4d3","3daa1216f7e6f7118ecc52c5f453d05891214bab","7918bb9a2441583cfee557532290f8271d09022f","83180e7e6f60d880563a0c7cd80bd9f116ff07b4","27b1e5691b180242804787b2d105ebb25804a7b5","95e456c4762111ca739613fc7e9afe7f21a3252d","dae75205e0ab15293ad0e747cc874485951b730f","b51f946bd3a316b69b0cb1c0a8169c0de124ef24","3d95ae9504cfb904216be4f2bfda9315d0476986","a35ec1830025da231863da9bffa2d9d769413264","f6ce2c3102440b9869025456b11cfbc9a46c7e82","b8d527eea7a492d8673d1b551208f0b0b6198182","c59c6afcfd5d03eb2c8fb5d1665afacc077771b9","ca1492b733a394ba2129fba933cd410156d64c69","88a82e1655a462f10485702599454585e47682a0","6e27b2585b529dea2c59fa6146038a340c7b4fd1","e4f8536b067127e5269316832a4733def51c399a","0bbe8cb0b4afb5c2b929512e174e87adf1b4e08d","7f98b5ad97c6cdb89d17ef94c72bc65abaacc188","5214b65ed56efffd97493a59114a772dfb54caf1","50607d10005e572cc92aacf0f3638e6829b08df5","5e23c634a7beb02a127ecb11551fd0333491c602","4aa25a62d9985c5059ce35eb2f4cbdfc483319d9","fac568988a5072780e17c01c335b204c34cc2896","5cc4284ba1aea7d2ad758649ef3cd56343b5aeee","6cf6580f0459bc6e341567e37ebc6ed273f7f60d","909f4d1dd885dd0cddc7fbbefc079284b3a94908","2b351b7ab1a2efbdc0c1a9d14c786616e75ce567","aeaee2343fccb5b62f6fb4af06428a229b371d7b","a27250cce7a494abafd25dcd4f6aa0b26dc1bb9b","15ef3978d8755a4ac546007dfebbc78538390dd4","d98ef875e2cbde3e2cc8fad521e3cbfe1bddbd69","4f607f03272e4d62708f5b2441355f9e005cb452","95c093452386a94d274803cf9c23a300baa3e43f","85cfa1c36f3007e351ee459e1578ee415f9c7345","28c5b9515882f9c5d680c37508ab901ef1faf5d5","06382f14850c7978f384986263242fa3691dd4c3","02697e6c4316f699baf4a0d7c59da6c831adcde8","182f77976b08d832b5cdc7debdaeacc300c8e723","7e963ccda920d82e8a9faf42fc84c970de4c86d2","bbde02d99533ad27c1e20447f58e5a6a3fc4e353","bab7a53795e22ad70cfcf632335a577d7c515a8a"],"journalName":"Journal of multivariate analysis","paperAbstract":"We consider the problem of high-dimensional classification between two groups with unequal covariance matrices. Rather than estimating the full quadratic discriminant rule, we propose to perform simultaneous variable selection and linear dimension reduction on the original data, with the subsequent application of quadratic discriminant analysis on the reduced space. In contrast to quadratic discriminant analysis, the proposed framework doesn't require the estimation of precision matrices; it scales linearly with the number of measurements, making it especially attractive for the use on high-dimensional datasets. We support the methodology with theoretical guarantees on variable selection consistency, and empirical comparisons with competing approaches. We apply the method to gene expression data of breast cancer patients, and confirm the crucial importance of the ESR1 gene in differentiating estrogen receptor status.","inCitations":["08d5c1be7e8e3e6558c92e750b21c475025488e1","a8b0de2765e9f74571e57d651dacd92fb8b9bca8"],"title":"Sparse quadratic classification rules via linear dimension reduction","doi":"10.1016/j.jmva.2018.09.011"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2000,"outCitations":[],"journalName":"Biostatistics","paperAbstract":"A model for ordinal response data based on an underlying (but unobserved) Normal distribution is proposed. The model is particularly useful for highly discrete data with a large proportion of zero values. It is applied to the estimation of age-specific reference intervals in two substantive example datasets.","inCitations":["dd6b9dbe22be67d640444092953b23e4db87f7a1","10b30f7eabdb723e91d4eb0d992f632868922e4e","c78153a4bab3bea1733ea8c59c9296a9c534623f","7b5cd1abcc0d327292b968a1948eced130188e61","ecc0d998f07d717672731ffe33fb8bf84bee7b3e","52d3457ce643d1d58d809dce2992fff75e4dea82"],"title":"A parametric model for ordinal response data, with application to estimating age-specific reference intervals.","doi":"10.1093/biostatistics/1.3.263"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2015,"outCitations":[],"journalName":"Pharmaceutical statistics","paperAbstract":"In recent years, high failure rates in phase III trials were observed. One of the main reasons is overoptimistic assumptions for the planning of phase III resulting from limited phase II information and/or unawareness of realistic success probabilities. We present an approach for planning a phase II trial in a time-to-event setting that considers the whole phase II/III clinical development programme. We derive stopping boundaries after phase II that minimise the number of events under side conditions for the conditional probabilities of correct go/no-go decision after phase II as well as the conditional success probabilities for phase III. In addition, we give general recommendations for the choice of phase II sample size. Our simulations show that unconditional probabilities of go/no-go decision as well as the unconditional success probabilities for phase III are influenced by the number of events observed in phase II. However, choosing more than 150 events in phase II seems not necessary as the impact on these probabilities then becomes quite small. We recommend considering aspects like the number of compounds in phase II and the resources available when determining the sample size. The lower the number of compounds and the lower the resources are for phase III, the higher the investment for phase II should be.","inCitations":["38b59256b6ee84974f460a0f86330417bb512ae1","0368802af7cd6e24a24eb1764760b92b40211761","541c6145f0e3c4d9d95cecc995a4fd245601e6c0","a050fd915321e419f8f4dae6f62594c76f521200"],"title":"Sample size planning for phase II trials based on success probabilities for phase III.","doi":"10.1002/pst.1717"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2013,"outCitations":[],"journalName":"Pharmaceutical statistics","paperAbstract":"Many methods are available for computing a confidence interval for the binomial parameter, and these methods differ in their operating characteristics. It has been suggested in the literature that the use of the exact likelihood ratio (LR) confidence interval for the binomial proportion should be considered. This paper provides an evaluation of the operating characteristics of the two-sided exact LR and exact score confidence intervals for the binomial proportion and compares these results to those for three other methods that also strictly maintain nominal coverage: Clopper-Pearson, Blaker, and Casella. In addition, the operating characteristics of the two-sided exact LR method and exact score method are compared with those of the corresponding asymptotic methods to investigate the adequacy of the asymptotic approximation.","inCitations":["35d8a924451517803784d20e86984959d6ef598d","9780c97994ef9f4f0110bc12eac5207249dd6a55"],"title":"Exact likelihood ratio and score confidence intervals for the binomial proportion.","doi":"10.1002/pst.1560"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2013,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"Assays to measure concentration of antibody after vaccination are often subject to left-censoring due to a lower detection limit (LDL), leading to a high proportion of observations below the detection limit. Not accounting for such left-censoring appropriately can lead to biased parameter estimates. To properly adjust for left-censoring and a high proportion of observations at LDL, this article proposes a mixture model combining a point mass below LDL and a Tobit model with skew-elliptical error distribution. We show that skew-elliptical distributions, where the skew-normal and skew-t are special cases, have great flexibility for simultaneously handling left-censoring, skewness, and heaviness in the tails of a distribution of a response variable with left-censored data. A Bayesian procedure is used to estimate model parameters. Two real data sets from a study of the measles vaccine and an HIV/AIDS study are used to illustrate the proposed models.","inCitations":["f8357308ee70115eef4eb8785b5192f99e35723c","1de8720d8afd168678f328192f15586ca5076d62"],"title":"Bayesian inference for skew-normal mixture models with left-censoring.","doi":"10.1080/10543406.2013.813517"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":1968,"outCitations":[],"journalName":"The British journal of mathematical and statistical psychology","paperAbstract":"Empirical findings about the perceived interaction of the components of qualitatively complex taste stimuli are reviewed and summarized. The revision of multidimensional scaling equations to incorporate a simulation of a mutually inhibitory or facilitatory interaction between components is discussed. Data from a previously published study on the perception of similarity among taste mixtures are re-analysed for illustrative purposes and a description of them is shown to be less adequate when provision is made for one form of interaction than when this is omitted. A reclassification of stimulus-response paradigms for studying taste mixture perception is outlined; and it is suggested that the interaction of taste components may be an artifact of the response measures used.","inCitations":["82e4477ee3ac265b9c4348fd1e9c1b8af0435f5b","f3f0f2667525426cf2a0ab868015d037e4988fa3"],"title":"Simulating perceived similarities between taste mixtures having mutually interacting components.","doi":"10.1111/j.2044-8317.1968.tb00402.x"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2004,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"Clinical trials with therapeutical endpoints are designed with three arms to demonstrate both the efficacy and the equivalence of the test generic treatment and the reference treatment. A generic drug product is determined to be equivalent to the reference drug product if the ratio or difference between the mean responses is bounded within the pre-specified equivalence limits. Often the trials are oversized for the placebo arm. For improvement, we propose a group sequential design with hierarchical testing for the purpose of terminating the placebo arm before testing equivalence between the test and the reference treatments. The hierarchical feature of the proposal will reduce the sample size of the placebo arm and provide treatments to patients in a more efficient manner in a clinical trial setting. After dropping the placebo arm, the option of allocating the planned but unused sample size from the placebo group to the test and reference groups will increase the sample size and power of the equivalence test without inflating the type I error rate by delaying spending it.","inCitations":["0f1322005838579e7adab6d4fd860b3e54308b6e","f74e96a08e84c82ba815980e1ba524b4aa765cb0","892ac327beb798cd50282b1f0ca62a715611ca92","4467ef17978e9166493c917e0df280fc3864d49d"],"title":"Group sequential design and analysis of clinical equivalence assessment for generic nonsystematic drug products.","doi":"10.1081/BIP-120037186"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2010,"outCitations":[],"journalName":"The British journal of mathematical and statistical psychology","paperAbstract":"In this study, we explore the effects of non-normality and heteroscedasticity when testing the hypothesis that regression lines associated with two independent groups have the same slopes. Our results indicate that some recently proposed methods that allow heteroscedasticity and perform well in extant simulation studies do not perform well for the situation at hand. Two of the methods studied here are recommended for general use.","inCitations":["9e31c4d1b5c09db7ff4f0392c19a9bbc8bbce490","44a3872be8d975a77ff4215af52e23444edb8b32","b486c9954f6fb2f36bf851cca6cc4a07d478ce76"],"title":"Comparing the regression slopes of independent groups.","doi":"10.1348/000711009X456845"}
