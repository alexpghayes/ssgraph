{"fieldsOfStudy":["Medicine","Mathematics"],"year":2014,"outCitations":["948ad7ff478d48500350278e93c6559c06f7cc2a","5bbbcb2988e0ef5171fadda83160db23bfe5829e","667b6b335d96481c7eb06f1c65009da7e6d09bd2","5c7d370c442ed782aa29dcba3fcd2372fcc0a05b","7a18669479b4d602cda524a0bac31c7ce9823d70","ba3f2c949938f7f33da6b33fe9d37805034f4f56","61572150188f35378fa208a158d2dbe0817647b8","f0b25b16bdcb7b6418e284255b9e2ba32a7585d4","a4876f9f66bac302fc07c3edc87a9877578431b5","f251388504d35e70982849b8d066c0350db40ad1","ec820837ad5ca45e09587cf250243d72c85a36a0","37d0e6c749f18aae788c880d9417b569bb66f532","465ac72e3f5144aacfd0f9e0a6d098ce07fc2c2d","5378e36a2e2fc5a14da970363e54ef924be344e8","e7fbd40f280854b8324aef33e335cba58bac269a","63a4f8ec37d4763ed3b12b304e44b0a281fe51ad"],"journalName":"The International Journal of Biostatistics","paperAbstract":"Abstract A common problem when conducting an experiment or observational study for the purpose of causal inference is “censoring by death,” in which an event occurring during the experiment causes the desired outcome value – such as quality of life (QOL) – not to be defined for some subjects. One approach to this is to estimate the Survivor Average Causal Effect (SACE), which is the difference in the mean QOL between the treated and control arms, considering only those individuals who would have had well-defined QOL regardless of whether they received the treatment of interest, where the treatment is imposed by the researcher in an experiment or by the subject in the case of an observational study. Zhang and Rubin [5] (Estimation of causal effects via principal stratification when some outcomes are truncated by “death”. J Educ Behav Stat 2003;28:353–68) have proposed a methodology to calculate large sample bounds – bounds on the SACE that assume that the exact QOL distribution for each arm is known or that the finite sample size can be ignored – in the case of a randomized experiment. We examine a modification of these bounds in the case where a binary covariate describing each of the subjects is available and assignment to the treatment or control group is ignorable conditional on the covariate. Using a dataset involving an employment training program, we find that the use of the covariate does not substantially change the bounds in this case, although it does weaken the assumptions about the sample and thus make the bounds more widely applicable. However, simulations show that the use of a binary covariate can in some cases dramatically narrow the bounds. Extensions and generalizations to more complicated variants of this situation are discussed, although the amount of computation increases very quickly as the number of covariates and the number of possible values of each covariate increase.","inCitations":["38ac2f6e018e0470afed7718c1a4a2d781b5524f"],"title":"Large Sample Bounds on the Survivor Average Causal Effect in the Presence of a Binary Covariate with Conditionally Ignorable Treatment Assignment","doi":"10.1515/ijb-2013-0039"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":1983,"outCitations":[],"journalName":"Journal of the Royal Statistical Society. Series C, Applied statistics","paperAbstract":"\n Previous studies have observed a 7-day cycle with the least number of births occurring on Sundays. This study was aimed at characterizing the daily effect on the number of births in Israel, where Sunday is a regular working day and Saturday is a nonworking day. It was hypothesized that fewer births would be noted on Saturday rather than Sunday and fewer births on Jewish holidays. The data consisted of a random sample of live births during 1975. A robust time series procedure was used for the data analysis. As expected, the number of births was much smaller on Saturdays than on other weekdays (10% reduction). The seasonal component for Sundays was greater than that for any other day due to births delayed from Saturday and scheduled induced births. The number of births was not reduced as much on Saturdays during spring and summer as during fall and winter. In addition, fewer births occurred on most Jewish holidays. However, an unexpected and extremely high number of births was noted on Yom Kippur and the day after. It is speculated that the strain and fasting during this holiday promoted labor induction. In 21 of the 52 weeks in the study period, the least number of births occurred on a Saturday, and the number of births was less than the mean of the remaining 6 days in 46 of these weeks. Similarly, in 17 of the 52 weeks, the greatest number of births occurred on a Sunday, and the Sunday births exceeded the mean of Monday-Friday births in 35 of these weeks. Thus, these results confirm the study hypothesis and are believed to reflect intervention in childbirth.\n","inCitations":["9a35073576a64c592e4e84b5699a1195fcff8377","51bc405e04543020a57067eb262214d2ab255259","428712d32e7372760b7b8cd26a11c2d59d1528d4","763a554f79d6367cf2a615432c02b943be9afa2c","c9f525c3950d72ad4d456a714f732a90664b160a","f49e1b68861a9d84ecd05b096520e66ad9aa7b4e","1eae9f65457f77676a7449a2b99908d186442c4b","076e4a3475c8567972b401c1f0da894e96a6eba5"],"title":"Seasonal daily effect on the number of births in Israel.","doi":"10.2307/2347945"}
{"fieldsOfStudy":["Computer Science","Mathematics","Medicine"],"year":2017,"outCitations":[],"journalName":"Computational statistics & data analysis","paperAbstract":"A Bayesian bi-level variable selection method (BAGB: Bayesian Analysis of Group Bridge) is developed for regularized regression and classification. This new development is motivated by grouped data, where generic variables can be divided into multiple groups, with variables in the same group being mechanistically related or statistically correlated. As an alternative to frequentist group variable selection methods, BAGB incorporates structural information among predictors through a group-wise shrinkage prior. Posterior computation proceeds via an efficient MCMC algorithm. In addition to the usual ease-of-interpretation of hierarchical linear models, the Bayesian formulation produces valid standard errors, a feature that is notably absent in the frequentist framework. Empirical evidence of the attractiveness of the method is illustrated by extensive Monte Carlo simulations and real data analysis. Finally, several extensions of this new approach are presented, providing a unified framework for bi-level variable selection in general models with flexible penalties.","inCitations":["747d66e4cfc241d4712ffb63da802061d04384c3"],"title":"Bayesian group bridge for bi-level variable selection","doi":"10.1016/j.csda.2017.01.002"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2009,"outCitations":["5b6fda804dcf6504355fbb9fd344893cce6e4da6","26a441f4c98f4ebb0cd28b1dc86532d24b178c6f","45e0716da594f94983f9cc974a92772215944a03","45018e58636363c633c271f7a186292224e5f1ec","6c614a43077b7aec32c1ce7ff3572d96416bd77e","7c14f4450bf7fda81957013d9d634f94f6db73d4","bbcd6e2fe6ad3f70e1c5fa828153348ac583276e","33261c1f5582c228cffa2ddf4a75e711c659a7ec","a5b9485f0bebfab76402f32b4dde806f56ffd840","1b160bb869094e1a50ddf0013247328dbf43c82c","4c3ab39f8450fb083b49b223dd8c8a763f944e00"],"journalName":"The International Journal of Biostatistics","paperAbstract":"CpG islands are genome subsequences with an unexpectedly high number of CG di-nucleotides. They are typically identified using filtering criteria (e.g., G+C% expected vs. observed CpG ratio and length) and are computed using sliding window methods. Most such studies illusively assume an exhaustive search of CpG islands are achieved on the genome sequence of interest. We devise a Lexis diagram and explicitly show that filtering criteria-based definitions of CpG islands are mathematically incomplete and non-operational. These facts imply that the sliding window methods frequently fail to identify a large percentage of subsequences that meet the filtering criteria. We also demonstrate that an exhaustive search is computationally expensive. We develop the Hierarchical Factor Segmentation (HFS) algorithm, a pattern recognition technique with an adaptive model selection device to overcome the incompleteness and non-operational drawbacks, and to achieve effective computations for identifying CpG-islands. The concept of a CpG island core\" is introduced and computed using the HFS algorithm, which is independent from any specific filtering criteria. Upon such a CpG island core,\" a CpG-island is constructed using a Lexis diagram. This two-step computational approach provides a nearly exhaustive search for CpG islands that can be practically implemented on whole chromosomes. In a simulation study realistically mimicking CpG-island dynamics through a Hidden Markov Model we demonstrate that this approach retains very high sensitivity and specificity, that is, very low rates of false positives and false negatives. Finally, we apply the HFS algorithm to identify CpG island cores on human chromosome 21.","inCitations":["67e5df244507ea1017e72092268eca1f3fd9019f","10321b88052cacd24ec4ab24786d2ba17be61119","8ffd4d7a3d51ef340ffb4da59d9679b7569a8e5e","039b366a0fa7e4ad8750e31b0d9573484a72f160","76b3c9978cfb737f3affb574523ead9568625d73","c72eccda4640252c2bbe1d938796e9f903ca59cb","4b01f5dbd673629e9e16290fbd397d8b2813d390","656fa98a5fc2b5f63047e99941d4cbc103cf9890","b86d7c1cdc1533182fd76eb45af1e0dc5d081dac"],"title":"A Nearly Exhaustive Search for CpG Islands on Whole Chromosomes","doi":"10.2202/1557-4679.1158"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2013,"outCitations":["354b3b52b36025c514cda36a0c1eba8c6a072309","f08526c6441fdf7938ab51dbab4e2c7876451627","756eaae3d02536103fa0619b462fba2f8708c44c","7e18f9c15ce990fb48bfb942b0c42b81aa2edc3e","81c68c6837c09217f6e2bf14ec6460db66c4d39c","19b29a3a50a801912014b7311025576e5300156c","7afee2f46c17e50fb686365f85391ea705a40a08","99069953d24133669b46026d842d4b6b7868a5c2","9c82d205ff8862c4a25b1496e9f2b1fa8b343224","62582232d3f469926dd2f0869780f33480b3dd2c","3b21545956d958dfb9ad728fec30574f2e169268","ebeb675e46950445d37c4ca709881f385d4eaaa5","fef0a6f229d9ad36d96ba92edd07f11a2d320f04","44538a6e3a7be11323fd9c7b950c1206161dd651","bc36d2c4eb24a9214c6f60beaff6cf21b33c7eb9","174e51242291ad6fa03a424c8a535426c4aaed75","3473cdd3fbe4a1881e10ff098b449264f40094d8","57d816d1f1c4f98d3041aff86df581785ffe1285","b876395a6a11e15fcc6bfd7ce9c1e139d1f44f93","fd8f9240510f0a3c02a1342c766c92edcc888f4c","4dc1ca5eacf5bab6afe9ddb5e3276dd9c8d5fbad","871afd5ec74441fb15f3097629745ff05b05e878","5b8f31ab4e03f0e3fb3c94a90750802435e663b8","bbc3f59ff470fa42151f84b897d72cef9f17928d","ea54f0c0568cab38619ee51e6ac021e76d6a6559","103559a30b8050564f596ff60d87ee0a8b758591","318ec6ebf796dda73265e98fc4161835521fbbbb","c4c67b3c9b956b09b8e447d078cff65da7c546f7"],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"People exposed to certain diseases are required to be treated with a safe and effective dose level of a drug. In epidemiological studies to find out an effective dose level, different dose levels are applied to the exposed and a certain number of cures is observed. Negative binomial distribution is considered to fit overdispersed Poisson count data. This study investigates the time effect on the response at different time points as well as at different dose levels. The point estimation and confidence bands for ED(100p)(t) and LT(100p)(d) are formulated in closed form for the proposed dose-time-response model with the negative binomial distribution. Numerical illustrations are carried out in order to check the performance level of the proposed model.","inCitations":["23e1b947085862ae81ad75b6ec3448cb0cdfae46"],"title":"Dose-time-response modeling using negative binomial distribution.","doi":"10.1080/10543406.2013.834916"}
{"fieldsOfStudy":["Computer Science","Medicine","Mathematics"],"year":2012,"outCitations":["0d634ab4754232d6e17181241954fbf6d73e5803","b5031ffe131d2e76b738234eae8c003afd5e1c39","aa7138c899fd48d3c8df2ccbb65dce06ca4d12c2","377339cd55087d503b855ae89d2126495cf104ee","d1d875e9f7020ee98f5a1051c2a567cba52299d1","1d60f3a98d106c787b4daa058d458df6cfd42631","296e0ce587af299ac88338950cd0e87b23409a73","75f8a4d7ed6a0f32fa098cac967de247938d9ce5","19f6eff358988e3e2deed4c7a7bb0bd7114fbce1","887ddc109559c6e20b7654c3690f0affe36d4a31","b56ef5c71c3d8d44816e0eac2a0ba1383424896c","95b1ddb21d6a0b66176ac3a9489e6e352d4eb697","0aa8774e218fafa445a986715f5b40124b7ae6a5","c1dc19f87fa83b4357f0557cbb6c32a4ee0002d7","f9c442eb46c6a57ec80e455e17715578217b552a","a68fff5d07699b33af739e88c59ff5b0dd4ee874","d3a3e8e25246b4186e4139a2c5645b089d4087aa","9a1a73d67042a1f60c18b84cb2f607a529bad2fe","28689e89714d34d9428db5f0a8a7dfafc5db1214","b333df17a575262926c8b36dcda2fae9306b259e"],"journalName":"The annals of applied statistics","paperAbstract":"The parametric bootstrap can be used for the efficient computation of Bayes posterior distributions. Importance sampling formulas take on an easy form relating to the deviance in exponential families, and are particularly simple starting from Jeffreys invariant prior. Because of the i.i.d. nature of bootstrap sampling, familiar formulas describe the computational accuracy of the Bayes estimates. Besides computational methods, the theory provides a connection between Bayesian and frequentist analysis. Efficient algorithms for the frequentist accuracy of Bayesian inferences are developed and demonstrated in a model selection example.","inCitations":["12fbba3091e58d1744890c66da9e3809051e0148","6a114e3df18f4d61ac0c676cd9de0ac811319796","4f23c13abb1dabc2777896261de42ed180dfdba7","f1258d9d28488e7bd59961a553253d4b0ba6f9bd","7b4f5b356c8ed1aa14ad01f6ad9832ab62bab62a","28d82e6bbc99ac5825efffe1625228c3308f70d3","2f6f97c65ec11cd614a3a88c3206cd48b4dee469","ad371cf8e62a99d0e10cb0e26a558b2b02118482","cb91676b86bac773325e5e0edb305e4db6050b62","b86fda7a1dd7620cf5093c14cafdf59c1db7db75","937374caba63c0653eee8a42088c881ebda47a6b","874ae03989b79ad447eddf75b8fce9b3634691ca","ee516bd5febbfd1f0f9082bf063b35cc97543ec8","5771b4774d5ed5f52a5500508887ac4b3a3f1058","12c1e837cc852e279c953768e40454cc8307dff5","c9fd2f064fff3d197e68d4f6aef531038297cc59","d0af17e1628081537e5a28e095ec4656129e769e","396b6798341e46cd8553cfc799b78c17391caa47","3087851c75759d08ed975304c1d7a7ab08e76577","63d823d52f1ab80e49eecf0f1cedb65c602ee3f8","9c776378c1e0e547e4baab3c2e239f26a70fbf6d","f33c6034f3353e2490fedc377023b3c2330d5def","dcdc71362c91fc6c8fd890994cc5007bc56f3f97","db1b7c473253674126199ce4db3ea2cb4c086891","6ab8aca1f727e379632292e1ec4a24ea2739cf89","30e324bb5c59cc4386327c3a14a2e6b8d4d4c292","89cd499f5a9952cc813dfad8fb27c3964e194731","248a8c8f43476b0281da648a1b2a46da9c63d032","74a634de78b98f933339de624c312f7036710c76","c3cdf4423d2dab58583e6dd3ce4261f5a791bf87","d623c2cbf100d6963ba7dafe55158890d43c78b6","d5147251fbacd3c8b397732b2e94081d7e1ae4cf","c6ba6205790fd94166654e57009483733a20ff94","621aabc4b1a9d00ee0bbcda17e150c2f80510872","81fffb274cb1ae3c01a5cbabf8735da289a5485f","eb48928a38324903f06fdf8ae7cf6822000b09ed"],"title":"Bayesian inference and the parametric bootstrap.","doi":"10.1214/12-AOAS571"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2008,"outCitations":["762176d0c509fac7649ef9188b3161506f755189","70dba8414e9795a99a285f1fd239c5eee2ea32a4","2018575a1a33bbb85f3dd7466e6a7bb0561b4e20","8b6c5b7cecf1b64a8c94364633ff45ec22904827","02fd7b5ee2d06b6002c793c2027497fbd791d6f6","bbe91931072eec45f22cdf00f57de98ddd457846","ceb1b2477e30e34f16877cad768c4a9131eda635","3f92132772625fef3abff85a48ad925cbb8abff2","86b2fb0cd87b1263d2e0d0400730333cf5e3def6","d0414821b25b6f28a90789e332d2f4c00f81b02c","56d44bc7b492325b165720a4fc06ee5ef2127f6f","271a9afec5e985e6cd8545bddc38b71a30406869","f619c1b15c8bb62b6a41adaa6de8316aa4b03e3c","8c5cecd5313a892728b3db0fbc63c9b0ba6d2a3a","0509544ba8a2ed69814cf22c2e2ae1c1d3ba9de1","c2ac7b659d99922bcc73b9629054d47b057e35de","2e2da6822c026dee4114921cc8a0babc7251b862","d7cd8fe5aaf4eabd02c1c2c7c94b3668189377f0","63a4f8ec37d4763ed3b12b304e44b0a281fe51ad","b941b4cd8f106157524bb9e1930375f3c3029cd9","0df2e49fef04d7cb6bd626932bc9fae2cb6fe55c","5e80e1fa69df544f9d66138830e373a18cab5c8b","5769d73a2ba56593faa9cba44b549d845989a1b2","a4876f9f66bac302fc07c3edc87a9877578431b5","938a29ff609aa0c4f326b9990a8c4f12fefb018f","b6827dbec33c0d55e087fee45babbf81c914ba3e","5b3cec0ac8c750f87408a2f9152f697b4aa3d300","a967b5f76037c86ac51556ae242f0a4b2729a9e8","847b301d7814c14fd3100d824bde72962b3d3187","46c56845fbb9e9452a318d736356949bd24fa012"],"journalName":"The annals of applied statistics","paperAbstract":"Assessing immune responses to study vaccines as surrogates of protection plays a central role in vaccine clinical trials. Motivated by three ongoing or pending HIV vaccine efficacy trials, we consider such surrogate endpoint assessment in a randomized placebo-controlled trial with case-cohort sampling of immune responses and a time to event endpoint. Based on the principal surrogate definition under the principal stratification framework proposed by Frangakis and Rubin [Biometrics58 (2002) 21-29] and adapted by Gilbert and Hudgens (2006), we introduce estimands that measure the value of an immune response as a surrogate of protection in the context of the Cox proportional hazards model. The estimands are not identified because the immune response to vaccine is not measured in placebo recipients. We formulate the problem as a Cox model with missing covariates, and employ novel trial designs for predicting the missing immune responses and thereby identifying the estimands. The first design utilizes information from baseline predictors of the immune response, and bridges their relationship in the vaccine recipients to the placebo recipients. The second design provides a validation set for the unmeasured immune responses of uninfected placebo recipients by immunizing them with the study vaccine after trial closeout. A maximum estimated likelihood approach is proposed for estimation of the parameters. Simulated data examples are given to evaluate the proposed designs and study their properties.","inCitations":["0e00b8e08ccccb1a33ff48f8fa767472a3bfad50","c6bda9816dfc2b0d5c196737ab6adcd062639b68","36dcd28a2e5c959b5f32a535168f6ea51102b026","eacdf7902ffb3ee053dff21a495a15d0263ea192","474dd7191603a3b0eaf0b9163b0695cb31f756f9","bad6ca275e4e67caf870223fb68689ed94c35807","024147edca143c3fdadeb9bfe580ccd905b6244c","b2cf4ef5b4fabc28ca4638fe3a0853e78b59a6cf","8de20390d14e5638a479e6de1f27c8249051e5b4","ef1d033ec592c2ac841def87283d71bd9730847f","e63239129a5337e903c4e41a77b64c7b3be99aae","23ca832ce0adf848f1d1cef082771f19d59d3e81","28cf1ea0d7dcaa8b631ca719416fb2cb5a97ba24","0a8868b5acf370e466c817e254a26224978d0d87","146a5707069f1a518cea28ad5a10598c604f7772","975133e227d88432ca3cae400170c93ffdba603e","f7d353a38b1d02a32818d55d652ef098cf9fade1","196f86403728a1cb10bafd10326a7a38a10a71e8","10e3686a06803ed4f094dff3a231251ff6f19a4a","231308aebaca9d5616cbdc54eba36abd7be02f7c","a2b71fd04854201c87505754dc4ab81d86f70643"],"title":"Assessing Surrogate Endpoints in Vaccine Trials with Case-cohort Sampling and the Cox Model.","doi":"10.1214/07-AOAS132"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2011,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"The identification of outliers in method comparison studies (MCS) is an important part of data analysis, as outliers can indicate serious errors in the measurement process. Common outlier tests proposed in the literature usually require a homogeneous sample distribution and homoscedastic random error variances. However, datasets in MCS usually do not meet these assumptions. In this work, a new outlier test based on robust linear regression is proposed to overcome these special problems. The LORELIA (local reliability) residual test is based on a local, robust residual variance estimator, given as a weighted sum of the observed residuals. The new test is compared to a standard test proposed in the literature by a Monte Carlo simulation. Its performance is illustrated in examples.","inCitations":["624d32770f1c372f9fdfe301a4de5fa4865c143d","459ae9fc5b7ff2fd4ad455546400b251812e846b"],"title":"A new outlier identification test for method comparison studies based on robust regression.","doi":"10.1080/10543401003650275"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2016,"outCitations":[],"journalName":"The annals of applied statistics","paperAbstract":"The human lung airway is a complex inverted tree-like structure. Detailed airway measurements can be extracted from MDCT-scanned lung images, such as segmental wall thickness, airway diameter, parent-child branch angles, etc. The wealth of lung airway data provides a unique opportunity for advancing our understanding of the fundamental structure-function relationships within the lung. An important problem is to construct and identify important lung airway features in normal subjects and connect these to standardized pulmonary function test results such as FEV1%. Among other things, the problem is complicated by the fact that a particular airway feature may be an important (relevant) predictor only when it pertains to segments of certain generations. Thus, the key is an efficient, consistent method for simultaneously conducting group selection (lung airway feature types) and within-group variable selection (airway generations), i.e., bi-level selection. Here we streamline a comprehensive procedure to process the lung airway data via imputation, normalization, transformation and groupwise principal component analysis, and then adopt a new composite penalized regression approach for conducting bi-level feature selection. As a prototype of composite penalization, the proposed composite bridge regression method is shown to admit an efficient algorithm, enjoy bi-level oracle properties, and outperform several existing methods. We analyze the MDCT lung image data from a cohort of 132 subjects with normal lung function. Our results show that, lung function in terms of FEV1% is promoted by having a less dense and more homogeneous lung comprising an airway whose segments enjoy more heterogeneity in wall thicknesses, larger mean diameters, lumen areas and branch angles. These data hold the potential of defining more accurately the \"normal\" subject population with borderline atypical lung functions that are clearly influenced by many genetic and environmental factors.","inCitations":["7852347a4a36ce8d934be4c24cf6aafd4032b214","be33cc9e3e4416ec488bdf0454706a605982cb64","b326f0bba171339350924440e3d8338e0467e6c8","81b899136e15843adafa49dd0aae512613c4d6b4","d7810a1457708522cce7b3e423035f4722a00781"],"title":"Linking Lung Airway Structure to Pulmonary Function via Composite Bridge Regression.","doi":"10.1214/16-AOAS947"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2013,"outCitations":["c1dad5822b1e635af593b5aeb887a06358b299a9","44df06f041bd60f432becd412d14828184eb9bd9","007bbe4e77ccd029742efea59f20804948b9caee","2e60b54f1777de12efd2ced8073f5be77e908ac3","38939a4c1b81e4c7b72bcd47bd4978f11c01ad8f","aba0e6a821e457814b01161b85831e500d6e7c35","3c0376b6710b4c21bc8dc76c15d80c45583957c7","ec2824142c36bdffba3145347fd53102297ab228","850d32dc53832e7d931783848005f01bf8f37d5b","fdd52a07c9933952275f850784a5174f05da24b0","0218ca73773ad4936117d9767b9470d66da40b40","20589a1af79ff160f5adf3fb1e342dec38785bb4","07d0e1eee7506c5204647ea370b649200b40e701","9b29601fd63805afffd2e826f4dec8e610db3024","af2859f928ba64c1973bf080aaf7706f6f016da2","7b3896049e03c2e7d9dfe33fec31a795b832e0f7","cf6692b5762e942ab42dec2ac4523ff27a18e24d","c92d6fa1e30e12946c874e5a8b9aeee3c0155e29","fddb43681b965d0e566f8beb2ce3e057e4072909","49e792e39f82cf788967c8ec0a825f89a07d2271","1c6536cf333ceaa04566d2c76e08b2e901405a69","e8bb8c34d22333ea2a16c3201311c802d6fb529a","b0c764b6f8e498ffe881008221753230a1be2d2e","97510e2048af0c6c510aed405091514946c4eb13","3c28a43e7feb30360757320b0a427aa0be9b212b","ddec9d5bc782e0dee4516fc383a43de625f59fb6","9c4ef69db2a255dbdff60f7f8fd760e7c2322657","305c1929f9b5cd60aede21b30b7f6fb65b31dbd3"],"journalName":"The British journal of mathematical and statistical psychology","paperAbstract":"Multilevel mediation analysis examines the indirect effect of an independent variable on an outcome achieved by targeting and changing an intervening variable in clustered data. We study analytically and through simulation the effects of an omitted variable at level 2 on a 1-1-1 mediation model for a randomized experiment conducted within clusters in which the treatment, mediator, and outcome are all measured at level 1. When the residuals in the equations for the mediator and the outcome variables are fully orthogonal, the two methods of calculating the indirect effect (ab, c - c') are equivalent at the between- and within-cluster levels. Omitting a variable at level 2 changes the interpretation of the indirect effect and will induce correlations between the random intercepts or random slopes. The equality of within-cluster ab and c - c' no longer holds. Correlation between random slopes implies that the within-cluster indirect effect is conditional, interpretable at the grand mean level of the omitted variable.","inCitations":["33d7387874c2787c3827b25acfcc78ae5b23a4db","f22904e9a0e8b22f0a7bad4307af0b348b012107","d3bb1b72b5681ea63600b5c9b97989cccbe2bce9","548a8691bb047c618773b98663b945a20538e0be","f8c86efd055b4330c59e273bef1a55029ec5d095","ad4f6499eb96e8a5477d75af626ed7c467fe752e","d144458dabe7bb8b1f898159ee1fd3fdb7289d1a","fd0eb8db5d3a0e701cfa0f9c6c09dbb61c27ad58","7d07c54420e89e7ac1fce2407b28595539dc8167","1fe3a223b53e3dfb93239e8a74dde6e5daf82810","5188a702ffa8043bf82048de4ad4ae21cc6a7c6c","88382b5526084d3bfcf931a6bf01499029d4baee","e86b9bb5584058ee6ffc7f9f74ce6a54202e2dd7","549f42e10131cc865f71c2b74f8839cc3d1b950a"],"title":"Multilevel mediation analysis: The effects of omitted variables in the 1-1-1 model.","doi":"10.1111/j.2044-8317.2012.02051.x"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2009,"outCitations":[],"journalName":"Biostatistics","paperAbstract":"Mass spectrometry is a powerful tool with much promise in global proteomic studies. The discipline of statistics offers robust methodologies to extract and interpret high-dimensional mass-spectrometry data and will be a valuable contributor to the field. Here, we describe the process by which data are produced, characteristics of the data, and the analytical preprocessing steps that are taken in order to interpret the data and use it in downstream statistical analyses. Because of the complexity of data acquisition, statistical methods developed for gene expression microarray data are not directly applicable to proteomic data. Areas in need of statistical research for proteomic data include alignment, experimental design, abundance normalization, and statistical analysis.","inCitations":["7105cd5fb67238b7b5cd4a7a991327f4d1e45aa2","36d203ad2a951c542b0881d13bfc4ccc4de733a8","5d77068116042c0526cc4773ac0cdffb1f0e5119","bf05fa7339bbf906e35fd530bd88919c5c27a005","c1ca5f8c75b392891e1c2384b5772002e1951b91","f757ebd425083d1d4d229d9a4c09737cb6e9c507","7b0b0890563e7f63a746cf459946caeac251d11d","d59e1f19aa0b3213e3bb2fd2402008a734122f1a","8b6ab93d39df2861a2f09b60defbe62deec4cd23","63c198076dea71358e7ed22931dd131d9435d8eb","dc5952e87786dd0e041e66f16789f47661d6edf0","1227cf56963b95c7c4e94e8cf9082da124fd5c8c","77896d85d1596997c01971735aec6461cb995d4a"],"title":"An insight into high-resolution mass-spectrometry data.","doi":"10.1093/biostatistics/kxp006"}
{"fieldsOfStudy":["Computer Science","Medicine","Mathematics"],"year":2008,"outCitations":["5cba3e9e979f1d9c27153a557140c0b4e097edfc","40b5da504c58269a59351c9b528e434aec6f9724","1fa236f4989f1e315eac97e7c938dce95863a847","1ebcd67d3d79107b5d49f99261b992e7c1a7328c","44ad920f1d046adb042ea6a33d4b216f2d76ba81","a56b8c46cbc273ba566c16e14e86130e9b194c86","53dc97756369cd1f9300116d6aabdffb7072f2ed","58db9852fedd50a4732e3c174383710422c32ecc","345d35bb850b721b978d4cb97c6208cead4e8516","c5e683b73f4218af4bf3357ae17e6ff30f7471e8","0638934dbe67a2079beced7e2645ec8428758603","e6290dedc000b2348d83ba1fa39427c8939af1a5","395b5f21b34cdcc0811e7d7f17a310efb9255d7b","84167e961cbd110c371f7e0933d9b48db2a0aa49","400b45a803d642b752a84147ef547af7811e8f3f","1c7c5595dc7a1f5d360acf5c360ca1ca49536ba5"],"journalName":"Journal of multivariate analysis","paperAbstract":"Recently, penalized regression methods have attracted much attention in the statistical literature. In this article, we argue that such methods can be improved for the purposes of prediction by utilizing model averaging ideas. We propose a new algorithm that combines penalized regression with model averaging for improved prediction. We also discuss the issue of model selection versus model averaging and propose a diagnostic based on the notion of generalized degrees of freedom. The proposed methods are studied using both simulated and real data.","inCitations":["63f8cb8269d9d503b9152008471daf412d427f11","4ff2f5ffd63e344f346ab542587a26f0cf30a810","e5ee76c6fb8f3398990232562698fb0fb48bbcf6","a233ce34f618e1702d6bbbe0cd422fc38055a7d9","488d26dbc47acd6ba947794d22f1b25b09bb667a","17b8b934217dc044f33f7e992556bbf013411839","47b44fcc3493f29989caa68139d4f477ebd1a965"],"title":"An improved model averaging scheme for logistic regression","doi":"10.1016/j.jmva.2009.01.006"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2007,"outCitations":[],"journalName":"Biostatistics","paperAbstract":"In this article, we compare Wald-type, logarithmic transformation, and Fieller-type statistics for the classical 2-sided equivalence testing of the rate ratio under matched-pair designs with a binary end point. These statistics can be implemented through sample-based, constrained least squares estimation and constrained maximum likelihood (CML) estimation methods. Sample size formulae based on the CML estimation method are developed. We consider formulae that control a prespecified power or confidence width. Our simulation studies show that statistics based on the CML estimation method generally outperform other statistics and methods with respect to actual type I error rate and average width of confidence intervals. Also, the corresponding sample size formulae are valid asymptotically in the sense that the exact power and actual coverage probability for the estimated sample size are generally close to their prespecified values. The methods are illustrated with a real example from a clinical laboratory study.","inCitations":["1cc439940abd79014db89ffed777bc79c29f2bf8","1f6685af82d5054fd77e54d40fe2c031c8de8aa0","9c517b3c3c272e4c2bede2c6b32f634885d94dde","4a57eda04ae37b72579e856d4d6d00a0f16a7922","2fc7ba50b9235db5826b6c49122cfb1e42349ed5","f7bd078b6f51d785625e0e097cdbd273ec533ef2","35d4091d5fc8857992aa4a040521b8fc3aa4e48c"],"title":"Sample size determination for matched-pair equivalence trials using rate ratio.","doi":"10.1093/biostatistics/kxl034"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2000,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"The U.S. Food and Drug Administration (FDA) requires pharmaceutical companies to show bioequivalence between different formulations or generic companies to show bioequivalence between generic drugs and brand drugs before approval. In a recent FDA guidance on bioequivalence, new criteria were proposed for assessment of population and individual bioequivalence. In this article, computer simulation is used to compare a modified large sample (MLS) upper bound for the population bioequivalence ratio with the bootstrap upper bound recommended by the FDA. The comparison criteria are the ability to maintain the stated confidence level and the estimated power of tests based on these bounds.","inCitations":["4ae883ed90ce3e3959c4e6e395bb733588bf6678","905f0e11f4cd678c72b31d3765e4bd7430fa0d08"],"title":"A modified large sample approach in the assessment of population bioequivalence.","doi":"10.1081/BIP-100101982"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2016,"outCitations":[],"journalName":"Pharmaceutical statistics","paperAbstract":"In clinical trials, continuous monitoring of event incidence rate plays a critical role in making timely decisions affecting trial outcome. For example, continuous monitoring of adverse events protects the safety of trial participants, while continuous monitoring of efficacy events helps identify early signals of efficacy or futility. Because the endpoint of interest is often the event incidence associated with a given length of treatment duration (e.g., incidence proportion of an adverse event with 2 years of dosing), assessing the event proportion before reaching the intended treatment duration becomes challenging, especially when the event onset profile evolves over time with accumulated exposure. In particular, in the earlier part of the study, ignoring censored subjects may result in significant bias in estimating the cumulative event incidence rate. Such a problem is addressed using a predictive approach in the Bayesian framework. In the proposed approach, experts' prior knowledge about both the frequency and timing of the event occurrence is combined with observed data. More specifically, during any interim look, each event-free subject will be counted with a probability that is derived using prior knowledge. The proposed approach is particularly useful in early stage studies for signal detection based on limited information. But it can also be used as a tool for safety monitoring (e.g., data monitoring committee) during later stage trials. Application of the approach is illustrated using a case study where the incidence rate of an adverse event is continuously monitored during an Alzheimer's disease clinical trial. The performance of the proposed approach is also assessed and compared with other Bayesian and frequentist methods via simulation.","inCitations":["c708caa2996d039564fee3cb1f1baaa9202aad53"],"title":"Continuous event monitoring via a Bayesian predictive approach.","doi":"10.1002/pst.1727"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":1998,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"In Tamhane, Hochberg, and Dunnett (1) we focused primarily on step-down test procedures based on contrasts among the sample means to find the minimum effective dose in a dose-response study. In the present article we use the global tests of Bartholomew (2,3) and Hayter (4) in these step-down procedures. We also propose a new step-down procedure that permits tests based on a class of contrasts [step and basin contrasts of Ruberg (5) are examples of such contrasts] that could not be used with the step-down procedures studied in our previous paper because of lack of control of the familywise error rate. A simulation study to compare the four procedures proposed in the present paper with the top four procedures from the previous article is carried out. It is found that the step-down procedure based on Bartholomew's test and the new step-down procedure based on step and modified basin contrasts generally perform better than the other procedures for a wide range of dose-response profiles.","inCitations":["435864700130f40727fa12fc239c3f3dbd1ff37e","97df6a394f63eedbde7afac8d6d48fd1f29037b2","fa699d6e7e4497d33bac99264e94cb4e87075db6","119e9a48244897e84ebae3e13823312680526985","640808ffe0970c0231f1463fe4df9f64d69d9627","af2b8d07833c297fa4bbe7173336a0b9cdb056f6"],"title":"Some new multiple-test procedures for dose finding.","doi":"10.1080/10543409808835245"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":1997,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"The implications of drop-outs for power of random regression model (RRM) tests of significance for differences in the rate of change produced by two treatments in a randomized parallel-groups design were investigated by Monte Carlo simulation methods. The two-stage RRM fitted a least squares linear regression equation to all of the available data for each individual, and then ANOVA or ANCOVA tests of significance were applied to the resulting slope coefficients. The tests of significance were adequately protected against type I error, but power was seriously eroded by the presence of drop-outs. Simple endpoint analyses with baseline and time-in-treatment covaried proved more robust against the power degradations.","inCitations":["91a44c4ebcff032e552ddd87bbdc03f21f37071d"],"title":"Drop-outs and a random regression model.","doi":"10.1080/10543409708835195"}
