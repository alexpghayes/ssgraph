{"fieldsOfStudy":["Computer Science","Medicine"],"year":2017,"outCitations":["4e776e712083bddabc6d2623106dd17f05c31601","ef05628ed2f8068246e837ae20991bbf0c78fc42","0f93935a2916a046f46811119c9133506f39dc78","83730969c0686b1d185bcca39f9b5743fa53ebc1","50acdeb9e84197659ca26d03c7bcbfca7e811e80","1f1b750baf5b0fa427c5b38379cdcc8d70634d36","977e9d97068254b350e6574c50bc86b51f9d7012","239b44fd21c3f949f9fdf43bfedd4ab2a3d314e3","ebfc6e76a5f9e488077a9ac5bc214e67853acb8d","166c42895882039e4252f7c943efa13d0505109f","140e28b488407e4c52bd3b201c44f1f3e693d241"],"journalName":"Journal of statistical software","paperAbstract":"Plots of the receiver operating characteristic (ROC) curve are ubiquitous in medical research. Designed to simultaneously display the operating characteristics at every possible value of a continuous diagnostic test, ROC curves are used in oncology to evaluate screening, diagnostic, prognostic and predictive biomarkers. I reviewed a sample of ROC curve plots from the major oncology journals in order to assess current trends in usage and design elements. My review suggests that ROC curve plots are often ineffective as statistical charts and that poor design obscures the relevant information the chart is intended to display. I describe my new R package that was created to address the shortcomings of existing tools. The package has functions to create informative ROC curve plots, with sensible defaults and a simple interface, for use in print or as an interactive web-based plot. A web application was developed to reach a broader audience of scientists who do not use R.","inCitations":["8b65e92249ff016d86486f40264a2f0ee4a2e675","e9c1dfeb7887d6b36182923ae9c99f06da3a5b12","010f706dfae9d04b8c792adbe52e38db28801a94","b16710afa44cd0878777768fcc5c7a4db06f173e","d9cfdb4959e9c565aa183f54ac1bca8c38a36a7a","ac36f07feb7fd21822d5f526d647cd498facb5ff","dbe6e601a07bbb013a40bb6d4773803cb6f889ed","70af1500a0d7baf8de993873d879bdadbbec97fd","602938dfc1865c122e6e49a980ece50c7923de2c","071f5b8988cea20dc2766d12bfbc33041d2412fc","a9b2b4e47e977871722c3699194e744685b7e528","519c2d962e330cc1be4620de2682b0a30a435926","057aa93b862afafbe830f6fd3459bd5efbb8d3e0","17e08096888f4b0d90a2def42e1363dc04594864","ca3546436580c175d86c160eddf71eccc824e3f0","5d12d259723a6e96d5ea813f2a94a19b6295eea9","77fda8193d96f8b1b507333367aaeb97b564002b","00d750e3679bc3ea78b2a66218c5be3b8470fb86","9bd82887b90e39feea034b5a698cecf7770736ab","a4a30d7ed65811bf2da07b28dd4eb151d25a95f2"],"title":"plotROC: A Tool for Plotting ROC Curves.","doi":"10.18637/jss.v079.c02"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":1998,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"In the course of clinical (or preclinical) trial studies, it is a common practice to conduct a relatively large number of tests to extract the maximum level of information from the study. It has been known that as the number of tests (or endpoints) increases, the probability of falsely rejecting at least one hypothesis also increases. Single-step methods such as the Bonferroni, Sid√°k, or James approximation procedure have been used to adjust the p-values for each hypothesis. To reduce the conservatism (i.e., underestimating type I error) possessed by the aforementioned methods, Holm proposed a so-called \"free-step-down\" procedure. This adjustment can be made even less conservative by incorporating the dependence structure of endpoints at each adjustment step of the procedure. That is done by sequentially applying James's approximation procedure for correlated endpoints at each step, referred to as the Free-James method. This article primarily compares the power of the Free-James method to the power of the Bonferroni and James single-step-down and the Holm free-step-down methods. Two definitions of power are considered: (a) the probability of correctly rejecting at least one hypothesis when it is true, and (b) the probability of correctly rejecting all hypotheses that are true. Monte Carlo simulations show that the Free-James method is as good as other methods under definition (a) and the most powerful under definition (b) for various sample sizes, numbers of endpoints, and correlations.","inCitations":["fec1f86094bc0ae91de88c4a787238ae61373e09","e3240b5e2c976cd523507cf469b79083fd0008a4"],"title":"A power study of a sequential method of p-value adjustment for correlated continuous endpoints.","doi":"10.1080/10543409808835262"}
{"fieldsOfStudy":["Computer Science","Mathematics","Medicine"],"year":2012,"outCitations":[],"journalName":"Pharmaceutical statistics","paperAbstract":"Optimal design methods have been proposed to determine the best sampling times when sparse blood sampling is required in clinical pharmacokinetic studies. However, the optimal blood sampling time points may not be feasible in clinical practice. Sampling windows, a time interval for blood sample collection, have been proposed to provide flexibility in blood sampling times while preserving efficient parameter estimation. Because of the complexity of the population pharmacokinetic models, which are generally nonlinear mixed effects models, there is no analytical solution available to determine sampling windows. We propose a method for determination of sampling windows based on MCMC sampling techniques. The proposed method attains a stationary distribution rapidly and provides time-sensitive windows around the optimal design points. The proposed method is applicable to determine sampling windows for any nonlinear mixed effects model although our work focuses on an application to population pharmacokinetic models.","inCitations":["05b7859ccdfb25cedebf16f0b81d3ef43e47312d","ba1df5b95584818b03ffefa1a62308e945230a9c","32a9d7c6a0ebb6605079349847817b1b09adc35b","608c5673fda3c55e1406fef0586e9e0ebcb076fe"],"title":"A general method to determine sampling windows for nonlinear mixed effects models with an application to population pharmacokinetic studies.","doi":"10.1002/pst.1509"}
{"fieldsOfStudy":["Computer Science","Medicine"],"year":2016,"outCitations":["0e7f5f99488a480589f8390a599f54005ac5e670","3c6cbd0875c08364aa86123ae110f2871a01885e","89dc74f5e832c18227683b75a661d6417059cccd","b0e220b05f3a4df63bdb8d04cd25f354a738d273","185327974fd44abb98b6c8861c84c00ab3e2823f","67e825d0158dca65ef68c59cbed77fc83a34cee5","7eb541983de0a39586a699e255563b26e9291340","dfe4afa46ca5f9deb8a7c8aed3d4da848ee104f6","0a18a550cb6f7e4dd376bf072c388fa3c7471670","da6331671b93f1d94792f55da2dc0545d4f446e3","c3aa5bf71340830ec69ec2e9467fc0eee15a6085","95e01c51205ada2c72b2833103bb17f4eefd2911","1d2cc2c01a9bb47263d846ab32bd9ab8884ac688","ac309f2d5d0c247583aebe39963bf650417bf962","0ddabc596352f9d2a1bc1123aeb40722b34d4d47","d6e67d20f0bd97274cac70b6b1985254f479d6c9","be15691fd813b20e8e43446cd9668408ad2f8e7a","1f74c2210a4640d814cb30ade7c8f90be95e4766","52c6b6f04736152d3262510074f5e8c591e2e8f0","e5a7e2671f1d754be65d753c400ed5e08652222e","2745bcee1de7111ab52d566726708d281cb1bcf8","5cce5e345d8fb686851e95a7d57de5e0987acadd","972dd9c569f2c5234b29c2e955402253e3300178","41986f1c5018720c1886bdd262cc515ea80b9854","b4d2782472935340b9ce25520ff9050fbfa1b18f","431858f1e38600e7cb9ce5f39d592e8491a6d81e","44d486479b672379595c796c7fcba70b17196ffd","c4c53888cc3d6321fe376a1455206f886392d6a2","e59234e821455d5040197422d43b1964c6b90a58","4178872c662ef02608740e9d36df005d224e21e5","49bf4fe4f28ba4fc028df28d32bee84ce2d34955","af2859f928ba64c1973bf080aaf7706f6f016da2","85a8ceebbeeb0b929ac0c3b4ae34c23879c5881a","021047362d7e328463f0238c3bd509a3232d35ef","676db56aa15389924ef84979beba7516f87f74af","7c4e3beefd3f23452a26f8e3cb4f5a9c8b10c715","23648ebd283b009dc05a8618a6c3f4bc1a4f7815","02fd4ef40fe211d3b7f509d6cec1c9518d2bf392","3d063e575d735937890ddee9d614fffeaff4f206","e3e70393d99ef8d33182f152899a90a4669e6a81","473dad7c5b3c2edca3a933d0855cdbf47a536585","068762661b71ca3b12573b834ac7ee2e6359660d"],"journalName":"Journal of survey statistics and methodology","paperAbstract":"Using multiple modes to collect data is becoming a standard practice in survey agencies. While this should lower costs and reduce non-response error it may have detrimental effects on measurement quality. This is of special concern in panel surveys where a key focus is on measuring change over time and where changing modes may have an effect on key measures. In this paper we use a quasi-experimental design from the Health and Retirement Study to compare the measurement quality of two scales between face-to-face, telephone and Web modes. Panel members were randomly assigned to receive a telephone survey or enhanced face-to-face survey in the 2010 core wave, while this was reversed in the 2012 core wave. In 2011, panelists with Internet access completed a Web survey containing selected questions from the core waves. We examine the responses from 3251 respondents who participated in all three waves, using latent models to identify measurement mode effects. The two scales, depression and physical activity, show systematic differences between interviewer administered modes (i.e., face-to-face and telephone) and the self-administered one (i.e., Web). Possible explanations are discussed.","inCitations":["48047b06956c8013f6ab6fba21047125c2df138d","08df11e7b5cc06b733a107c6c6bc8a0162b2a8f6","6ea1444a489d5bdc7c0e90363ce4661bde26edd9"],"title":"Estimation of Mode Effects in the Health and Retirement Study Using Measurement Models.","doi":"10.1093/jssam/smw021"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2005,"outCitations":["084b980cb494bce7860150ed8bdcb5af44736787","36604b3ee308f66e7c05bc47fc50015de72961dd","0a1f99556725a04eee23fdc1daa735809ed146a8","9db53f724822cd60b5dbaecb6a07b0649743185c","15a2759f9cc160b4b2e7fa5d949121b5ee005938","250a00089830c0387bf478f861129d849c86abae","ebe7526bc38cc1c2523b88b5ab10b3aac8ebaf50","13866e2365c07f3fb05057d1cd3f10be4a799a6b","724decbfb4da4c954abf08af33c9c187d7150866","9bffa2854bb16ee72e17eae571071e5159127526","ac1cabe5a354a855e85ffdeba9e15c3841c4b01f","a1780988f2821ec1d47886aa1fbf933b675878ad","ef84c52cab19692a5a671a42d00a4c6b26ad3e6c","9520ee65abbbdf2fe5d946afc64eeca302041a7e","d7f28b333bc94ba0feb28dc05ad2f36b9ed9ea06","5475385d5082101d78a33fc9b0419aa463697e79","bdf3bcb2b2c75be958d4dae178f5d38a1b82cd6f","72de31338c688d820c30ae5380d5a6b2ad98017a","adbda7e2e333194ff2b444ad15abbb4c93d9f3f2","3d8e5a839e72c3fbee1d9d39706d5683ff9a36c9","c2a807396e6191c2f64c02be5268cca2e8baa528","98551f518c3dcb013bfe1325374c90f5b82d4bd9","aea4d0c5709af7327ba90fe3512b5602c61f004e","86c35680190dcb1a040243927e98e4ca08f8d80e","dc49e47850ec1375aadeecba395652bfe58fd666","2d51cec9ec237bd4563ec5fc6eaafd637366c4c0","0b7299a2cc09436fb00e5484e8feea7c83d416bb","6d638aaa7d65af13b452d3dec0b49940f34ec374","94d56aa2f073821eaf5f89af7f4923519aaa5e36","1cac4b8d9da537328d5de6bf43ea1870578601ac","04b83723eb3f89f4ff68c7cbe1672d0b3ea3a793","569207a31091f201269448643f8548905f716a05","ee7519f22986886e975fe0436ddee9441732e2e9","a8441263a04f317d3e84cd543f6194c74e366ffc","9e32ca85c9b4102d4efe23c6babe0b467cede48b","d681b2a79d9fe0569c7bdff98fe01b3cf2ac9588","f113eb4d8e093a41b1f0db1804008a8cc0a184b4"],"journalName":"Biostatistics","paperAbstract":"In this paper, we develop a general strategy for linkage analysis, applicable for arbitrary pedigree structures and genetic models with one major gene, polygenes and shared environmental effects. Extending work of Whittemore (1996), McPeek (1999) and Hossjer (2003d), the efficient score statistic is computed from a conditional likelihood of marker data given phenotypes. The resulting semiparametric linkage analysis is very similar to nonparametric linkage based on affected individuals. The efficient score S depends not only on identical-by-descent sharing and phenotypes, but also on a few parameters chosen by the user. We focus on (1) weak penetrance models, where the major gene has a small effect and (2) rare disease models, where the major gene has a possibly strong effect but the disease causing allele is rare. We illustrate our results for a large class of genetic models with a multivariate Gaussian liability. This class incorporates one major gene, polygenes and shared environmental effects in the liability, and allows e.g. binary, Gaussian, Poisson distributed and life-length phenotypes. A detailed simulation study is conducted for Gaussian phenotypes. The performance of the two optimal score functions S(wpairs) and S(normdom) are investigated. The conclusion is that (i) inclusion of polygenic effects into the score function increases overall performance for a wide range of genetic models and (ii) score functions based on the rare disease assumption are slightly more powerful.","inCitations":["608852b32bf3cd6e2e4c222fc06131b9e1bde1cd","a8441263a04f317d3e84cd543f6194c74e366ffc","06fef4bdd3e043e93d33d7eedf8f4a367e2eb2ae","581efb919b6658cea25f67eb7009c49f089bdc29","f0ec0288394cca9c61a1fec7fe05ceafdb53bdc0","bd0d9582ab027294f7267043383fbabf0d30264e","cad8332e21cc01daa51d31fd511fd047228709b5","0fede382c50b5e6ffe030417776c6414b6226ca2"],"title":"Conditional likelihood score functions for mixed models in linkage analysis.","doi":"10.1093/biostatistics/kxi012"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2012,"outCitations":[],"journalName":"Spatial statistics","paperAbstract":"In applications where covariates and responses are observed across space and time, a common goal is to quantify the effect of a change in the covariates on the response while adequately accounting for the spatio-temporal structure of the observations. The most common approach for building such a model is to confine the relationship between a covariate and response variable to a single spatio-temporal location. However, oftentimes the relationship between the response and predictors may extend across space and time. In other words, the response may be affected by levels of predictors in spatio-temporal proximity to the response location. Here, a flexible modeling framework is proposed to capture such spatial and temporal lagged effects between a predictor and a response. Specifically, kernel functions are used to weight a spatio-temporal covariate surface in a regression model for the response. The kernels are assumed to be parametric and non-stationary with the data informing the parameter values of the kernel. The methodology is illustrated on simulated data as well as a physical data set of ozone concentrations to be explained by temperature.","inCitations":["2c36a577272b9b1abfbb7285b4ce913a1f43056e"],"title":"Kernel Averaged Predictors for Spatio-Temporal Regression Models.","doi":"10.1016/j.spasta.2012.05.001"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2004,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"The theory of measurement scales, and in particular multi-item scales, has been extensively developed in educational testing, psychometric testing, personality testing, and consumer research. These scales are usually either based upon traditional psychometric models or modern theory using item response theory. However, clinical measuring instruments, including health-related quality-of-life questionnaires, frequently have different underlying principles and so the adoption of such approaches can be inappropriate. The fundamental statistical distinction between indicator and causal variables can be used to explain why psychometric methods fail. So-called clinimetric approaches may sometimes be more relevant, and clinimetric and psychometric ideas should be combined to yield a suitable measuring instrument. Recognition of the role of causal variables enables informed decisions to be made regarding scale development, validation, and scoring.","inCitations":["21cb3a274e471194d90c59fcc30f42b34c4b59f4","c9e452485e709e603366b04b0e5e08cf5606b1cf","c674e4955d4051616b6b677091c060a43b166cb0","19e6db7ab31c53d80ad7d898d70a955e606f500b","8f6bbf6c36828956705890d2d4bd5f0794c7aa6d","d3a0f5feaa74c2ae9f4bfaf6b82556a44989b8d7","095b3dce768e7fcb1ca20ac12ab4175650efdc7a","9e9c8f4da417966b8228aec954f977833eb8164a","a0e71bbf6c659c52f165e2fc595b3ebdb0422d04","9deae93a3e485e88097681c8b554ae0d85675ed1","4597cca18c73a34977af9055550fc888fa4b5b61","fd9f82d74528cf1bd4a50a11b71bc22f16373f25","1e987dd8f31e5c540cd9f61e53a6dc20163ea507","e005282cf21506860d3790c249754a8856a0f0d3","a22ab3a9135978b455a17dd99583872dbc0ba9d2","9c78233800db9d52e6f6d7d83b10e5cde509d178","780a7d5c6deddd45813cc783ba088e90ad4177ef","66dd5293329af4ba4b1fec1b5b9b1334649c5120"],"title":"Quality-of-life measurement in clinical trials--the impact of causal variables.","doi":"10.1081/BIP-120028512"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2010,"outCitations":[],"journalName":"Journal of statistical planning and inference","paperAbstract":"In clinical trials, several competing treatments are often carried out in the same trial period. The goal is to assess the performances of these different treatments according to some optimality criterion and minimize risks to the patients in the entire process of the study. For this, each coming patient is allocated sequentially to one of the treatments according to a mechanism defined by the optimality criterion. In practice, sometimes different optimality criteria, or the same criterion with different regimes, need to be considered to assess the treatments in the same study, so that each mechanism is also evaluated through the trail study. In this case, the question is how to allocate the treatments to the incoming patients so that the criteria/mechanisms of interest are assessed during the trail process, and the overall performance of the trial is optimized under the combined criteria or regimes. In this paper, we consider this problem by investigating a compound adaptive generalized P√≥lya urn design. Basic asymptotic properties of this design are also studied.","inCitations":["63dd3e380025fcf2992ee50ef1266bc672c97ae7"],"title":"Compound adaptive GPU design for clinical trials.","doi":"10.1016/j.jspi.2010.05.022"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2014,"outCitations":["35408a62c256edf76bd035b4ed13c43ec492765f","e684639f3e7e0903013562b926d109dc4dee2a78","26a3b996f390b35176f8f69d8dde0588ac4387fa","a8e1238575d871f83517601939f99743f7228618","85df64c82d3cf341203092856d9be253538e38d2","fd7887e40e4c2dcf82a5c647e03edd4c7af24cee","5f621563eb736339fe804cdc8c273c1af3c919f3","d65040dc931705c778c1f48eb6b454cba61df0e3","a24b7bf40c967f357e66b00dc7d2141a6966986c","a4325e1b013e7bd974afa9c739e86a7845049b29","afbd20072d1f243589ca6067a7753cb31fd99401","944a4d3d1ddb23465d9f27b207c6e1a226751119","6a4d98b3855f06cd17ebdb1e17a13c4300375473"],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"A test treatment is considered to be interchangeable with its reference treatment if they are equivalent and expected to produce the same clinical result in any given patient. To assess interchangeability, FDA Draft Guidance (1999) and Guidance for Industry (2001, 2003) recommend using individual bioequivalence (IBE) and population bioequivalence (PBE) procedures. Chow (1999) and Chow and Liu (1999) gave a discussion on the limitation of the aggregate criteria of the IBE and PBE proposed therein. They mentioned that it is not clear whether IBE or PBE can imply average bioequivalence. Alternative approaches have been proposed to address the weakness of IBE and PBE. Dong et al. (2014) discuss the tolerance interval method and an approximate test for interchangeability defined by a two-sided probability. These tests may not be able to test for the two one-sided tests (TOST) with asymmetric margins around the true mean difference. In addition, the tests of two-sided probability provide no direction when failing the equivalence in interchangeability. Thus, we reexamine the statistical properties of the two one-sided tolerance interval approaches proposed by Tsong and Shen (2007, 2008). In this project, we extend their approach for parallel arms trials and paired/crossover data without the assumption of equal sample sizes and variances. We also develop the exact power function and assess the type I error rate of our proposed approach. In addition, we study the sample size determination based on the interchangeability testing utilizing the tolerance interval method.","inCitations":["753c4c6afe2a41526d5123228695aa5484c13d5c","ab4c786448e5564b8dbc0d028162d1dfaad4c6fb","5af6661eb58356d8cfd4c3323b0b537bff408dd9","121574835b5d91cb7d17847f374d81d755c1540c","8e88bd01be4cf508673d105e2deb33ba74ef1db6","7648847815b5d2cb0e6a42d6f5e013417fa77e8e","7c0d91a26f6b7297335dfc2c5baf1a4c8433373f","e870dc3a4eaee07d11975619104171e18ea194fe","05c4c9fc7e3552b29a732b27fae9db74c10b934c","2a80d543e0e4c27f75c514a174f488848b16d0e7"],"title":"Equivalence tests for interchangeability based on two one-sided probabilities.","doi":"10.1080/10543406.2014.941987"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2009,"outCitations":["2295cc4bccf9f43b3d9329964c2b7a3e2fe3f8b1","326ed5ec92da0b01046c91a3966436949f1a13d1","5ef1b4f5c7bd9a116e99f7f1eda4527449a6482b","a5b76fa17917a8a2d07687e064c327a3056910a4","b6d0906ba50119fca2843b84ded50ed63eefa6ae","8db8646c94852e7b36cb9610fb998faab3eee8bb","3c2824ab6d4fc4da7ccb3253ce122d75a78627a0","a8373a94f9869abc88a3dc81e6b35b5797158e3a","0514c2895a30b47b7c0449ddc87c5f6b7e4f1556","54832f36360fa72c44af21c0bb647c1da6bdd0b3","3842c1a919969ea701459d4c92747ff11dd11f55","245ad4aad5006492d6f0588a05c7468f0d2a91d9","88cbae5b087256967e01e989f6c51e05cbc00c96","7073e12add76eafc44b30adcc7b8bddf9caea76f","0150262658898781b526df04f28c07371c53d63a"],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"Multiple testing problems in regulatory applications are often more challenging than the problems of handling a set of mathematical symbols representing multiple null hypotheses under testing. In the union-intersection setting, it is important to define a family of null hypotheses relevant to the clinical questions at issue. The distinction between primary endpoint and secondary endpoint needs to be considered properly in different clinical applications. Without proper consideration, the widely used sequential gate keeping strategies often impose too many logical restrictions to make sense, particularly to deal with the problem of testing multiple doses and multiple endpoints, the problem of testing a composite endpoint and its component endpoints, and the problem of testing superiority and noninferiority in the presence of multiple endpoints. Partitioning the null hypotheses involved in closed testing into clinical relevant orderings or sets can be a viable alternative to resolving the illogical problems requiring more attention from clinical trialists in defining the clinical hypotheses or clinical question(s) at the design stage. In the intersection-union setting there is little room for alleviating the stringency of the requirement that each endpoint must meet the same intended alpha level, unless the parameter space under the null hypothesis can be substantially restricted. Such restriction often requires insurmountable justification and usually cannot be supported by the internal data. Thus, a possible remedial approach to alleviate the possible conservatism as a result of this requirement is a group-sequential design strategy that starts with a conservative sample size planning and then utilizes an alpha spending function to possibly reach the conclusion early.","inCitations":["0ffa4281c876708bc75d9d2542f6edf7ff4c7fd2","25df9cfcf0103a9ccd93d15081f74679836eac5b","3e40507b213275f501adda4778cdfab9f4b94786","ec85d93990f5bdf41e01c207162c4848e88b32ca","fc88591df0f84fe2892adc945bf296dea5ffcb7b","a9d748ab830d7c20d3a61c86ba147028ad22aaac","47a77b3117ce6c253780d0f0faac71d1763f0158","83df3b8ddee2ce98abd7122856f5e5729059a26d","944d174f82ef2cf003b8e0ca76e709c327d77327","920f3ea3416cac09ff6b70d01bac940a293d2846","c7c15465bd9032c8e09934b13eff38c079d82818","e9ef4f700aae0898ca2a6ad917ea0c65aa03a76d","79a8cff74fac40de6ad25864b8fff320c10edf97","21ae4d54b47b70b0383047fc269c6e40ccfffbbc","b5b414e321f2a9d99b9191b6fd4f37bd8de2c785","58b01c5ff645f35aea439030ca34fe869d5c2ef8","500653e6a559079a5aa52883f3532562be77b66d","6a7b3e26da4c117cfc28ad54ddd8d71bf300293a","780b29f931b7323929f52f50ae170f35dde53a9d","603b5e774356cb716e8204823d824f7c74a60273","333119b0d785ed40673909b5917f8a514f92b1d7","fdfda8d5616d8cbebeab4a1b235a4e5b1ba9276f","9392dc10b793fbde88ca614b7e0fc04de204bc43","162cb04535a661210428fd416f98a23cdc03554a","050a4112bc918c683b6a0cdaad8f1fdc50199522","b620b6e2b431b5a494c5f27326c8e81c7787b7d8","ffc19d712e15d1dbab319506cd9219befc80568d","5b7b9535bc674cb9a75d523bd89f1691dd24578a","b93f9ef4cf683853eb2b03fc7ca1fe3d82b4e80e","0137fb09f57fd3685a6c3a43159c3647b6f1d667","149abcb87fc9e94be418822853c0a71177ae919d","7627b470f8e071285dc6e1311c53df5a28c897bc","86329018e2d19074629a9546365bc81a1dd474fe","c0ddb83e0ffc35b08ef80a75a99e4829f828728d","534672949e7565e021af23f1b0b81371ee49a905","bb14db2049fa93c922d54fbe39ac9854dae51707","cb0235e2d037de835ed2e8044493108802cd0a60","f2d0c63426714f32fa6432403d2bb9900aaace5b","956bbcdd471c49ad626b91ab0759f57acba553c9","58e5fa711ff39dc2ce27a99d763cfc4c7d87bc52"],"title":"Some controversial multiple testing problems in regulatory applications.","doi":"10.1080/10543400802541693"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2016,"outCitations":["7951294b412dfe008ee1baa414ee85ee5e94d3cd","fb9dbfff9f4bfd90bfe1f09b48ce4929874fee12","6916702d9732c030698791dd2359e7fc7ccfc3c8","f7f5e6be3b4f9eb957e66c6e75b0453ddd268b6e","c24c0d6f53ea1243036c3c0da2992c2175628f2e","354a90db4580ed68b05d79545198947a6af9f50a","7877b398ff2c4404f589fd336f00800d0bd28234"],"journalName":"Journal of modern applied statistical methods : JMASM","paperAbstract":"Little research has been devoted to multiple imputation (MI) of derived variables. This study investigates various MI approaches for the outcome, rate of change, when the analysis model is a two-stage linear regression. Simulations showed that competitive approaches depended on the missing data mechanism and presence of auxiliary terms.","inCitations":["7b2500e93a7b8987115ce927a7af142a7891fdf5"],"title":"Multiple Imputation When Rate of Change is the Outcome of Interest.","doi":"10.22237/jmasm/1462075740"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2018,"outCitations":[],"journalName":"Biostatistics","paperAbstract":"Electroencephalography (EEG) data possess a complex structure that includes regional, functional, and longitudinal dimensions. Our motivating example is a word segmentation paradigm in which typically developing (TD) children, and children with autism spectrum disorder (ASD) were exposed to a continuous speech stream. For each subject, continuous EEG signals recorded at each electrode were divided into one-second segments and projected into the frequency domain via fast Fourier transform. Following a spectral principal components analysis, the resulting data consist of region-referenced principal power indexed regionally by scalp location, functionally across frequencies, and longitudinally by one-second segments. Standard EEG power analyses often collapse information across the longitudinal and functional dimensions by averaging power across segments and concentrating on specific frequency bands. We propose a hybrid principal components analysis for region-referenced longitudinal functional EEG data, which utilizes both vector and functional principal components analyses and does not collapse information along any of the three dimensions of the data. The proposed decomposition only assumes weak separability of the higher-dimensional covariance process and utilizes a product of one dimensional eigenvectors and eigenfunctions, obtained from the regional, functional, and longitudinal marginal covariances, to represent the observed data, providing a computationally feasible non-parametric approach. A mixed effects framework is proposed to estimate the model components coupled with a bootstrap test for group level inference, both geared towards sparse data applications. Analysis of the data from the word segmentation paradigm leads to valuable insights about group-region differences among the TD and verbal and minimally verbal children with ASD. Finite sample properties of the proposed estimation framework and bootstrap inference procedure are further studied via extensive simulations.","inCitations":["383fafe47dcb42ca6da0721cbe694c6828a556fe","d2fee95a09bd4b94bd6011068edf40a94e4dfdfb","e252a882d2f6be915adcb3fba9b78c957090c2b9","1137aac11ef631cdd8826d11b1274a10ded185a9"],"title":"Hybrid principal components analysis for region-referenced longitudinal functional EEG data.","doi":"10.1093/biostatistics/kxy034"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2013,"outCitations":["30bfb644c04ac0b0fbd58218151e6238ec61357c","f0efe38b07efe2131cd02c6f87b4a9a81b635216","6fdd089629c22e77809273a72bc988eabd3b4628","b10819aa57b43ed7f3e27c3c6565cc863a59b0ec","d8574a62874312b81347438b1566cdb1c6d5abe5","81a15463a09b9555a78b755e43f9a1c278321ce3","675fce3a47e89cc74ae4b0cc9592fee2fcfad335","d158680063539d86a18b1d47c8b59df375bd6b9c","7d6335d7fec8fa344a539ce2dccd46eada146ecb","793d675269f5def7f3fec81f0c4f30228285405b","d8f0c1bcb6c5afa8cbfe83199b55c014dca08802","4c266531c59bd63464a0f0dcc31452642f634d7b","fd8861991e13dcba3e0ce4e57c529a1c9ce4809e","a0147acdca89e18f26ae800468af6216118e06f3","e8faa25c928573cbaf10c6cf3858725ef7017a1a","b84356fc4f7202ac012f1c9016ec510c27aeea52","42b8aaff0d2ad951256c6921f62dbae47bcd0e71","ddd660f2a83ec98ebb7f0b96499822b8ff35d24b","2d69fe775a7894a187858741fad1fb18c6040407"],"journalName":"The International Journal of Biostatistics","paperAbstract":"Abstract Estimating the direct effect of a treatment on an outcome is often the focus of epidemiological and clinical research, when the treatment has more than one specified pathway to the defined outcome. Even if the total effect is unconfounded, the direct effect is not identified when unmeasured variables affect the intermediate and outcome variables. Therefore, bounds on direct effects have been presented via linear programming under two common definitions of direct effects: controlled and natural. Here, we propose bounds on natural direct effects without using linear programming, because such bounds on controlled direct effects have already been proposed. To derive narrow bounds, we introduce two monotonicity assumptions that are weaker than those in previous studies and another monotonicity assumption. Furthermore, we do not assume that an outcome variable is binary, whereas previous studies have made that assumption. An additional advantage of our bounds is that the bounding formulas are extremely simple. The proposed bounds are illustrated using a randomized trial for coronary heart disease.","inCitations":["b58c9365c768d6b4504d6e38f03e2278c65d745f","4c05f821ce566a82a776c1b2b61512a892fbdf13","e3b3806100853dbe8e85da9362624d852cb1b4f6","b13ca22164620729ade497a756b248ab1678ec85"],"title":"Alternative Monotonicity Assumptions for Improving Bounds on Natural Direct Effects","doi":"10.1515/ijb-2012-0022"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2008,"outCitations":["4b4279db68b16e20fbc56f9d41980a950191d30a","ce6418d15446ef810ab9c8ad8c2b885d257854d7","aa5715fe5cdac17bb177580e219736a909dd5c81","294c8f3df5b79582a1d59e668dd61f52e04108ff","839da4e7db0b33e5c4a744d282fd8f48aba1b3b5","30715b8c4a4bd0bbb51574ba320b156d9687b117","7453b1418a3ecffc12d5d089989bfff31100b835","b622e345c7e2cc1eab2b2c64c3698d5fc4e76606","505c58c2c100e7512b7f7d906a9d4af72f6e8415","fe88589300414a8c8d735438df8324c2d0bc49a3","0382d69d619cb00abfe014128e658d994917ac0f","b09483cc087a9ff9a6aef2220c465050807f144e","0117f9abf33bd8a97f54c91962f0418f33cb7688","4d6caea81ab350bd36020d935a6f61eebad447b4"],"journalName":"The British journal of mathematical and statistical psychology","paperAbstract":"The purpose of this study is to find a formula that describes the relationship between item exposure parameters and item parameters in computerized adaptive tests by using genetic programming (GP) - a biologically inspired artificial intelligence technique. Based on the formula, item exposure parameters for new parallel item pools can be predicted without conducting additional iterative simulations. Results show that an interesting formula between item exposure parameters and item parameters in a pool can be found by using GP. The item exposure parameters predicted based on the found formula were close to those observed from the Sympson and Hetter (1985) procedure and performed well in controlling item exposure rates. Similar results were observed for the Stocking and Lewis (1998) multinomial model for item selection and the Sympson and Hetter procedure with content balancing. The proposed GP approach has provided a knowledge-based solution for finding item exposure parameters.","inCitations":["41f9d2dfd34b4c1d8d3e2bd7d65837466a0d1107","053de8a978b00816260749a60122b4aa2fe92492","bc8655bd4ee6fb182b1f92ea647a33dc6dcabda8","66f0dde18b8196391368d479dd27197c4468caf8"],"title":"Predicting item exposure parameters in computerized adaptive testing.","doi":"10.1348/000711006X129553"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2010,"outCitations":["fdb43a622cb37c00ea3fae567944792721e4b332","4e65058098bda6d1f027aa306ca66d5f03fe4ab9","cfe7469f8d29ab473653274b5470d81be4203330","f558afeec9667b66995b46e306bcf5aabc2898b5","9f282400aa7f9eb4dd221c43b6a9e0aeca9bbc67","d5587c069200835f9d49efd6b5c37aa5805402ae","1da20a7dcf60a9cbfd37d1313a76e2cc77c32745","3fe055f559a84c7002c01ae332635d6e0e541ed4","7ce10624b09c54d2604f60b4c2d48409201fcc5b","9f96169ea4cbd294bc3dcf3ed590e1ce8d0747fd","9d78d82835cb4275ad160875296527eb86871553","12ec8bde5b1d46607bbd86fe401498986d7b8614","bdb0eb999c6d06f84ac331989267ad400b4460dd","fa0f05b6c48120083dd4cc07b85fe22a2e8f6030","8141b79fbe7a810dc26fd6aefb3018a37205f4d7"],"journalName":"Pharmaceutical statistics","paperAbstract":"This paper explores the utility of different approaches for modeling longitudinal count data with dropouts arising from a clinical study for the treatment of actinic keratosis lesions on the face and balding scalp. A feature of these data is that as the disease for subjects on the active arm improves their data show larger dispersion compared with those on the vehicle, exhibiting an over-dispersion relative to the Poisson distribution. After fitting the marginal (or population averaged) model using the generalized estimating equation (GEE), we note that inferences from such a model might be biased as dropouts are treatment related. Then, we consider using a weighted GEE (WGEE) where each subject's contribution to the analysis is weighted inversely by the subject's probability of dropout. Based on the model findings, we argue that the WGEE might not address the concerns about the impact of dropouts on the efficacy findings when dropouts are treatment related. As an alternative, we consider likelihood-based inference where random effects are added to the model to allow for heterogeneity across subjects. Finally, we consider a transition model where, unlike the previous approaches that model the log-link function of the mean response, we model the subject's actual lesion counts. This model is an extension of the Poisson autoregressive model of order 1, where the autoregressive parameter is taken to be a function of treatment as well as other covariates to induce different dispersions and correlations for the two treatment arms. We conclude with a discussion about model selection.","inCitations":["e74dfe2152b19cdc5a27507b17336b2246aaaea1"],"title":"Modeling longitudinal count data with dropouts.","doi":"10.1002/pst.366"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2014,"outCitations":[],"journalName":"The British journal of mathematical and statistical psychology","paperAbstract":"The family of (non-parametric, fixed-step-size) adaptive methods, also known as 'up-down' or 'staircase' methods, has been used extensively in psychophysical studies for threshold estimation. Extensions of adaptive methods to non-binary responses have also been proposed. An example is the three-category weighted up-down (WUD) method (Kaernbach, 2001) and its four-category extension (Klein, 2001). Such an extension, however, is somewhat restricted, and in this paper we discuss its limitations. To facilitate the discussion, we characterize the extension of WUD by an algorithm that incorporates response confidence into a family of adaptive methods. This algorithm can also be applied to two other adaptive methods, namely Derman's up-down method and the biased-coin design, which are suitable for estimating any threshold quantiles. We then discuss via simulations of the above three methods the limitations of the algorithm. To illustrate, we conduct a small scale of experiment using the extended WUD under different response confidence formats to evaluate the consistency of threshold estimation.","inCitations":["726614ad6ffb1004eaa3a7307dea4d910258f800","005a9fa99160df491080f2680f09659cc2a8a0a1","531535f853a6ddc05cb532d050d9171e2d20301c"],"title":"On the limitations of fixed-step-size adaptive methods with response confidence.","doi":"10.1111/bmsp.12018"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2016,"outCitations":["094513a3c0dbdfffee8c1407775dc489b0abead5","5d9761b6f06b3cc9f8b1b1bdda795d6ccac3c93d","bc4bd279f6dd0a7a74172f2c272a694a3b267acf","3e62ceddbe9252875b5dae3b6267db2638af67a6","90a3e5aad244c217699da83f842c25485518e16b","e1ababf08c9ec103db854a2c1b4db611142cfdb7","e1103d528d874a9e8e84ca443fe3fd5c1ff9eb9e","84bc4ed3eeb1966fda7074a444bf81143a035804","7990d9ff83eea3c5a3607c76e61e451c3d6d7e40","102b344d67c4f54a792371fc18ac5663aa469e0e","4ccb8775c4f2c2a2c0ab108cd02d58fb52997489","708857b59a65cda6fafc6d99c31d175720e75cb4","b969ce8edb9a75b5d92353fc24be9da230f03af2","d4d705db1a78856313358539e84249f7a6ac1947","60cb1947f1149c625bf7cc0511d1fffe2f189828","3f2434c0bceee5a90992b2557e67b63f74a3c9b9","b8500d23e3feb60a4008f90094929e672bc76006"],"journalName":"Biostatistics","paperAbstract":"Non-linear mixed effect models (NLMEMs) are widely used for the analysis of longitudinal data. To design these studies, optimal design based on the expected Fisher information matrix (FIM) can be used instead of performing time-consuming clinical trial simulations. In recent years, estimation algorithms for NLMEMs have transitioned from linearization toward more exact higher-order methods. Optimal design, on the other hand, has mainly relied on first-order (FO) linearization to calculate the FIM. Although efficient in general, FO cannot be applied to complex non-linear models and with difficulty in studies with discrete data. We propose an approach to evaluate the expected FIM in NLMEMs for both discrete and continuous outcomes. We used Markov Chain Monte Carlo (MCMC) to integrate the derivatives of the log-likelihood over the random effects, and Monte Carlo to evaluate its expectation w.r.t. the observations. Our method was implemented in R using Stan, which efficiently draws MCMC samples and calculates partial derivatives of the log-likelihood. Evaluated on several examples, our approach showed good performance with relative standard errors (RSEs) close to those obtained by simulations. We studied the influence of the number of MC and MCMC samples and computed the uncertainty of the FIM evaluation. We also compared our approach to Adaptive Gaussian Quadrature, Laplace approximation, and FO. Our method is available in R-package MIXFIM and can be used to evaluate the FIM, its determinant with confidence intervals (CIs), and RSEs with CIs.","inCitations":["d3367c9f9086a6437eb32d35f383abae42c18ad1","cc9d818270cb225fe55ff0ecaa7d5bf133b530f4","cb5e04b32f2f977795185182ea93a4143d733f99"],"title":"An MCMC method for the evaluation of the Fisher information matrix for non-linear mixed effect models.","doi":"10.1093/biostatistics/kxw020"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2004,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"Clinical trials necessary for the development of new treatment often require testing of multiple endpoints for equivalence or noninferiority relative to an existing effective standard therapy. An example is a vaccine study with multiple antibody measurements in sera of subjects receiving a combination vaccine such as a pneumococcal vaccine, which contains many different serotypes of the pneumococcal organism. This article describes testing methods for the demonstration of simultaneous marginal equivalence or noninferiority of two treatments on each component of the response vector that follows a multivariate normal distribution. Systematic simulation studies are conducted to evaluate the performance of the testing method and to examine under what conditions the power is substantially different if the multiple endpoints are assumed to be independent when they are actually strongly correlated. Data from an illustrative example are used to describe how the study power can be evaluated in the design of the trials.","inCitations":["450a2b7a61bec0af7e3951d9bf7d551617e10c29","ed70a5d90d0a83b60bcaccc3a4de69b712b94ee8","245ad4aad5006492d6f0588a05c7468f0d2a91d9","5b3bbede2becede44f8db8be9313bff6aa3d7e00","2623679131bc70e5fd672b09c70f2230136b6147"],"title":"Type I error and power in noninferiority/equivalence trials with correlated multiple endpoints: an example from vaccine development trials.","doi":"10.1081/BIP-200035454"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2006,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"One adaptive design is proposed and studied by Bandyopadhyay and Biswas (2001) for comparing two treatments having continuous responses with covariates at hand in a phase III clinical trial. On the other hand, a drop-the-loser urn design is recently proposed by Ivanova (2003), which is known to have the least variability among urn-based adaptive designs for binary responses. The drop-the-loser rule for continuous data was recently introduced by Ivanova et al. (2005). But neither of the works considered covariates for the allocation design. The present paper provides a version of the newly proposed adaptive design, drop-the-loser rule, but for continuous responses and by incorporating the covariate information in the allocation procedure. Several exact and limiting properties of the design, and also of a simpler version of it, are studied. We compare the design of Bandyopadhyay and Biswas (2001) with the covariate-adjusted drop-the-loser-type rule for continuous responses and conclude that, although the drop-the-loser rule is better for binary responses, the design of Bandyopadhyay and Biswas (2001) performs better than the drop-the-loser-type rule for continuous responses with covariates. We recommend the existing design of Bandyopadhyay and Biswas (2001) for practical purposes.","inCitations":["082e38a56d256c7c13dea137f465dd330c4eb768","e78533f9f6e834ffa0743f7b64e449902e46b335","017aa5f633ccc783fd38e9ff01950e67e320c7cf","88e0086a960d4066d9e2b6b2e82c5c4bd548534f","c99527c24bc62716f3fbcc4270284a55a82686c2","b7b13265ad876c761837456d26f699fe97a3643d"],"title":"Covariate-adjusted adaptive designs for continuous responses in a phase III clinical trial: recommendation for practice.","doi":"10.1080/10543400500508929"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2015,"outCitations":[],"journalName":"Pharmaceutical statistics","paperAbstract":"This paper considers the maximin approach for designing clinical studies. A maximin efficient design maximizes the smallest efficiency when compared with a standard design, as the parameters vary in a specified subset of the parameter space. To specify this subset of parameters in a real situation, a four-step procedure using elicitation based on expert opinions is proposed. Further, we describe why and how we extend the initially chosen subset of parameters to a much larger set in our procedure. By this procedure, the maximin approach becomes feasible for dose-finding studies. Maximin efficient designs have shown to be numerically difficult to construct. However, a new algorithm, the H-algorithm, considerably simplifies the construction of these designs. We exemplify the maximin efficient approach by considering a sigmoid Emax model describing a dose-response relationship and compare inferential precision with that obtained when using a uniform design. The design obtained is shown to be at least 15% more efficient than the uniform design.","inCitations":["be134a603f98ebdb1f70676b42cf3a45dc581b17","a85c9be1c1e3a21fc73fdff6454ef139c9f5519b","27e63c71466ce279c14e04e72c1699a206288d8c","6f1a9e45d89309902d761db56d1d71e11ae505be"],"title":"Implementation of maximin efficient designs in dose-finding studies.","doi":"10.1002/pst.1660"}
{"fieldsOfStudy":["Mathematics","Computer Science","Medicine"],"year":2019,"outCitations":["d83f37659d418a915c0b06def402bd0c32ae0ca8","d4435292f076384d1a76f39fd100c8b369cf3756","7ce0be405be5ac06650bef176a6b4fd9ba7d5af3","3cd515fbb37b023585bc7dd90fff444c38e9b39a","767a4cd5d8b877845291d2a0515b913a84dcf8cd","837176dce5792d3e2dcb613beb199b584763c7ce","d1f6e58c049131c874c9ce047c90b0f876fa0b0a","1bee24b85a60e9d933a429f2b2e7f46407d3ca13","ec4ddf899007e65fac4754c9506174c156d7e607","0f48f4a415d93ea5dccb6ba64f5861cf362e38d4","49600dc65804751ae38c22eb0d61ee8593b3716c","4413c6864ce0803d25f70760d6a229def7bcf392","e02bc64332a84f8aef992b2605bf0b7530a45297","2ea931fb55701a5f5b82aa491a64c0e431fb4b38","adaf164405e1d8f8e04f12cc6805c70dcedaa295","870d0421232ab5c1e8d6e394612e1d3dada22635","d6189989ac587f0296e0d65e51faa18db947affb","abce70fbc53c990bdf0c24931a412946c5c6d6f6","7f33f65a48a2bbb193c0fd15bbf1e533dcbab22e","913cd58807990b0de85b18dc2961d41363076611","686261e8a8c91c760a10747b49090ee55597aca6","618aeceee6ca739b6019562a2ab4ae3bf02d3ea4","6c8b6acf451b9e53ef2ed6ed3da4c107df248961","5b2e82fc9f763b1598618421340def4dd4301c01","7c9c96531aae7afc6bdfbcb1a6e03b20d779a17d","0433549dfd5335a3e684ce53cf90d672fd91869d","c2b1eab16b833b6451ce2bc12477c40c2274e802"],"journalName":"Journal of multivariate analysis","paperAbstract":"Case-controls studies are popular epidemiological designs for detecting gene-environment interactions in the etiology of complex diseases, where the genetic susceptibility and environmental exposures may often be reasonably assumed independent in the source population. Various papers have presented analytical methods exploiting gene-environment independence to achieve better efficiency, all of which require either a rare disease assumption or a distributional assumption on the genetic variables. We relax both assumptions. We construct a semiparametric estimator in case-control studies exploiting gene-environment independence, while the distributions of genetic susceptibility and environmental exposures are both unspecified and the disease rate is assumed unknown and is not required to be close to zero. The resulting estimator is semiparametric efficient and its superiority over prospective logistic regression, the usual analysis in case-control studies, is demonstrated in various numerical illustrations.","inCitations":["e974164e36d3ba636dec5c2ad97895f325090010"],"title":"A semiparametric efficient estimator in case-control studies for gene-environment independent models","doi":"10.1016/j.jmva.2019.01.006"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2008,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"We provide a set of formulas that allow the combination of separately performed analyses of population pharmacokinetic (PK) studies, without any further computational effort. More specifically, given the point estimates and uncertainties of two population PK analyses, the formulas provide the point estimates and uncertainties of the combined analysis, including the mean population values, the between-subject variability, and the residual variability. To derive the formulas we considered distributional assumptions applicable for the conjugate priors of the Bayesian problem of \"unknown mean and variance.\" In order to demonstrate the approach, the formulas were applied to an example involving the results of fitting two real experimental datasets. The formulas presented offer an easy-to-use method of combining different analyses particularly applicable to a combination of literature information.","inCitations":["ff285396414ee1283ae4758cc1ca48bacdaaa663","735f87edbbdc78e23c64e01895c20d68e34edd6f","588e46ee04aa364f803b05eaaaeaa92bdde2c76a"],"title":"Analytical expressions for combining population pharmacokinetic parameters from different studies.","doi":"10.1080/10543400802071360"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2014,"outCitations":["eea30ac24c5b70d8fb9fd3e7f4bcc9bf06d42c49","e63328b74b3718e59e83b00647dc0f6076bcab5e","609b583cec63ab2cd7246c6fcb2a2ac5c8162ceb","d7ce745d427d2bc0ad4bf73fce50418db297af2a","56bafb8442ddaa506dc7f7d62f2a371f076031a9","f456e1fe56d71b0a12f588fc16db88cd2d46e1b5","dc7189296ff23316c19b55e019f0a5e5f0fd9aee","a85acbe6ff39173031d877eaf79af3ca52bbc20f","cc0b477e8034219062843a2c2b446f3df323674e","4adae4fa920c5896353f958e786fd3da72e9b3c9","f867e56d3a8ac2bbef6bfe5c74ee80ab43239718","8d585b634404749e2a6973bd91c58fd33cfb9b9f","eac0d806dcc051244cfd1e51cf7523b465b7bc3e","b0be5fb3067f4040a59e26bdaf13e9c4874e0c83","4227e4782dcaaa6c53ff703d44bfe08179d275b8","dd52648b35aaae3bb4a3614d51402b539fd12481","6916702d9732c030698791dd2359e7fc7ccfc3c8","74eb6fc1c039b5fcb4a5c50866d367070048eeff","d341f9a9cd63f6f553114c60aa4fd2de4e5edc7f","d1747122d0e53a8277f3a08800baeadd8f451a35","f42d82d7394f846aae98f73dd091832740aa3745","1010951b8cec238b872879bc5b34747be2f7b60f","2219b330ef98f6ea71a172659595b7506fca3633","1466fee22d33bbfdd4117e83e15f81708e4331c3","e841fa3834e787092e4266e9484158689405b7b0","f33d3f91059fccfd8449d39831e7a4c50d1b3091","3467e34cae93c33c1be8c3dc0fa4a3a6405e18e3","fb9dbfff9f4bfd90bfe1f09b48ce4929874fee12","088447d1c9d41dd5c6f730e5accbfda151f91593","4a6ece2d94f230f49c080d30d95ee22735fdb021","990c7457ff255ca023a6815c1e69eba0ca215698","f558afeec9667b66995b46e306bcf5aabc2898b5","13b30e35b9a54dad07094cfe4f50d40ff15d8370","7edf9b7c1aa90b6ba45db5facd4b07ee1067026c","87fc7f6e80295f5ec7a3904474a127c9400d8a45","83b55649a9923db46a3c56fd0a88964cb26a60be","e6a0dd7b777b25d8d75053ee2a75e90e410fd069","97f02fff673fcea5267ae604617bee91533b1fc0"],"journalName":"The British journal of mathematical and statistical psychology","paperAbstract":"Missing values are a practical issue in the analysis of longitudinal data. Multiple imputation (MI) is a well-known likelihood-based method that has optimal properties in terms of efficiency and consistency if the imputation model is correctly specified. Doubly robust (DR) weighing-based methods protect against misspecification bias if one of the models, but not necessarily both, for the data or the mechanism leading to missing data is correct. We propose a new imputation method that captures the simplicity of MI and protection from the DR method. This method integrates MI and DR to protect against misspecification of the imputation model under a missing at random assumption. Our method avoids analytical complications of missing data particularly in multivariate settings, and is easy to implement in standard statistical packages. Moreover, the proposed method works very well with an intermittent pattern of missingness when other DR methods can not be used. Simulation experiments show that the proposed approach achieves improved performance when one of the models is correct. The method is applied to data from the fireworks disaster study, a randomized clinical trial comparing therapies in disaster-exposed children. We conclude that the new method increases the robustness of imputations.","inCitations":["132c6137cc52a9440e972d6f803960b4624bd883","e064f78fc92bc8ddc3a86313551f075b2fca3435","0f43de325598005f59409394a2cc763b4a1da3c1","4ab06bdf1dee2e498312caa00b1523d9ffb646ea"],"title":"Dual imputation model for incomplete longitudinal data.","doi":"10.1111/bmsp.12021"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":1993,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"A simulation study was conducted to compare the levels of significance and power between Schuirmann's and nonparametric two one-sided tests procedures for a 2 x 2 crossover design under different combinations of sample sizes, intrasubject variabilities, and underlying distributions. Empirical results suggest that Schuirmann's two one-sided tests procedure is robust to minor departure from the assumption of normality.","inCitations":["96f7dc695568b4fe557972654ed99271dea2fb3a","ca6b09bec35dedafeba7d6278bf7985361ede1ae"],"title":"Evaluation of parametric and nonparametric two one-sided tests procedures for assessing bioequivalence of average bioavailability.","doi":"10.1080/10543409308835050"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":1991,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"Comparative clinical trials are usually conducted to compare the means associated with the treatments. However, it is often also of interest to compare the variances. Here the problem of testing the equality of the variances associated with two treatments in a two-by-two crossover design is examined.","inCitations":["d49f9ec8be916bb04b12e5a30924cd7ae62bb843","d1c59016499b5386a0e0bb6203f55f3584f9536c","469722440b531c75eb4667b3f9a6d7e50374df59","01ca99f323135b318416633c2d2661943fdb9e7d"],"title":"Testing equality of treatment variances in a two-by-two crossover study.","doi":"10.1080/10543409108835017"}
