{"fieldsOfStudy":["Medicine","Mathematics"],"year":2004,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"DNA microarray offers a powerful and effective technology to monitor the changes in the gene expression levels for thousands of genes simultaneously. It is being widely applied to explore the quantitative alternation in gene regulation in response to a variety of aspects including diseases and exposure of toxicant. A common task in analyzing microarray data is to identify the differentially expressed genes under two different experimental conditions. Because of the large number of genes and small number of arrays, and higher signal-noise ratio in microarray data, many traditional approaches seem improper. In this paper, a multivariate mixture model is applied to model the expression level of replicated arrays, considering the differentially expressed genes as the outliers of the expression data. In order to detect the outliers of the multivariate mixture model, an effective and robust statistical method is first applied to microarray analysis. This method is based on the analysis of kurtosis coefficient (KC) of the projected multivariate data arising from a mixture model so as to identify the outliers. We utilize the multivariate KC algorithm to our microarray experiment with the control and toxic treatment. After the processing of data, the differential genes are successfully identified from 1824 genes on the UCLA M07 microarray chip. We also use the RT-PCR method and two robust statistical methods, minimum covariance determinant (MCD) and minimum volume ellipsoid (MVE), to verify the expression level of outlier genes identified by KC algorithm. We conclude that the robust multivariate tool is practical and effective for the detection of differentially expressed genes.","inCitations":["e070fe45ba837473302221a223454be54f1622d3","9b1104b2ccb8953078977efc8f2f79479c6f5801","5a731865baac2ec1fb26c5ae98dd6a0568385b31","e05306b0aed0958afb0f6794f1e6b4920c62b87e","e0645860491ea4c2b17796f487c0920b1ce57057","40a1a2be097360198370309e1da90884469a9b02"],"title":"Identification of differentially expressed genes with multivariate outlier analysis.","doi":"10.1081/BIP-200025654"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2010,"outCitations":["09d25c3d58757d778c5b87f928218f61b5c6b8eb","66d51658707820c8df744fab41a5a45ef037742c","7c0b880018df6ff9db26a86b4ed4b46439a2be78","caa1467000e339123201e8d65c7928f7f6af5844","c858d618426dd4d2829d0fe625982805e081af1d","a3bbec1b5cdfeb40fc44e664da892da5a9b6cca6","d2f5fc32852ec9b878c9ac902a31eb2ad9495cc5"],"journalName":"Pharmaceutical statistics","paperAbstract":"In recent years, multi-regional trials have received increasing attention by pharmaceutical companies carrying out global drug development programs. In Japan, new drugs are often approved several years after market release in other countries. The recently published guidance on 'Basic Principles on Global Clinical Trials' addresses specifically this time lag. A multi-regional trial has at least two main objectives. First, it is necessary to show a significant benefit in effect of a new drug in the entire population. Second, one needs to demonstrate that the results for a particular region are consistent with those from the entire population. In this paper, we discuss the methods proposed in the Japanese regulatory guidance document and derive closed form expressions for the resulting probabilities, which require the evaluation of multivariate normal or t probabilities. In addition, we propose an alternative method with better operating characteristics than the current approaches. Moreover, we examine the performance of our suggested method by simulating the probability of achieving the objectives and calculating the false-positive error rate.","inCitations":["9dd6a9fbee97451c6d4012a2697564aa707a770c","1df7844a86ba849d4eb46329cc8f36079dd587a1","6ea0386a2e635cac2f5b2e0015047cc809c0b47c","f9aa37f7b6c052dbb872ed36d9b5e4c2c1a35f5b","b12dc3f2ba8fa678e9096d87df132e4562cfeadc","349c39bca8463f1f768e6cd50e2fac66348923b6","500653e6a559079a5aa52883f3532562be77b66d"],"title":"Sample size and proportion of Japanese patients in multi-regional trials.","doi":"10.1002/pst.455"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2019,"outCitations":["8130fdc0bb37acf99387193095a2eb717abaf493","d8a58c84bc60e7d51b1c14a6013fca38bd2aefb2","3c6a73a24351a7977cd2afdac95c18b3919c1311","03d6a1d5e508320919bc13380a3ba106b5b17cf7","5634935c1ce1681a29c3cc733c8bf48a4ec27f5e","9a7a0287bacf0ccb08a305f6052b9666e4c40963","bc37489e7173c75be152b2fcea35191c68847ab2","2d02221977fda49c46a7de50b05175d3541e6ca3","1c2a34272a452ccfca8685377fbcb63759b9c7d9","94d642ba3b0f46109dfe531509a910475fb33366","785f15ad68a3a90f64b8de9310a0c677e716a00e","ac52d7faa2b69a8c0efd9ea3671d15a292ac9e7e","15da583eec9741673cbc96e8797a9a3fbb87dde8","a3aa16910423d0108bb8fb1874195251e7c33f14","cd69b4cb74582a5a20963c7790fcd98a735528df","d88d672d1ec52cb91c53bb5095b1d581001824c0","ec2e7ca4ea749f13d16c29ca497b4a85b1fbd9e7","310fadb2d9908151578ad09be23b1b96c3e9fdf3","6c6ff5dd361a9bd026717df4ca5b05b57355c0df","ef67687379a9d48a811e5edeecb2c8a8540bfb09","477550cced0f4763cdaa1f40fea22013ddd1c65e","387488f95614516347c07d1d6889c805b4cacd51","73ce06ce03b719a4a9d71c8c624f9a100452dfe5","6d6fa364cdb69e1ee9566b01195d715c3b32b190","2071d8f5ab58237ee70258300c1b7840cbda6ede","84db722252682601f6d88f53a74bdf6f26764e61","16b91b3444d6e971877f57e68b306f1de8b023ae"],"journalName":"The International Journal of Biostatistics","paperAbstract":"Abstract The receiver operating characteristic (ROC) curve and their associated summary indices, such as the Youden index, are statistical tools commonly used to analyze the discrimination ability of a (bio)marker to distinguish between two populations. This paper presents the concept of Youden index in the context of the generalized ROC (gROC) curve for non-monotone relationships. The interval estimation of the Youden index and the associated cutoff points in a parametric (binormal) and a non-parametric setting is considered. Monte Carlo simulations and a real-world application illustrate the proposed methodology.","inCitations":["5210d955ac16d9831eb751d3e1b420c966ccff6d","b2c93c4873194cb2b2e45454c08174feaded4e89"],"title":"The Youden Index in the Generalized Receiver Operating Characteristic Curve Context","doi":"10.1515/ijb-2018-0060"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2015,"outCitations":["c936668a0ed3fe435298b661231e18c5c7368a49","78c811c9c29ff13f44ede53a42faaa38a8ce32ea","a6563be2bbc0a9b1ebf54362916ae0cb22db46b7","1932cf4da736d54e5d5ae6c82781a7c8f5693ce2","eb59cf7717b6db35f54ad5b06e909c7d15e88dc1","7cd3bcaca9658349350c450d1b5e1051180b7aa9","fb511e58d430ba648ecd7bdbbe5b902ad03772cb","1545362fd28dc5c6406117892d22f455cda6460c","f173eb4dd80b42f06448a7db08133c829aea7ad9","97510e2048af0c6c510aed405091514946c4eb13","20fb050452107548185580adfe9f1ed521c30532","4c52ba78db5f29132d7f77db4f6c3d4f4ff0d276","861f1bf85053038af051801981369e1c6465b139","3c0376b6710b4c21bc8dc76c15d80c45583957c7","2d611458f70a315dec999cd044def11b28920a0b","8d1c588d202f150e1797ed113fba7e67bfa43ecb","24db02cd419238b91650f7c4492b5dfe329f88b1","57d60377699533fc4fc147e13bc882e9b3eafc47","ee7f867739a0d638997bb0f63b6ad18a38bd5be7","7081140c9035e1d0aad08df76cc85ad76eb5bbc8","884e67564eca9c19e5e4a72ddc847996bfd138f6","87bbcbc06a605a2fb65dcead3dac4adb712c8ccb","4b0be901277263048cb0d48e6488adb6615a5f0c","7a3a81eba3edf166622df6865d42bfc70139cc35","545122e2990590524459ec9b59ccac6ce71e3b6a","e67af0d0f5775c56c96adda97b6ad6d588ddc741","e9bfa82e4252e1bb1ef5326209eeda977a6d8b76","4661acd7af5d7f8708eba9522f588a84bde1d4a4","017ec0fb815db8d589d95239ce416456ba8460e0","c7381ede82b222eadcb065a6617a1552588c8f9f","0218ca73773ad4936117d9767b9470d66da40b40","03b5f73674a7ce75bffc619b3a8fbfdcbf524d32","9e5ca3de57272127ec97af99c19933e9064ac449","543c861ec4c8a1ba02bde4c6281a3f66fd7b0a6a","9b9087bbe84889bca98f65c7c6dd1b92fb15d71b","b9f5f24513c4958c5f209474b14b929a6841cf3b","26213739650e7afc9ea576c9b4d9115d9a222351","d158680063539d86a18b1d47c8b59df375bd6b9c","39e9d249796f9118661ecb2876af9e8fcff8a0b1","c14194bb9bc01767eb0f966cc8f8414e069d1c41","af3a519e16c79693cc7a6eb4bf2ca8826b36cafd","a97a6ad64e20f1fd0a636c1c2d3eeaff1013be57","9a99bf314c4d28c159349c70b286024e991058e4","0c9b91da73d83a77959090251daee7c531140225"],"journalName":"Biostatistics","paperAbstract":"Mediation analysis is an important tool in the behavioral sciences for investigating the role of intermediate variables that lie in the path between a treatment and an outcome variable. The influence of the intermediate variable on the outcome is often explored using a linear structural equation model (LSEM), with model coefficients interpreted as possible effects. While there has been significant research on the topic, little work has been done when the intermediate variable (mediator) is a high-dimensional vector. In this work, we introduce a novel method for identifying potential mediators in this setting called the directions of mediation (DMs). DMs linearly combine potential mediators into a smaller number of orthogonal components, with components ranked based on the proportion of the LSEM likelihood each accounts for. This method is well suited for cases when many potential mediators are measured. Examples of high-dimensional potential mediators are brain images composed of hundreds of thousands of voxels, genetic variation measured at millions of single nucleotide polymorphisms (SNPs), or vectors of thousands of variables in large-scale epidemiological studies. We demonstrate the method using a functional magnetic resonance imaging study of thermal pain where we are interested in determining which brain locations mediate the relationship between the application of a thermal stimulus and self-reported pain.","inCitations":["1ecd4588a28f9386e3cfb1f10cb9f381a602cc8c","7787cf8af227d6d4b4744e3067a191d72bcd697d","68b44bae8756232eefee4a213c94125c0c3da234","41825192562676c9564e920b8d26bf24acc7e44c","789a954a705816c0e01e22f70e32b54428e08ab1","9c056f506aa3d48564f1e2caab71958c4e859db5","8251f99ad6c23cb9e27971c4e730751b213cf0ea","0e377bed365a2d49ebc2154956bfd0759b3760e2","812ab339620cabbbf85ee143ec51c1c00dfb31e0","946567ae1a6c5f61f115a4309da2e0fe03e6f327","a55fd138c719fed5b9467fdecd0e57c66c31dede","306a9b72ee2f0d207147439008c5cc4f540ebab2","3c0ed2bf58437aa2dc7977d49f3b305215848422","93b10e02655c4780b14d5ac20152496e9cf564ac","c953b88dee843fb7846d5612a6a3adb54c8b8bcb","3e972e1d517edbdf643468c306eacb85dd98020c"],"title":"High-dimensional multivariate mediation with application to neuroimaging data.","doi":"10.1093/biostatistics/kxx027"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2000,"outCitations":["8417310eaf3e5a7e1d33794831f2748b058c3e87","b9bb6963c8291a9a3b697d30d8e8979c25c51f02","702b2fb4e27df219c8dbc4452546a778a16f96a4","10b4ed3eaf5947a0314b775c02585626ab765b7c","f5d7d06db91d2c82f361c2c3b8697a6156879753","efa296faa52fd7799002315956f082f631b99ac4","7b261c11533a4bdcb14f10d840660bd60fc5130a","79a12626b1c5fc523196157ecae4206a406bbca8","bc20b0d8037780f976453089b84dc40c19e5958a","f8d65d3d73bcb4cdc99ab96a049e567b98520e32","94d6a5ed17042dfac7a756202bfb019ff84080fb","983fe6d87c51af83cd0c699e4225e923131da56e","22d07c1c71e6bc55de967747f86900e0c3bdcaf5","040cf85e53e48aab1512ed8dd02d994eea0e4bcc","32653d6f4785e24536d4da39be939a0f6e219487","cb206828a05e6fd16af34be901ab5eb7e5380617","adf3347c57bb79219d9397d63157eef9eea373db","c50342756c4f303bfacc89c48223a6f1b64a7029","a8a9b46d7cd26619fd87f7f6f3be4c62d8e41046"],"journalName":"Biostatistics","paperAbstract":"In many clinical trials and evaluations using medical care administrative databases it is of interest to estimate not only the survival time of a given treatment modality but also the total associated cost. The most widely used estimator for data subject to censoring is the Kaplan-Meier (KM) or product-limit (PL) estimator. The optimality properties of this estimator applied to time-to-event data (consistency, etc.) under the assumptions of random censorship have been established. However, whenever the relationship between cost and survival time includes an error term to account for random differences among patients' costs, the dependency between cumulative treatment cost at the time of censoring and at the survival time results in KM giving biased estimates. A similar phenomenon has previously been noted in the context of estimating quality-adjusted survival time. We propose an estimator for mean cost which exploits the underlying relationship between total treatment cost and survival time. The proposed method utilizes either parametric or nonparametric regression to estimate this relationship and is consistent when this relationship is consistently estimated. We then present simulation results which illustrate the gain in finite-sample efficiency when compared with another recently proposed estimator. The methods are then applied to the estimation of mean cost for two studies where right-censoring was present. The first is the heart failure clinical trial Studies of Left Ventricular Dysfunction (SOLVD). The second is a Health Maintenance Organization (HMO) database study of the cost of ulcer treatment.","inCitations":["83608b16913bc75061a2c5df123d81017748339e","4eef17f00719a1a808fbd5eb0759cfd3a6c3d69e","9b261a4898de9afa00ab79252227c75768ba9cb7","fa8faf5dd8fb167676911181c5cdbcb703525abe","2d71489cfe78a993259abef38e72793e49f8c4b0","7886e0cf8d93dc8501a0e8e2e1f1b9f22b1b83d7","b04de92a58ddb45b9c4f674f64c4468ece682a7a","862d6dec723b556b63bb971b541250a958b66996","be6825c79e24d84ebf244d5223e45e6772b76e31","4cf468e3688d89ac967a171a87563bdabd2e81b2","9895b8cc294d6ca756a40d455ef13c767671846b","97930775547f1f7789ba7f32b7daa8d905ea88b6","379e255e18a7af2d08e33084213d20e7aa6ebf3d","7cba74bd9fdd1faa0379806bcd457fa21f4c2ccf","4f9cb4825eecce86dbc7826f17cc12d640a16d75","e8da4813e7d148c23f0d51ac692f453b1c0c7c06","df2de31b0559943eaa772d6b9cfeaa879c658439","77fb234df08b2c643a056ddc3b527d8f31509b1c","054baa48a1f6c119c92f575b549e7a0fc80c6a7a","6229a1802ba65a7a1ffd22a35af7219fc8a4286e","094d0660f1e6d19db52f650f577f21d6bb2e92be","0bdd55d3509f1466e2bb85f7a9e3752a219ecd33","bcbe6e714a63a510dfbf6375bb9c32f8bb0e9ba9","8311476a844ddabc6f5a3a93c487c5e3004a2b36","eed9dcd8582025d2d2f8aa53eaeca8e137b2b206","d9d22c6c3afe406e39dd0dde31ae8d7e5b15a9a8","513612164db35105937748a333bbdb9a6dfd9b08","139daa05f423e82155a3b71d9fbbe12e477cdba9","80d5ff02951ea33781c320891a74a9b686268238","d875a26f50d9e648e1b55d198962c07538207b65","c4f5d3dc0b8542bdd4a296ac44be5c7621b3b9e4"],"title":"A regression-based method for estimating mean treatment cost in the presence of right-censoring.","doi":"10.1093/biostatistics/1.3.299"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2019,"outCitations":[],"journalName":"Pharmaceutical statistics","paperAbstract":"Sample size reestimation in a crossover, bioequivalence study can be a useful adaptive design tool, particularly when the intrasubject variability of the drug formulation under investigation is not well understood. When sample size reestimation is done based on an interim estimate of the intrasubject variability and bioequivalence is tested using the pooled estimate of intrasubject variability, type 1 error inflation will occur. Type 1 error inflation is caused by the pooled estimate being a biased estimator of the intrasubject variability. The type 1 error inflation and bias of the pooled estimator of variability are well characterized in the setting of a two-arm, parallel study. The purpose of this work is to extend this characterization to the setting of a crossover, bioequivalence study with sample size reestimation and to propose an estimator of the intrasubject variability that will prevent type 1 error inflation.","inCitations":["bd370e242839dbad04fc2fd95995097b8edb5c86"],"title":"Controlling type 1 error rate for sequential, bioequivalence studies with crossover designs.","doi":"10.1002/pst.1911"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2012,"outCitations":["1c6df13290553cf76ca467959e610ce664d2df58","5ef64e29b9ec2848831510c435d4d891d327d65e","346e681210aa6a44c590d5e1a318c5173f822f45","9c8ec1467863467b55a4d7fd3112afa553471300","f8d499dbcf3099c720bce8460820b96316744015","3aab1ec64c94c7a8217d50bed0a793275ce0e2aa","0ec69348f1c6cc34de6bd8f9da18b0692673b03a","6e89cc3a48b6eb9d14e7d1a7b1603cb73ef66537","8a990b5fdc3b5bb662b297e3899481560848bf74","4f8a2039af5598dfc345de8e8cbc4c52875b0b0a","0a509260015d2910fd41f19d98f064e96be1e653","380a107b42489558f2b6df849910e04f0280682f","6afa524382ed875954f5a1d534da3878fb4dcaff","871722c8b97620cd0cafd12db6f4a6efafe1feb7","fad7420f2566022872bd79e1c2a28e347c37d68a"],"journalName":"Pharmaceutical statistics","paperAbstract":"The two one-sided test procedure (TOST) has been used for average bioequivalence testing since 1992 and is required when marketing new formulations of an approved drug. TOST is known to require comparatively large numbers of subjects to demonstrate bioequivalence for highly variable drugs, defined as those drugs having intra-subject coefficients of variation greater than 30%. However, TOST has been shown to protect public health when multiple generic formulations enter the marketplace following patent expiration. Recently, scaled average bioequivalence (SABE) has been proposed as an alternative statistical analysis procedure for such products by multiple regulatory agencies. SABE testing requires that a three-period partial replicate cross-over or full replicate cross-over design be used. Following a brief summary of SABE analysis methods applied to existing data, we will consider three statistical ramifications of the proposed additional decision rules and the potential impact of implementation of scaled average bioequivalence in the marketplace using simulation. It is found that a constraint being applied is biased, that bias may also result from the common problem of missing data and that the SABE methods allow for much greater changes in exposure when generic-generic switching occurs in the marketplace.","inCitations":["a6f20412452bef97ed8c84db4315bf76a6a08e9d","8f5151966d00f70da9227508f9b1d2eb2fbdaaa7","b3af5c3197c2ed22af173f8bf29bf43060ce231d","00dbe9af5fa031bf38808dd9f03abfee3de0fb4f","873d14b04c6b26177567a8fc1d04a23b3f2d3722","4ff46f4b0563ea6bd59b90fc9d8b6101a07db3aa"],"title":"Viewpoint: observations on scaled average bioequivalence.","doi":"10.1002/pst.498"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2016,"outCitations":[],"journalName":"Pharmaceutical statistics","paperAbstract":"Bayesian methods are increasingly used in proof-of-concept studies. An important benefit of these methods is the potential to use informative priors, thereby reducing sample size. This is particularly relevant for treatment arms where there is a substantial amount of historical information such as placebo and active comparators. One issue with using an informative prior is the possibility of a mismatch between the informative prior and the observed data, referred to as prior-data conflict. We focus on two methods for dealing with this: a testing approach and a mixture prior approach. The testing approach assesses prior-data conflict by comparing the observed data to the prior predictive distribution and resorting to a non-informative prior if prior-data conflict is declared. The mixture prior approach uses a prior with a precise and diffuse component. We assess these approaches for the normal case via simulation and show they have some attractive features as compared with the standard one-component informative prior. For example, when the discrepancy between the prior and the data is sufficiently marked, and intuitively, one feels less certain about the results, both the testing and mixture approaches typically yield wider posterior-credible intervals than when there is no discrepancy. In contrast, when there is no discrepancy, the results of these approaches are typically similar to the standard approach. Whilst for any specific study, the operating characteristics of any selected approach should be assessed and agreed at the design stage; we believe these two approaches are each worthy of consideration.","inCitations":["f0469a8a432ed69b88603c1d14365a1e0281fe8e","defaa701eddee7513d6d64b1af8b587deaaad9b8"],"title":"Addressing potential prior-data conflict when using informative priors in proof-of-concept studies.","doi":"10.1002/pst.1722"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2011,"outCitations":["559b1c323e3bf1f04aa76ea8187c1585c410d1fb","459fe31ba1d91fb4f8d96b389002a5b852ce1542","f3f6a2ceeb8887cfb482c8e6fff8e52c7393dabe","4597bcb2d1abc6c09f7aac657f8280d7a669d6a3","510ea60f46785dcc5d5d1c96bd21b07d3852c6dc","24f3e29d9feab95e78f3f47364c4edbae34adfd2","6e820cf11712b9041bb625634612a535476f0960","6cc5b22e19a2049b9cf237d8b63fccc3b0b6d0df","d9665992ee36699b8ae4a2e2294552cd4be9003a","3dcba83c222211e461d466b868881068fc6de594","adbc35e6d34aac05e22d5ce5904f43f821aaa2f6","d9db67acc223c9bd9b8c1d4969dc105409c6dfef","5c8e2340a48ebb48bd3043bf9fce5df578968b63","35fc9c5d4805c74c76b88c9afa4d7755a01d0a71","b1ccd67d45981dd07997eae59fd8e641890fe34f","5c7f86fad63391931fd57c5ae1ad5a2b6eb81cb1"],"journalName":"Pharmaceutical statistics","paperAbstract":"Detecting data fabrication is of great importance in clinical trials. As the role of statisticians in detecting abnormal data patterns has grown, a large number of statistical procedures have been developed, most of which are based on descriptive statistics. Based upon the fact that substantial data fabrication cases have certain clustering structures, this paper discusses the potential for the use of statistical clustering method in fraud detection. Three clustering patterns, angular, neighborhood and repeated measurements clustering, are identified and explored. Correspondingly, simple and efficient test statistics are proposed and randomization tests are carried out. The proposed methods are applied to a 12-week multi-center study for illustration. Extensive simulations are conducted to validate the effectiveness of the procedures.","inCitations":["45cf7ac8fc209e9c69dd942ceba3b24f50eecff4","8385d88083689a03e84ac3595eb2b108bde751ca","23dabc96c98800695366c597cb2768b608197d66","dfcc9fecd32300a3795ab9cfba2f0cfcd97c8e5f","f186eb382722be45850f483166ec429d124934fa"],"title":"Detecting data fabrication in clinical trials from cluster analysis perspective.","doi":"10.1002/pst.462"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2005,"outCitations":[],"journalName":"The British journal of mathematical and statistical psychology","paperAbstract":"","inCitations":["cb8a2cf5d1c50462b190a3f3c7923959f3db354c"],"title":"Latent variable models for misclassified polytomous outcome variables.","doi":"10.1348/000711005X64970"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2012,"outCitations":[],"journalName":"The British journal of mathematical and statistical psychology","paperAbstract":"In 2004, Hunter and Schmidt proposed a correction (called Case IV) that seeks to estimate disattenuated correlations when selection is made on an unmeasured variable. Although Case IV is an important theoretical development in the range restriction literature, it makes an untestable assumption, namely that the partial correlation between the unobserved selection variable and the performance measure is zero. We show in this paper why this assumption may be difficult to meet and why previous simulations have failed to detect the full extent of bias. We use meta-analytic literature to investigate the plausible range of bias. We also show how Case IV performs in terms of standard errors. Finally, we give practical recommendations about how the contributions of Hunter and Schmidt (2004) can be extended without making such stringent assumptions.","inCitations":["295c318c528ac383b4d023d67e6b09504d107412"],"title":"Revisiting Case IV: a reassessment of bias and standard errors of Case IV under range restriction.","doi":"10.1111/j.2044-8317.2012.02060.x"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2017,"outCitations":["a30a2c4e74c843533ba9476cb871e3dec50d3bca","db869fa192a3222ae4f2d766674a378e47013b1b","9fdfb307864a0893fb0deb7be0b6c701787a092a","527051391a3da3209744955b1bf512a56344a12a","377339cd55087d503b855ae89d2126495cf104ee","9ece35a92c19a996b82bf6510ee7d6798c629d50","502e8e0d8502ff9d8cbfc565d9360afdfb2aea45","602e9f9844ce34c72e0bb6dceb80fb7c8e4d2e2a","2d8294ef6bdf283e4b7f524f8f388ef744e539b3","267cf324f04f1993227f780af3555ea7d6c59c26","228b1a39e768ea18f6332e6a56eee8f90cbc3075","576c1566be4ade86397db776a529275ec650208b","f56e77b637af934626b359ffe149c6bc3de76d06","9f46b5215f247519b058d0f8ebdb9535cf807328","5085499af8371ed0e33948ab74da3c8778379817","07960627be6d23f3fad40e7d153936b2ca96a704","9a3865baa4ca5cf7c55a9f427f078820e990e89e","e4ef2cad401b7e713d5cb19d9955c6908d532f28","6b547b4074fa7733543353f9c2b05f3eae8ba322","e4f3ec8909370c2fc5b95d6697547837884d20a2","65bb01b985035307f7b1102e17b8a5c0f2dafff8","7bb351ff50cb69a8f9ac6f7d474da9817fc47c40","a5dc6b6acb9dc3af6fd0a961d9c799ea18eb2c49","f714b82aff5370bec8990671b30b9af743b147ba","1800bbe878b7e83d22bf386ae5e689c91a904fdd","75f063c9b32912f4b1b1f08dbcf6b0575ce16bf1","c9db97118af813a87eb355c5a80671364c9ebbe1","4b8d6bb9eb2457ddd85b6e32c6c6f3e2fe9f6a69","02e0b64a2464b0a368d0355a8e4430ab6d4d61ab","296e0ce587af299ac88338950cd0e87b23409a73","f62bd0269aeb12f308078de2ade5d6d917fcfbc5","dbb7856e235481a8c07552288bc5972a50347d25","21eba2146c1f1b7f2b577c7c8b92d0622bc442e6"],"journalName":"Journal of statistical computation and simulation","paperAbstract":"The Log-Gaussian Cox Process is a commonly used model for the analysis of spatial point pattern data. Fitting this model is difficult because of its doubly-stochastic property, i.e., it is an hierarchical combination of a Poisson process at the first level and a Gaussian Process at the second level. Various methods have been proposed to estimate such a process, including traditional likelihood-based approaches as well as Bayesian methods. We focus here on Bayesian methods and several approaches that have been considered for model fitting within this framework, including Hamiltonian Monte Carlo, the Integrated nested Laplace approximation, and Variational Bayes. We consider these approaches and make comparisons with respect to statistical and computational efficiency. These comparisons are made through several simulation studies as well as through two applications, the first examining ecological data and the second involving neuroimaging data.","inCitations":["95faca748136bc4f94d55be6176eb7d9c3f70f5e","592965cd106278c160cce7961b4a3d67861d12be","32e76c79fe8bea763cdf2ee675dab1c04232b9ee","14908a61a48bd27256a36fd08eed69815d059b16","9ba4e12861de5580e582b15c65dd161100d050ac"],"title":"Bayesian Computation for Log-Gaussian Cox Processes: A Comparative Analysis of Methods.","doi":"10.1080/00949655.2017.1326117"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2000,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"Generalized linear models are developed for crossover trials with no carryover effects and fixed subject effects. A general multinominal model for the distribution of data is considered. This subsumes both binary and categorical data. Conditional inferences eliminate subject effects by conditioning on their sufficient statistics. For normal data, least-squares analysis is exact with identical treatment inferences from unconditional and conditional analyses. For Poisson data, unconditional and conditional analyses are also identical, but for multinomial data this is not the case and the unconditional analysis is invalid. For multinomial data, asymptotic tests of both treatment effects and goodness of fit are unreliable with small samples. Procedures for exact tests are developed to overcome such problems, using enumeration, random sampling, and a hybrid of importance sampling and enumeration. A four-period binary crossover trial is used to illustrate an exact test of treatment effects by a two-stage sampling procedure based on a factorization of the conditional distribution of the sufficient statistics. An exact test of goodness of fit on the same data illustrates a two-stage scheme mixing importance sampling and enumeration.","inCitations":["ec1c22bb87244cdf2b6783a6085333ccc8547ac1"],"title":"Conditional and exact tests in crossover trials.","doi":"10.1081/BIP-100101017"}
{"fieldsOfStudy":["Medicine","Mathematics"],"year":2009,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"We use the framework of coarsened data to motivate performing sensitivity analysis in the presence of incomplete data. To perform the sensitivity analysis, we specify pattern-mixture models to allow departures from the assumption of coarsening at random, a generalization of missing at random and independent censoring. We apply the concept of coarsening to address potential bias from missing data and interval-censored data in a randomized controlled trial of an herbal treatment for acute hepatitis. Computer code using SAS PROC NLMIXED for fitting the models is provided.","inCitations":["28b9401aa7e36bd683a6e813566b0de7eac31363","c190dc3003f648a8e95d7886fde46b5155a79332"],"title":"Sensitivity analysis of informatively coarsened data using pattern mixture models.","doi":"10.1080/10543400903242779"}
{"fieldsOfStudy":["Computer Science","Medicine"],"year":2014,"outCitations":[],"journalName":"Wiley interdisciplinary reviews. Computational statistics","paperAbstract":"Recent studies have collected high-dimensional data longitudinally. Examples include brain images collected during different scanning sessions and time-course gene expression data. Because of the additional information learned from the temporal changes of the selected features, such longitudinal high-dimensional data, when incorporated with appropriate statistical learning techniques, are able to more accurately predict disease status or responses to a therapeutic treatment. In this article, we review recently proposed statistical learning methods dealing with longitudinal high-dimensional data.","inCitations":["a5c0309b9895066ebd08acfe326b01ce2fdefdd4","1d4fe6469d79c88896a171930eba675c3b14eb34","d02dfed6c2898a322a437531ea35a3cc4dce0ea5","1ccf652fb8424722b501464ae8a93bd49a6e24f9"],"title":"Statistical Learning Methods for Longitudinal High-dimensional Data.","doi":"10.1002/wics.1282"}
{"fieldsOfStudy":["Computer Science","Medicine","Mathematics"],"year":2013,"outCitations":["756280569cd1308db6823095772ae4fdb269e2a7","d60cd9a32dce378706cfe66b3987f4797f452adf","732325ce284ea3ee43c9a53eac6fc4e7a8e76b90","040f0be1f1bbc49fd23941f77400022f3bbca390","04d7cc26dbcc98170cfe938dd553fdbd6a436505","0b22ef0a44af2c229081c5b68d46514a8fd8f643","97012f51b10409adc85d3085ab3a1b029a6cf049","9d59e5c5d029345e176da0351a0831b9cf762096","7b00f78cf908518b1fbc2af0c10815d2e69036ff","e53f12258ad27f727e6907ca3a6a391dd856cd2e","311115db251ff1b9317d2b58a55309d90b3f5d1e"],"journalName":"Computational statistics & data analysis","paperAbstract":"This paper discusses nonparametric comparison of survival functions when one observes only interval-censored failure time data (Peto and Peto, 1972; Sun, 2006; Zhao et al., 2008). For the problem, a few procedures have been proposed in the literature. However, most of the existing test procedures determine the test results or p-values based on ad hoc methods or the permutation approach. Furthermore for the test procedures whose asymptotic distributions have been derived, the results are only for the null hypothesis. In other words, no nonparametric test procedure exists that has a known asymptotic distribution under the alternative hypothesis and thus can be employed to carry out the power and test size calculation. In this paper, a new class of generalized log-rank tests is proposed and their asymptotic distributions are derived under both null and alternative hypotheses. A simulation study is conducted to assess their performance for finite sample situations and an illustrative example is provided.","inCitations":["70a7c7b5e35e76ca3e5a0a807b612dae347964bb","64896fb6bf18f82076bc97de96536b7a44c04945"],"title":"A new class of generalized log rank tests for interval-censored failure time data","doi":"10.1016/j.csda.2012.11.002"}
{"fieldsOfStudy":["Computer Science","Mathematics","Medicine"],"year":2006,"outCitations":["9c872e57ae37601d3c90d4d2ad5b9636dc3555fd","263f103fd2bfbbd6aeb392c6519d3f590e647c0a","4f9dc27a5ddcca1a24848412ece85b10c121ed90","6db47b58d3a63e60d3772c02250c5973402b1385","18d5fa98e73d30da0621916dac5318e2ea0a386d","d95900d5ad6a4ebf1e0efd86ebe906144fc75386","df25adb36860c1ad9edaac04b8855a2f19e79c5b","2446ff36818d62c8851e39bef95da9c02235388a","3599ecc225de0bbb4a34ac01d780681881639385","7fc22c72ce8f998c9e8dc54f4dca3e2bc7a1ab25","c824343ac540d3bafd7c4eaadb10fb7a1d8e5c76","66be81f765a825940748f6eb54b63a64ff972e7b","baf0aa3bd227d7cc07663083d1f91d0b52a860a6","a9b9c2e71566912d1f82643b50f6368539738c28","4aeb93b27e4755f04629e094df36b649c03bc078","eb7ba495d2adb625347448f0b30dca86f9f3d3f1","ba72eebd90de624a5428a8490e2c1365b99f4a3c","3926a7a217481883bb530cc83ec3f3f331729a5c","115abfc6765454e124afe47e82e7bef8ee7687a8","08401cd7b944057a654147cc70c9df1cf93005bd","c781aac01809a87ede686d0ee7fcf1f6917503e6","3a414cb37970ae9a7f047599f00f1f7d5a13c2f4","7656b85eb6ee1d2324de453a153c5aefdfa1af05","d0b50ca70f781df9514a6cbb02ed6eb54af48f75","ed831e9c931f82488374629e3245008cff4bcb53","6ee64fa84d223afc6af901dae5d91272ffd69fe6","ed330694a21dd9dc4755a41984e6277d1d2428b0","7af7ab031fd9717494abd949f05cdf3730272371","c92d6fa1e30e12946c874e5a8b9aeee3c0155e29"],"journalName":"Computational statistics & data analysis","paperAbstract":"Performance evaluations often aim to achieve goals such as obtaining estimates of unit-specific means, ranks, and the distribution of unit-specific parameters. The Bayesian approach provides a powerful way to structure models for achieving these goals. While no single estimate can be optimal for achieving all three inferential goals, the communication and credibility of results will be enhanced by reporting a single estimate that performs well for all three. Triple goal estimates [Shen and Louis, 1998. Triple-goal estimates in two-stage hierarchical models. J. Roy. Statist. Soc. Ser. B 60, 455-471] have this performance and are appealing for performance evaluations. Because triple-goal estimates rely more heavily on the entire distribution than do posterior means, they are more sensitive to misspecification of the population distribution and we present various strategies to robustify triple-goal estimates by using nonparametric distributions. We evaluate performance based on the correctness and efficiency of the robustified estimates under several scenarios and compare empirical Bayes and fully Bayesian approaches to model the population distribution. We find that when data are quite informative, conclusions are robust to model misspecification. However, with less information in the data, conclusions can be quite sensitive to the choice of population distribution. Generally, use of a nonparametric distribution pays very little in efficiency when a parametric population distribution is valid, but successfully protects against model misspecification.","inCitations":["c98e6250efbe82026787195e2420787471616a73","9c6e2e63ebc562d2769b4e5d89f3afe8fdce5613","a1a92dd0742fd3f9a0a30158264cbea8be6177a6","7718a52627c30b46557891f3695d87c32a5e7d30","14fa9b3d28d1d6d6c86fbf0dd6432acc1dd96f70","912f3158f057975aa0a805ea94fd70f511b7fa24","0c3b92d2d8b87a816d739a9f191c8205b41a6487","b63b551c883c815ca47a05e98686e87b8bb66700"],"title":"Flexible distributions for triple-goal estimates in two-stage hierarchical models","doi":"10.1016/j.csda.2005.05.008"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2002,"outCitations":[],"journalName":"Journal of biopharmaceutical statistics","paperAbstract":"A common standard for the demonstration of efficacy in a clinical submission is a statistically significant outcome in at least two pivotal trials (\"two-trials convention\"). When the data structures in different trials are sufficiently similar to allow pooling of the data across trials for a combined analysis, we argue here that such an analysis is a more logical and efficient basis for a judgment regarding efficacy. Criteria for combined analyses may be established, which ensure the same false positive rate protection as the two-trials convention. A combined analysis will generally have much more power than the corresponding application of the two-trials approach that has the same false positive rate protection. In addition, we describe the behavior of modified versions of pure combined analysis, which incorporate a formal standard for reproducibility of trial results by limiting the larger of the individual trial p-values. These modifications are shown to maintain the desirable behavior of the pure combined analysis, namely, higher power compared to the two-trials convention.","inCitations":["3c9961f1a6d644517ea29d142b54bbb8d86de0ff","58ab90291c697937d222e22cb70495f2d20b86a6","e1da9df28014a89aa7453c28f6c64a47a978c200","d2c918160cce56ee7ac72f1e56471faec2d295eb","a9d748ab830d7c20d3a61c86ba147028ad22aaac"],"title":"Reconsidering some aspects of the two-trials paradigm.","doi":"10.1081/BIP-120006450"}
{"fieldsOfStudy":["Mathematics","Medicine"],"year":2011,"outCitations":["5d6092c6e5f3521e1e10358850bdb225bac100a1","c788056f32a392ac50b8c5e770ad7b78b8f71b88","ca695cc71ea4b92b1816ae8704b50d6a1fdbf4ed","9604dac10e0d561ca13e2495a1ded4d4173b44c7","b99d2b48686cd600862bc77ec27b49a5cf45c88b","c01c62ffaf98dc13f80a59a6929786f5b16a5f35","586a9687065f87faa75c6fef6a20af67620863cb","3b04dd767075c2af9bad82c5594b8e6f5d6b96eb","20d6ab2fdf44b90f90f9f4c3c3ee2d8367e81b89","20425e201224caebc92b280cf4cf788723643a0f","9cd04858c52bc3ebd81649e24b0be7b95745214b","18711bd7461ee018ef214218897bab9dc56b85cf","e3754a4f6cc119252ae58670944e7bcfa45f8876","fe94d18fe5f7b94f0805dbec9a1106a0244cdca7","ec139326c657b85d533e7304fbac5d4088ff6e28","eb334d755dce73fbba06c9ea48f832c57e9f1080","f7f04e0468059e69aa0b1dcaefa190c54939ec83","c24e9b15cef07eefcc158b1356debe8ef0680c52","32f56a6b28b944cacfbe144f421b869e448473d3","6b61b3a8dc0359a029efb08f0dcf0e4aa044b263","e6f00c548a4ace7c152bc3e2f6a8bb50a458bbde","0fa319ccabb6dc2790f0ca7bcdb3ad4f62a55901","7a9a0c696f04af308db9733a012d6e80f60dcb64"],"journalName":"The annals of applied statistics","paperAbstract":"We propose a new integrated phase I/II trial design to identify the most efficacious dose combination that also satisfies certain safety requirements for drug-combination trials. We first take a Bayesian copula-type model for dose finding in phase I. After identifying a set of admissible doses, we immediately move the entire set forward to phase II. We propose a novel adaptive randomization scheme to favor assigning patients to more efficacious dose-combination arms. Our adaptive randomization scheme takes into account both the point estimate and variability of efficacy. By using a moving reference to compare the relative efficacy among treatment arms, our method achieves a high resolution to distinguish different arms. We also consider groupwise adaptive randomization when efficacy is late-onset. We conduct extensive simulation studies to examine the operating characteristics of the proposed design, and illustrate our method using a phase I/II melanoma clinical trial.","inCitations":["f996e371d554dd16837dadfbee9615b1191d8b91","3df62fadb08311b8d9b14d9bfb31771da62e50a6","76dcca26bf89d3fbbd8e32af97e43fb80fed8729","ef6bbdf722d4a0266f571e9c6910353efb294545","b0bf2559f64c30f2ac882bb7afb0c5e8af9062ff","f523457d75fcfde3a9687d4ec5a0082c046e593f","c3a447307e81b59994c9a688867b7de89cc7e08a","a41559bc41dc83ff9deae28a54f53cd4c440b235","4ba7e4524e903c95c980b05690115151e745d75d","7af6036c6ea2bd18579360d6f8c79b90f3d829ed","fb8d33e1913a9200c0e16f2c126e8f57f42b3b0a","3c765ad429b7cd9cfe523ecacc66849ca76476d2","949f7193d3cd2491f71f3fb916c14375fe58e331","f42b3a98cd00fd25caa5deda225c91c50e49f723","525117a90d01d39880e54ca59d70752bf29fa5db"],"title":"Bayesian Phase I/ii Adaptively Randomized Oncology Trials with Combined Drugs.","doi":"10.1214/10-AOAS433"}
